#
# CosmoPipe Pipeline Configuration File 
# Pipelines should be configured as: 
#
# [name]: .[submode1] [standalone1] [standalone2] .[submode2] ...
# .[submode1]: [standalone3] [standalone4] .[submode3] ...
# 
# There are 3 special functions: 
# - @[name] sets the datablock entry [name] to the datahead 
# - ![name] sets the current datahead to the block item [name]
# - %[name1]-[name2] changes the datablock entry [name1] to [name2]
# - +[name]=[value] assigns variable [name] the [value] in the block variables
#

#Variables {{{
.use_simulation_variables_skills: #Set relevant column names to those from simulated catalogues {{{
  +NSOM_GOLDWEIGHT=10                   #number of SOMs for goldweight calculation
  +ZSPECNAME=redshift_input       #spec-z name 
  +ZPHOTNAME=Z_B                  #Photo-z name 
  +WEIGHTNAME=AlphaRecalC_weight  #Weightname 
  +RANAME=X_WORLD                 #RA variable name 
  +DECNAME=Y_WORLD                #DEC variable name 
  +G1NAME=g1_in                   #Input g1 variable name 
  +G2NAME=g2_in                   #Input g2 variable name 
  +E1NAME=e1_LF_r                 #E1 variable name 
  +E2NAME=e2_LF_r                 #E2 variable name 
  +SNRNAME=SNR_LF_r               #Signal-to-noise name 
  +RAWE1NAME=e1_LF_r              #Raw E1 variable name 
  +RAWE2NAME=e2_LF_r              #Raw E2 variable name 
  +SHAPEVARNAME=LS_variance_LF_r  #Shape Variance variable name 
  +BULGEFRACNAME=bulge_fraction_LF_r  #Shape Variance variable name 
  +PSFE1NAME=psf_e1_LF_r          #PSF E1 variable name 
  +PSFE2NAME=psf_e2_LF_r          #PSF E2 variable name 
  +ADDITIONALFLAGS=--refr.truth   #Compute true biases for dz calculations 
  +MAGLIST="MAG_GAAP_u MAG_GAAP_g MAG_GAAP_r MAG_GAAP_i1 MAG_GAAP_i2 MAG_GAAP_Z MAG_GAAP_Y MAG_GAAP_J MAG_GAAP_H MAG_GAAP_Ks"
  +REFMAGNAME=MAG_AUTO            #Name of the reference magnitude 
#}}}

.use_simulation_variables_mice2: #Set relevant column names to those from simulated catalogues {{{
  +NSOM_GOLDWEIGHT=10             #number of SOMs for goldweight calculation
  +RANAME=ra_gal_mag              #RA variable name 
  +DECNAME=dec_gal_mag            #DEC variable name 
  +ZSPECNAME=z_cgal_v             #spec-z name 
  +ZPHOTNAME=Z_B                  #Photo-z name 
  #+WEIGHTNAME=recal_weight        #Weightname 
  +WEIGHTNAME=AlphaRecalC_weight_@BV:BLIND@   #Weightname inherited from the data
  +REFMAGNAME=MAG_GAAP_r          #Name for the reference total mag 
  +MAGLIST="MAG_GAAP_u MAG_GAAP_g MAG_GAAP_r MAG_GAAP_i1 MAG_GAAP_i2 MAG_GAAP_Z MAG_GAAP_Y MAG_GAAP_J MAG_GAAP_H MAG_GAAP_Ks"
  +ADDITIONALFLAGS=--refr.truth   #Compute true biases for dz calculations 
#}}}

.use_data_variables: #Set relevant column names to those from data catalogues {{{
  +NSOM_GOLDWEIGHT=10                        #number of SOMs for goldweight calculation
  +ZSPECNAME=z_spec                          #spec-z name 
  +ZPHOTNAME=Z_B                             #Photo-z name 
  +WEIGHTNAME=AlphaRecalC_weight_@BV:BLIND@  #Weightname 
  +RANAME=ALPHA_J2000                        #RA variable name 
  +DECNAME=DELTA_J2000                       #DEC variable name 
  +RAWE1NAME=raw_e1_@BV:BLIND@               #Raw E1 variable name (for KiDS-Legacy) 
  +RAWE2NAME=raw_e2_@BV:BLIND@               #Raw E2 variable name (for KiDS-Legacy) 
  +XNAME=Xpos                                #X variable name (for KiDS-Legacy) 
  +YNAME=Ypos                                #Y variable name (for KiDS-Legacy) 
  +E1NAME=autocal_e1_@BV:BLIND@              #E1 variable name (for KiDS-Legacy) 
  +E2NAME=autocal_e2_@BV:BLIND@              #E2 variable name (for KiDS-Legacy) 
  +SHAPEVARNAME=2D_measurement_variance      #Shape Variance variable name 
  +BULGEFRACNAME=bulge_fraction              #Bulge Fraction variable name 
  +PSFE1NAME=PSF_e1                          #PSF E1 variable name 
  +PSFE2NAME=PSF_e2                          #PSF E2 variable name 
  +SNRNAME=model_SNratio                     #Signal-to-noise name 
  +ADDITIONALFLAGS=                          #Do not compute true biases (because we can't!)
  +MAGLIST="MAG_GAAP_u MAG_GAAP_g MAG_GAAP_r MAG_GAAP_i1 MAG_GAAP_i2 MAG_GAAP_Z MAG_GAAP_Y MAG_GAAP_J MAG_GAAP_H MAG_GAAP_Ks"
  +REFMAGNAME=MAG_AUTO                       #Name of the reference magnitude 
#}}}

.use_data_variables_k1000: #Set relevant column names to those from the KiDS-1000 data catalogues {{{
  +NSOM_GOLDWEIGHT=1                    #number of SOMs for goldweight calculation
  +ZSPECNAME=z_spec_B                    #spec-z name 
  +ZPHOTNAME=Z_B                        #Photo-z name 
  +WEIGHTNAME=recal_weight_@BV:BLIND@   #Weightname 
  +RANAME=ALPHA_J2000                   #RA variable name 
  +DECNAME=DELTA_J2000                  #DEC variable name 
  +RAWE1NAME=raw_e1_@BV:BLIND@          #Raw E1 variable name (for KiDS-1000) 
  +RAWE2NAME=raw_e2_@BV:BLIND@          #Raw E2 variable name (for KiDS-1000) 
  +E1NAME=autocal_e1_@BV:BLIND@         #E1 variable name (for KiDS-1000) 
  +E2NAME=autocal_e2_@BV:BLIND@         #E2 variable name (for KiDS-1000) 
  +SHAPEVARNAME=2D_measurement_variance #Shape Variance variable name 
  +PSFE1NAME=PSF_e1                     #PSF E1 variable name 
  +PSFE2NAME=PSF_e2                     #PSF E2 variable name 
  +SNRNAME=model_SNratio                #Signal-to-noise name 
  +ADDITIONALFLAGS=                     #Do not compute true biases (because we can't!)
  +MAGLIST="MAG_GAAP_u MAG_GAAP_g MAG_GAAP_r MAG_GAAP_i MAG_GAAP_Z MAG_GAAP_Y MAG_GAAP_J MAG_GAAP_H MAG_GAAP_Ks"
  +REFMAGNAME=MAG_AUTO                  #Name of the reference magnitude 
#}}}

.use_data_variables_k1000_hybrid: #Set relevant column names to those from the KiDS-1000 data catalogues {{{
  +NSOM_GOLDWEIGHT=10                   #number of SOMs for goldweight calculation
  +ZSPECNAME=z_spec                      #spec-z name 
  +ZPHOTNAME=Z_B                        #Photo-z name 
  +WEIGHTNAME=recal_weight_@BV:BLIND@   #Weightname 
  +RANAME=ALPHA_J2000                   #RA variable name 
  +DECNAME=DELTA_J2000                  #DEC variable name 
  +RAWE1NAME=raw_e1_@BV:BLIND@          #Raw E1 variable name (for KiDS-1000) 
  +RAWE2NAME=raw_e2_@BV:BLIND@          #Raw E2 variable name (for KiDS-1000) 
  +E1NAME=autocal_e1_@BV:BLIND@         #E1 variable name (for KiDS-1000) 
  +E2NAME=autocal_e2_@BV:BLIND@         #E2 variable name (for KiDS-1000) 
  +BULGEFRACNAME=bulge_fraction         #Bulge Fraction variable name 
  +SHAPEVARNAME=2D_measurement_variance #Shape Variance variable name 
  +PSFE1NAME=PSF_e1                     #PSF E1 variable name 
  +PSFE2NAME=PSF_e2                     #PSF E2 variable name 
  +SNRNAME=model_SNratio                #Signal-to-noise name 
  +ADDITIONALFLAGS=                     #Do not compute true biases (because we can't!)
  +MAGLIST="MAG_GAAP_u MAG_GAAP_g MAG_GAAP_r MAG_GAAP_i1 MAG_GAAP_Z MAG_GAAP_Y MAG_GAAP_J MAG_GAAP_H MAG_GAAP_Ks"
  +REFMAGNAME=MAG_AUTO                  #Name of the reference magnitude 
#}}}

.use_data_variables_paus: #Set relevant column names to those from data catalogues {{{
  +NSOM_GOLDWEIGHT=10                   #number of SOMs for goldweight calculation
  +ZSPECNAME=Zbest                #spec-z name 
  +ZPHOTNAME=Z_B                  #Photo-z name 
  +WEIGHTNAME=AlphaRecalC_weight  #Weightname 
  +RANAME=ALPHA_J2000             #RA variable name 
  +DECNAME=DELTA_J2000            #DEC variable name 
  +RAWE1NAME=raw_e1               #Raw E1 variable name 
  +RAWE2NAME=raw_e2               #Raw E2 variable name 
  +E1NAME=autocal_e1              #E1 variable name 
  +E2NAME=autocal_e2              #E2 variable name 
  +BULGEFRACNAME=bulge_fraction         #Bulge Fraction variable name 
  #+RAWE1NAME=autocal_e1_@BV:BLIND@ #Raw E1 variable name (for K1000 LF309) 
  #+RAWE2NAME=autocal_e2_@BV:BLIND@ #Raw E2 variable name (for K1000 LF309) 
  #+E1NAME=autocal_e1_@BV:BLIND@  #E1 variable name (for K1000 LF309) 
  #+E2NAME=autocal_e2_@BV:BLIND@  #E2 variable name (for K1000 LF309) 
  +SHAPEVARNAME=2D_measurement_variance #Shape Variance variable name 
  +PSFE1NAME=PSF_e1               #PSF E1 variable name 
  +PSFE2NAME=PSF_e2               #PSF E2 variable name 
  +SNRNAME=model_SNratio          #Signal-to-noise name 
  +ADDITIONALFLAGS=               #Do not compute true biases (because we can't!)
  +REFMAGNAME=MAG_AUTO            #Name of the reference magnitude 
#}}}

.use_data_variables_lf321_hybrid: #Set relevant column names to those from data catalogues {{{
  +NSOM_GOLDWEIGHT=10                   #number of SOMs for goldweight calculation
  +ZSPECNAME=z_spec               #spec-z name 
  +ZPHOTNAME=Z_B                  #Photo-z name 
  +WEIGHTNAME=AlphaRecalC_weight  #Weightname 
  +RANAME=ALPHA_J2000             #RA variable name 
  +DECNAME=DELTA_J2000            #DEC variable name 
  +RAWE1NAME=raw_e1               #Raw E1 variable name 
  +RAWE2NAME=raw_e2               #Raw E2 variable name 
  +E1NAME=autocal_e1              #E1 variable name 
  +E2NAME=autocal_e2              #E2 variable name 
  +XNAME=Xpos                           #X variable name (for KiDS-Legacy) 
  +YNAME=Ypos                           #Y variable name (for KiDS-Legacy) 
  +BULGEFRACNAME=bulge_fraction         #Bulge Fraction variable name 
  +SHAPEVARNAME=2D_measurement_variance #Shape Variance variable name 
  +PSFE1NAME=PSF_e1               #PSF E1 variable name 
  +PSFE2NAME=PSF_e2               #PSF E2 variable name 
  +SNRNAME=model_SNratio          #Signal-to-noise name 
  +ADDITIONALFLAGS=               #Do not compute true biases (because we can't!)
  +MAGLIST="MAG_GAAP_u MAG_GAAP_g MAG_GAAP_r MAG_GAAP_i1 MAG_GAAP_Z MAG_GAAP_Y MAG_GAAP_J MAG_GAAP_H MAG_GAAP_Ks"
  +REFMAGNAME=MAG_AUTO                  #Name of the reference magnitude 
#}}}

.use_data_variables_lf321: #Set relevant column names to those from data catalogues {{{
  +NSOM_GOLDWEIGHT=10                   #number of SOMs for goldweight calculation
  +ZSPECNAME=Zbest                #spec-z name 
  +ZPHOTNAME=Z_B                  #Photo-z name 
  +WEIGHTNAME=AlphaRecalC_weight  #Weightname 
  +RANAME=ALPHA_J2000             #RA variable name 
  +DECNAME=DELTA_J2000            #DEC variable name 
  +RAWE1NAME=raw_e1               #Raw E1 variable name 
  +RAWE2NAME=raw_e2               #Raw E2 variable name 
  +E1NAME=autocal_e1              #E1 variable name 
  +E2NAME=autocal_e2              #E2 variable name 
  +XNAME=Xpos                           #X variable name (for KiDS-Legacy) 
  +YNAME=Ypos                           #Y variable name (for KiDS-Legacy) 
  +BULGEFRACNAME=bulge_fraction         #Bulge Fraction variable name 
  +SHAPEVARNAME=2D_measurement_variance #Shape Variance variable name 
  +PSFE1NAME=PSF_e1               #PSF E1 variable name 
  +PSFE2NAME=PSF_e2               #PSF E2 variable name 
  +SNRNAME=model_SNratio          #Signal-to-noise name 
  +ADDITIONALFLAGS=               #Do not compute true biases (because we can't!)
  +MAGLIST="MAG_GAAP_u MAG_GAAP_g MAG_GAAP_r MAG_GAAP_i1 MAG_GAAP_Z MAG_GAAP_Y MAG_GAAP_J MAG_GAAP_H MAG_GAAP_Ks"
  +REFMAGNAME=MAG_AUTO                  #Name of the reference magnitude 
#}}}

.setup_datasim_variables_skills: #Setup the specific _DATA and _SIM variables {{{
  .use_data_variables                    #Use the data variable names 
  +ZSPECDATA=@BV:ZSPECNAME@              #Data redshift name 
  +ZSPECDATAKEEP=@BV:ZSPECNAME@          #Data redshift name 
  +DATAFEATURES=@BV:MAGLIST@             #Data feature list (magnitudes)
  +WEIGHTNAME_DATA=@BV:WEIGHTNAME@       #Data weight name 
  .use_simulation_variables_skills       #Use the simulation variable names 
  +ZSPECSIM=@BV:ZSPECNAME@               #Simulation redshift name 
  +ZSPECSIMKEEP=@BV:ZSPECNAME@           #Simulation redshift name 
  +SIMFEATURES=@BV:MAGLIST@              #Simulation feature list (magnitudes)
  +WEIGHTNAME_SIM=@BV:WEIGHTNAME@        #Simulation weight name
#}}}

.setup_datasim_variables_mice2: #Setup the specific _DATA and _SIM variables {{{
  .use_data_variables                    #Use the data variable names 
  +ZSPECDATA=@BV:ZSPECNAME@              #Data redshift name 
  +ZSPECDATAKEEP=@BV:ZSPECNAME@          #Data redshift name 
  +DATAFEATURES=@BV:MAGLIST@             #Data feature list (magnitudes)
  +WEIGHTNAME_DATA=@BV:WEIGHTNAME@       #Data weight name 
  .use_simulation_variables_mice2        #Use the simulation variable names 
  +ZSPECSIM=@BV:ZSPECNAME@               #Simulation redshift name 
  +ZSPECSIMKEEP=@BV:ZSPECNAME@           #Simulation redshift name 
  +SIMFEATURES=@BV:MAGLIST@              #Simulation feature list (magnitudes)
  +WEIGHTNAME_SIM=@BV:WEIGHTNAME@        #Simulation weight name 
#}}}
#}}}

#Catalogue Preparation {{{
.add_datasets: # Add all catalogues to the datablock {{{
  add_main                   #Add the main catalogues to the data block 
  %main_cats-main_raw        #rename the original cats block to main_raw
  add_specz                  #Add the specz calibration catalogue to the data block 
  add_sims_main              #Add the simulated main catalogues (for dz and m computation) 
  %sims_main-sims_raw        #Rename original catalogues to sims_raw
#}}}

.inherit_fiducial_data: # Inherit the primary data products from the fiducial pipeline {{{ 
  +INHERIT_PIPE=Legacy_fiducial
  +INHERIT_BLOCK="main_all main_all_tomo main_cats main_cats_tomo specz_adapt specz_adapt_tomo sims_main sims_main_tomo sims_specz sims_specz_tomo"
  inherit  
#}}}

#Data {{{
.prepare_data_catalogues: # Prepare all catalogues for science {{{
  .use_data_variables        #Update variables for the data catalogues
  .prepare_main              #Prepare the main survey catalogues 
  .prepare_specz_NOADAPT     #Prepare the specz calibration catalogues 
#}}}

.prepare_data_catalogues_expflag: # Prepare all catalogues for science with flagging of bad chip astrometry {{{
  .use_data_variables        #Update variables for the data catalogues
  .prepare_main_expflag      #Prepare the main survey catalogues 
  .prepare_specz_NOADAPT     #Prepare the specz calibration catalogues 
#}}}

.prepare_data_catalogues_expflag_flip: # Prepare all catalogues for science with flagging of bad chip astrometry {{{
  .use_data_variables        #Update variables for the data catalogues
  .prepare_main_expflag_flip #Prepare the main survey catalogues 
  .prepare_specz_NOADAPT     #Prepare the specz calibration catalogues 
#}}}

.prepare_data_catalogues_HHexpflag: # Prepare all catalogues for science with flagging of bad chip astrometry {{{
  .use_data_variables        #Update variables for the data catalogues
  .prepare_main_HHexpflag      #Prepare the main survey catalogues 
  .prepare_specz_NOADAPT     #Prepare the specz calibration catalogues 
#}}}

.prepare_data_catalogues_KKexpflag: # Prepare all catalogues for science with flagging of bad chip astrometry {{{
  .use_data_variables        #Update variables for the data catalogues
  .prepare_main_KKexpflag      #Prepare the main survey catalogues 
  .prepare_specz_NOADAPT     #Prepare the specz calibration catalogues 
#}}}

.prepare_data_catalogues_flag: # Prepare all catalogues for science {{{
  .use_data_variables        #Update variables for the data catalogues
  .prepare_main_flag         #Prepare the main survey catalogues 
  .prepare_specz_NOADAPT     #Prepare the specz calibration catalogues 
#}}}

.prepare_data_catalogues_k1000: # Prepare all KiDS-1000 catalogues for science {{{
  .use_data_variables_k1000  #Update variables for the data catalogues
  .prepare_main_k1000        #Prepare the main survey catalogues 
  .prepare_specz_k1000       #Prepare the specz calibration catalogues 
#}}}

.prepare_data_catalogues_k1000_hybrid: # Prepare all KiDS-1000 catalogues for science {{{
  .use_data_variables_k1000_hybrid  #Update variables for the data catalogues
  .prepare_main_k1000_hybrid #Prepare the main survey catalogues 
  .prepare_specz_NOADAPT     #Prepare the specz calibration catalogues 
#}}}

.prepare_data_catalogues_lf321_hybrid: # Prepare all KiDS-1000 lf321 catalogues for science {{{
  .use_data_variables_lf321_hybrid  #Update variables for the data catalogues
  .prepare_main_lf321_hybrid #Prepare the main survey catalogues 
  .prepare_specz_NOADAPT     #Prepare the specz calibration catalogues 
#}}}

.prepare_data_catalogues_lf321: # Prepare all KiDS-1000 LF321 catalogues for science {{{
  .use_data_variables_lf321  #Update variables for the data catalogues
  .prepare_main_lf321        #Prepare the main survey catalogues 
  .prepare_specz_lf321       #Prepare the specz calibration catalogues 
#}}}

.prepare_specz_lf321: # Prepare calibration catalogues {{{
  @specz_cat                   #Copy the specz catalogue to the DATAHEAD 
  use_adapt_mag                #Convert the magnitudes to adapted magnitudes 
  .ensure_ldac                 #Ensure that the calibration catalogue is LDAC compatible
  .specz_selection_paus        #Select sources with specz measurements
  .gaapflag_selection_kv450    #Select the sources with GAAPFLAG 0 values
  .column_reduction            #Keep only columns that we need for CosmoPipe
  #add_prior_weights            #Add the weights to correct for prior volume shift
  .add_psf_radius              #Add PSF Radius information 
  .add_aper_ratio_kv450        #Add GAaP aperture B/A ratio 
  !specz_adapt                 #Save the specz adapt catalogue to data block 
  #.specz_inherit_weight_noPV
  tomography                   #Apply tomography to calibration catalogue
  !specz_adapt_tomo            #Save specz adapt tomographic catalogue to data block 
  @                            #Clear the DATAHEAD 
#}}}

.prepare_main: # Prepare main survey catalogues {{{
  @main_raw                       #Copy the main catalogues to the DATAHEAD
  .ensure_ldac                    #Ensure that the main catalogues are LDAC compatible 
  .column_reduction               #Keep only columns that we need for CosmoPipe
  .gaapflag_selection             #Select the sources with GAAPFLAG 0 values
  .add_psf_radius                 #Add PSF Radius information 
  .add_aper_ratio                 #Add GAaP aperture B/A ratio 
  !main_allweight                 #Save the catalogue without weight>0 cut 
  +FILTERCOND=(@BV:WEIGHTNAME@>0) #Remove weight=0 sources 
  ldacfilter                      #Filter the catalogue to this subset 
  !main_cats                      #Copy these catalogues back to the main_cats 
  tomography                      #Apply tomography to the main catalogues (still in DATAHEAD)
  !main_cats_tomo                 #Save patchwise tomographic catalogues to main_cats_tomo 
  @main_cats                      #Combine the patches into a single catalogue
  combine_patch                   # ^^
  !main_all                       #Construct tomographic all-patch catalogues
  tomography                      # ^^
  !main_all_tomo                  #Save tomographic all-patch catalogues to main_all_tomo 
  @                               #Clear the DATAHEAD 
#}}}

.prepare_main_expflag: # Prepare main survey catalogues {{{
  @main_raw                       #Copy the main catalogues to the DATAHEAD
  .ensure_ldac                    #Ensure that the main catalogues are LDAC compatible 
  .column_reduction               #Keep only columns that we need for CosmoPipe
  .gaapflag_selection             #Select the sources with GAAPFLAG 0 values
  .delete_inconsistent_exposures  #Remove sources which reside in areas of catastrophic internal astrometry
  .delete_inconsistent_astrom     #Remove sources which reside in areas of catastrophic external astrometry
  .add_psf_radius                 #Add PSF Radius information 
  .add_aper_ratio                 #Add GAaP aperture B/A ratio 
  !main_allweight                 #Save the catalogue without weight>0 cut 
  +FILTERCOND=(@BV:WEIGHTNAME@>0) #Remove weight=0 sources 
  ldacfilter                      #Filter the catalogue to this subset 
  !main_cats                      #Copy these catalogues back to the main_cats 
  tomography                      #Apply tomography to the main catalogues (still in DATAHEAD)
  !main_cats_tomo                 #Save patchwise tomographic catalogues to main_cats_tomo 
  @main_cats                      #Combine the patches into a single catalogue
  combine_patch                   # ^^
  !main_all                       #Construct tomographic all-patch catalogues
  tomography                      # ^^
  !main_all_tomo                  #Save tomographic all-patch catalogues to main_all_tomo 
  @                               #Clear the DATAHEAD 
#}}}

.prepare_main_expflag_flip: # Prepare main survey catalogues {{{
  @main_raw                       #Copy the main catalogues to the DATAHEAD
  .ensure_ldac                    #Ensure that the main catalogues are LDAC compatible 
  .column_reduction               #Keep only columns that we need for CosmoPipe
  .gaapflag_selection             #Select the sources with GAAPFLAG 0 values
  .delete_inconsistent_exposures_flip  #Remove sources which reside in areas of catastrophic internal astrometry
  .delete_inconsistent_astrom     #Remove sources which reside in areas of catastrophic external astrometry
  .add_psf_radius                 #Add PSF Radius information 
  .add_aper_ratio                 #Add GAaP aperture B/A ratio 
  !main_allweight                 #Save the catalogue without weight>0 cut 
  +FILTERCOND=(@BV:WEIGHTNAME@>0) #Remove weight=0 sources 
  ldacfilter                      #Filter the catalogue to this subset 
  !main_cats                      #Copy these catalogues back to the main_cats 
  tomography                      #Apply tomography to the main catalogues (still in DATAHEAD)
  !main_cats_tomo                 #Save patchwise tomographic catalogues to main_cats_tomo 
  @main_cats                      #Combine the patches into a single catalogue
  combine_patch                   # ^^
  !main_all                       #Construct tomographic all-patch catalogues
  tomography                      # ^^
  !main_all_tomo                  #Save tomographic all-patch catalogues to main_all_tomo 
  @                               #Clear the DATAHEAD 
#}}}

.prepare_main_HHexpflag: # Prepare main survey catalogues {{{
  @main_raw                       #Copy the main catalogues to the DATAHEAD
  .ensure_ldac                    #Ensure that the main catalogues are LDAC compatible 
  .column_reduction               #Keep only columns that we need for CosmoPipe
  .gaapflag_selection             #Select the sources with GAAPFLAG 0 values
  delete_HHsel_pointings          #Remove sources which reside in areas of catastrophic external astrometry
  .add_psf_radius                 #Add PSF Radius information 
  .add_aper_ratio                 #Add GAaP aperture B/A ratio 
  !main_allweight                 #Save the catalogue without weight>0 cut 
  +FILTERCOND=(@BV:WEIGHTNAME@>0) #Remove weight=0 sources 
  ldacfilter                      #Filter the catalogue to this subset 
  !main_cats                      #Copy these catalogues back to the main_cats 
  tomography                      #Apply tomography to the main catalogues (still in DATAHEAD)
  !main_cats_tomo                 #Save patchwise tomographic catalogues to main_cats_tomo 
  @main_cats                      #Combine the patches into a single catalogue
  +KEEPSTRINGS="unique tile_label run_id flag_ Level ^R$ MAG_GAAP_ MAG_AUTO ALPHA_ DELTA_ RAJ2000 DECJ2000 ^FLUX_RADIUS$ ^PSF_Q ^Agaper ^Bgaper ^RA_ ^DEC_ ^X_ ^Y_ e1 e2 weight scalelength SNR SNratio variance g1 g2 ^T_B$ ^Z_B$ redshift ^z_ zspec zbest ^SeqNr$ ^FIELD_POS$ Xpos Ypos ^W$ ^bulge_fraction"  #(Partial-)Matching columns are kept, case-insensitive  
  ldackeepcols        #Remove non-matching columns 
  combine_patch                              #Combine the c-corrected patches together by patch
  !main_all                       #Construct tomographic all-patch catalogues
  tomography                      # ^^
  !main_all_tomo                  #Save tomographic all-patch catalogues to main_all_tomo 
  @                               #Clear the DATAHEAD 
#}}}

.prepare_main_KKexpflag: # Prepare main survey catalogues {{{
  @main_raw                       #Copy the main catalogues to the DATAHEAD
  .ensure_ldac                    #Ensure that the main catalogues are LDAC compatible 
  .column_reduction               #Keep only columns that we need for CosmoPipe
  .gaapflag_selection             #Select the sources with GAAPFLAG 0 values
  delete_KKsel_pointings          #Remove sources which reside in areas of catastrophic external astrometry
  .add_psf_radius                 #Add PSF Radius information 
  .add_aper_ratio                 #Add GAaP aperture B/A ratio 
  !main_allweight                 #Save the catalogue without weight>0 cut 
  +FILTERCOND=(@BV:WEIGHTNAME@>0) #Remove weight=0 sources 
  ldacfilter                      #Filter the catalogue to this subset 
  !main_cats                      #Copy these catalogues back to the main_cats 
  tomography                      #Apply tomography to the main catalogues (still in DATAHEAD)
  !main_cats_tomo                 #Save patchwise tomographic catalogues to main_cats_tomo 
  @main_cats                      #Combine the patches into a single catalogue
  +KEEPSTRINGS="unique tile_label run_id flag_ Level ^R$ MAG_GAAP_ MAG_AUTO ALPHA_ DELTA_ RAJ2000 DECJ2000 ^FLUX_RADIUS$ ^PSF_Q ^Agaper ^Bgaper ^RA_ ^DEC_ ^X_ ^Y_ e1 e2 weight scalelength SNR SNratio variance g1 g2 ^T_B$ ^Z_B$ redshift ^z_ zspec zbest ^SeqNr$ ^FIELD_POS$ Xpos Ypos ^W$ ^bulge_fraction"  #(Partial-)Matching columns are kept, case-insensitive  
  ldackeepcols        #Remove non-matching columns 
  combine_patch                              #Combine the c-corrected patches together by patch
  !main_all                       #Construct tomographic all-patch catalogues
  tomography                      # ^^
  !main_all_tomo                  #Save tomographic all-patch catalogues to main_all_tomo 
  @                               #Clear the DATAHEAD 
#}}}

.prepare_main_flag: # Prepare main survey catalogues {{{
  @main_raw                       #Copy the main catalogues to the DATAHEAD
  .ensure_ldac                    #Ensure that the main catalogues are LDAC compatible 
  .column_reduction               #Keep only columns that we need for CosmoPipe
  .gaapflag_selection             #Select the sources with GAAPFLAG 0 values
  .add_psf_radius                 #Add PSF Radius information 
  .add_aper_ratio                 #Add GAaP aperture B/A ratio 
  !main_allweight                 #Save the catalogue without weight>0 cut 
  +OLDKEY=AlphaRecalC_weight
  +NEWKEY=AlphaRecalC_weight_bak
  ldacrenkey
  +OLDKEY=AlphaRecalC_variance
  +NEWKEY=AlphaRecalC_variance_bak
  ldacrenkey
  +RAWE1NAME=autocal_e1_@BV:BLIND@         #raw E1 variable isn't in the catalogue (for KiDS-Legacy) 
  +RAWE2NAME=autocal_e2_@BV:BLIND@         #raw E2 variable isn't in the catalogue (for KiDS-Legacy) 
  +WEIGHTNAME=AlphaRecalC_weight_bak       #Uncalibrated weight 
  run_weight_recal_flag           #Rerun the weight recalibration, flagging outliers 
  +WEIGHTNAME=AlphaRecalC_weight  #Calibrated weight
  +FILTERCOND=(@BV:WEIGHTNAME@>0) #Remove weight=0 sources 
  ldacfilter                      #Filter the catalogue to this subset 
  !main_cats                      #Copy these catalogues back to the main_cats 
  tomography                      #Apply tomography to the main catalogues (still in DATAHEAD)
  !main_cats_tomo                 #Save patchwise tomographic catalogues to main_cats_tomo 
  @main_cats                      #Combine the patches into a single catalogue
  combine_patch                   # ^^
  !main_all                       #Construct tomographic all-patch catalogues
  tomography                      # ^^
  !main_all_tomo                  #Save tomographic all-patch catalogues to main_all_tomo 
  @                               #Clear the DATAHEAD 
#}}}

.prepare_main_k1000: # Prepare main survey catalogues {{{
  .use_data_variables_k1000       #Update variables for the data catalogues
  @main_raw                       #Copy the main catalogues to the DATAHEAD
  .ensure_ldac                    #Ensure that the main catalogues are LDAC compatible 
  .column_reduction               #Keep only columns that we need for CosmoPipe
  .gaapflag_selection_k1000       #Select the sources with GAAPFLAG 0 values
  .add_psf_radius                 #Add PSF Radius information 
  .add_aper_ratio                 #Add GAaP aperture B/A ratio 
  !main_allweight                 #Save the catalogue without weight>0 cut 
  +FILTERCOND=(@BV:WEIGHTNAME@>0) #Remove weight=0 sources 
  ldacfilter                      #Filter the catalogue to this subset 
  !main_cats                      #Copy these catalogues back to the main_cats 
  tomography                      #Apply tomography to the main catalogues (still in DATAHEAD)
  !main_cats_tomo                 #Save patchwise tomographic catalogues to main_cats_tomo 
  @main_cats                      #Combine the patches into a single catalogue
  combine_patch                   # ^^
  !main_all                       #Construct tomographic all-patch catalogues
  tomography                      # ^^
  !main_all_tomo                  #Save tomographic all-patch catalogues to main_all_tomo 
  @                               #Clear the DATAHEAD 
#}}}

.prepare_main_k1000_hybrid: # Prepare main survey catalogues {{{
  .use_data_variables_k1000_hybrid #Update variables for the data catalogues
  @main_raw                       #Copy the main catalogues to the DATAHEAD
  .ensure_ldac                    #Ensure that the main catalogues are LDAC compatible 
  .column_reduction               #Keep only columns that we need for CosmoPipe
  .rename_skills_iband            #Rename i-band to i1-band 
  .gaapflag_selection_k1000       #Select the sources with GAAPFLAG 0 values
  .add_psf_radius                 #Add PSF Radius information 
  .add_aper_ratio                 #Add GAaP aperture B/A ratio 
  !main_allweight                 #Save the catalogue without weight>0 cut 
  +FILTERCOND=(@BV:WEIGHTNAME@>0) #Remove weight=0 sources 
  ldacfilter                      #Filter the catalogue to this subset 
  !main_cats                      #Copy these catalogues back to the main_cats 
  tomography                      #Apply tomography to the main catalogues (still in DATAHEAD)
  !main_cats_tomo                 #Save patchwise tomographic catalogues to main_cats_tomo 
  @main_cats                      #Combine the patches into a single catalogue
  combine_patch                   # ^^
  !main_all                       #Construct tomographic all-patch catalogues
  tomography                      # ^^
  !main_all_tomo                  #Save tomographic all-patch catalogues to main_all_tomo 
  @                               #Clear the DATAHEAD 
#}}}

.prepare_main_lf321_hybrid: # Prepare main survey catalogues {{{
  .use_data_variables_lf321_hybrid #Update variables for the data catalogues
  @main_raw                       #Copy the main catalogues to the DATAHEAD
  .ensure_ldac                    #Ensure that the main catalogues are LDAC compatible 
  .column_reduction               #Keep only columns that we need for CosmoPipe
  .rename_skills_iband            #Rename i-band to i1-band 
  .gaapflag_selection_k1000       #Select the sources with GAAPFLAG 0 values
  .add_psf_radius                 #Add PSF Radius information 
  .add_aper_ratio                 #Add GAaP aperture B/A ratio 
  !main_allweight                 #Save the catalogue without weight>0 cut 
  +FILTERCOND=(@BV:WEIGHTNAME@>0) #Remove weight=0 sources 
  ldacfilter                      #Filter the catalogue to this subset 
  !main_cats                      #Copy these catalogues back to the main_cats 
  tomography                      #Apply tomography to the main catalogues (still in DATAHEAD)
  !main_cats_tomo                 #Save patchwise tomographic catalogues to main_cats_tomo 
  @main_cats                      #Combine the patches into a single catalogue
  combine_patch                   # ^^
  !main_all                       #Construct tomographic all-patch catalogues
  tomography                      # ^^
  !main_all_tomo                  #Save tomographic all-patch catalogues to main_all_tomo 
  @                               #Clear the DATAHEAD 
#}}}

.prepare_main_lf321: # Prepare main survey catalogues {{{
  .use_data_variables_lf321       #Update variables for the data catalogues
  @main_raw                       #Copy the main catalogues to the DATAHEAD
  .ensure_ldac                    #Ensure that the main catalogues are LDAC compatible 
  .column_reduction               #Keep only columns that we need for CosmoPipe
  .gaapflag_selection_k1000       #Select the sources with GAAPFLAG 0 values
  .add_psf_radius                 #Add PSF Radius information 
  .add_aper_ratio                 #Add GAaP aperture B/A ratio 
  !main_allweight                 #Save the catalogue without weight>0 cut 
  +FILTERCOND=(@BV:WEIGHTNAME@>0) #Remove weight=0 sources 
  ldacfilter                      #Filter the catalogue to this subset 
  !main_cats                      #Copy these catalogues back to the main_cats 
  tomography                      #Apply tomography to the main catalogues (still in DATAHEAD)
  !main_cats_tomo                 #Save patchwise tomographic catalogues to main_cats_tomo 
  @main_cats                      #Combine the patches into a single catalogue
  combine_patch                   # ^^
  !main_all                       #Construct tomographic all-patch catalogues
  tomography                      # ^^
  !main_all_tomo                  #Save tomographic all-patch catalogues to main_all_tomo 
  @                               #Clear the DATAHEAD 
#}}}

.prepare_specz_NOADAPT: # Prepare calibration catalogues {{{
  @specz_cat                   #Copy the specz catalogue to the DATAHEAD 
  .ensure_ldac                 #Ensure that the calibration catalogue is LDAC compatible
  .mask_selection              #Select only MASK<1 sources 
  .gaapflag_selection          #Select the sources with GAAPFLAG 0 values
  .column_reduction            #Keep only columns that we need for CosmoPipe
  add_prior_weights            #Add the weights to correct for prior volume shift
  .add_psf_radius              #Add PSF Radius information 
  .add_aper_ratio              #Add GAaP aperture B/A ratio 
  !specz_adapt                 #Save the specz adapt catalogue to data block 
  .specz_inherit_weight        #Add shape measurements weights to the catalogue 
  tomography                   #Apply tomography to calibration catalogue
  !specz_adapt_tomo            #Save specz adapt tomographic catalogue to data block 
  @                            #Clear the DATAHEAD 
#}}}

.prepare_specz: # Prepare calibration catalogues {{{
  @specz_cat                   #Copy the specz catalogue to the DATAHEAD 
  use_adapt_mag                #Convert the magnitudes to adapted magnitudes 
  .ensure_ldac                 #Ensure that the calibration catalogue is LDAC compatible
  .mask_selection              #Select only MASK<1 sources 
  .gaapflag_selection          #Select the sources with GAAPFLAG 0 values
  .column_reduction            #Keep only columns that we need for CosmoPipe
  add_prior_weights            #Add the weights to correct for prior volume shift
  .add_psf_radius              #Add PSF Radius information 
  .add_aper_ratio              #Add GAaP aperture B/A ratio 
  !specz_adapt                 #Save the specz adapt catalogue to data block 
  tomography                   #Apply tomography to calibration catalogue
  !specz_adapt_tomo            #Save specz adapt tomographic catalogue to data block 
  @                            #Clear the DATAHEAD 
#}}}

.prepare_specz_k1000: # Prepare calibration catalogues {{{
  @specz_cat                   #Copy the specz catalogue to the DATAHEAD 
  use_adapt_mag                #Convert the magnitudes to adapted magnitudes 
  .ensure_ldac                 #Ensure that the calibration catalogue is LDAC compatible
  .gaapflag_selection_kv450    #Select the sources with GAAPFLAG 0 values
  .column_reduction            #Keep only columns that we need for CosmoPipe
  add_prior_weights            #Add the weights to correct for prior volume shift
  .add_psf_radius              #Add PSF Radius information 
  .add_aper_ratio_kv450        #Add GAaP aperture B/A ratio 
  !specz_adapt                 #Save the specz adapt catalogue to data block 
  tomography                   #Apply tomography to calibration catalogue
  !specz_adapt_tomo            #Save specz adapt tomographic catalogue to data block 
  @                            #Clear the DATAHEAD 
#}}}

.lensfit_magnitude_selection: #Select only sources within the lensfit magnitude limits {{{
  #NB: These limits are also defined in the BV:MAGTHRESH variable! 
  +FILTERCOND=(@BV:REFMAGNAME@>=20)&(@BV:REFMAGNAME@<=25.5)
  ldacfilter                      #Filter the catalogues 
#}}}

.add_psf_radius: #Add the per-pointing PSF radius information to the catalogue {{{
  +STATNAME=PSF_RAD                #Inherit the PSF_RAD for lensfit matching 
  +STATFUNC=                       #No modification function required 
  +HPMAPFILE=/net/home/fohlen11/awright/KiDS/Legacy/Production/KiDS/mosaic_maps/PSF_RAD_r_1024.fits 
  stat_from_map                    #Inherit the statistic 
#}}}

.add_aper_ratio: #Add the GAaP Aperture ratio information to the catalogue {{{
  +CALCCOND=Bgaper/Agaper         #Compute the aperture ellipticity 
  +CALCCOLNAME=BAgaper             #Name the column
  +CALCCOMM="B/A GAaP Aperture"    #Comment for the new column 
  ldaccalc                         #Compute the new column 
#}}}

.add_aper_ratio_kv450: #Add the GAaP Aperture ratio information to the catalogue {{{
  +CALCCOND=Bgaper_r/Agaper_r      #Compute the aperture ellipticity 
  +CALCCOLNAME=BAgaper             #Name the column
  +CALCCOMM="B/A GAaP Aperture"    #Comment for the new column 
  ldaccalc                         #Compute the new column 
#}}}

.specz_inherit_weight: #Inherit the BV:LABELNAME weight from DB:main_allweight to DB:specz_adapt {{{
  +LABELNAME=@BV:WEIGHTNAME@       #We want to inherit the shape weight 
  +DATAFEAT_OLD=@BV:DATAFEATURES@                           #Save the previous data features 
  +DATAFEATURES="MAG_AUTO FLUX_RADIUS BAgaper Z_B PSF_RAD"  #Define the matching features 
  @main_allweight                  #Use the main catalogues **before removal of zero weight sources** as the base to get the lensfit weight
  +KEEPSTRINGS="unique tile_label run_id flag_ Level ^R$ MAG_GAAP_ MAG_AUTO ALPHA_ DELTA_ RAJ2000 DECJ2000 ^FLUX_RADIUS$ ^PSF_Q ^Agaper ^Bgaper ^RA_ ^DEC_ ^X_ ^Y_ e1 e2 weight scalelength SNR SNratio variance g1 g2 ^T_B$ ^Z_B$ redshift ^z_ zspec zbest ^SeqNr$ ^FIELD_POS$ Xpos Ypos ^W$ ^bulge_fraction ^BAgaper$ ^PSF_RAD$"  #(Partial-)Matching columns are kept, case-insensitive  
  ldackeepcols        #Remove non-matching columns 
  combine_patch                    #Combine patches into a single catalogue 
  !match_base                      #Assign this combined catalogue to match_base 
  @specz_adapt                     #Inherit lensfit weight into the tomographic catalogues 
  assign_matching_label            #Perform the label inheritence 
  +LABELNAME=@BV:BULGEFRACNAME@    #We want to inherit the bulge_fraction as well  
  assign_matching_label            #Perform the label inheritence 
  +CALCCOND=@BV:WEIGHTNAME@*PriorWeight                     #Merge the two weights 
  +CALCCOLNAME=@BV:WEIGHTNAME@_wPV                          #Include the PV label in the column name 
  +CALCCOMM="Combined calibration weight (priorVol+shape)"  #Comment for the new column 
  ldaccalc                                                  #Compute the new column 
  +DATAFEATURES=@BV:DATAFEAT_OLD@                           #Restore the data features 
  !specz_adapt                     #Save the result back to specz_adapt
  -match_base                      #Delete the match_base catalogue 
#}}}

.specz_inherit_weight_allblinds: #Inherit the BV:LABELNAME weight from DB:main_allweight to DB:specz_adapt {{{
  +DATAFEAT_OLD=@BV:DATAFEATURES@  #Save the previous data features 
  +BLIND_OLD=@BV:BLIND@            #Save the previous data features 
  +DATAFEATURES="MAG_AUTO FLUX_RADIUS BAgaper Z_B PSF_RAD"  #Define the matching features 
  @main_allweight                  #Use the main catalogues **before removal of zero weight sources** as the base to get the lensfit weight
  +KEEPSTRINGS="unique tile_label run_id flag_ Level ^R$ MAG_GAAP_ MAG_AUTO ALPHA_ DELTA_ RAJ2000 DECJ2000 ^FLUX_RADIUS$ ^PSF_Q ^Agaper ^Bgaper ^RA_ ^DEC_ ^X_ ^Y_ e1 e2 weight scalelength SNR SNratio variance g1 g2 ^T_B$ ^Z_B$ redshift ^z_ zspec zbest ^SeqNr$ ^FIELD_POS$ Xpos Ypos ^W$ ^bulge_fraction ^BAgaper$ ^PSF_RAD$"  #(Partial-)Matching columns are kept, case-insensitive  
  ldackeepcols        #Remove non-matching columns 
  combine_patch                    #Combine patches into a single catalogue 
  !match_base                      #Assign this combined catalogue to match_base 
  @specz_adapt                     #Inherit lensfit weight into the tomographic catalogues 
  +BLIND=A
  +LABELNAME=@BV:WEIGHTNAME@       #We want to inherit the shape weight 
  assign_matching_label            #Perform the label inheritence 
  +CALCCOND=@BV:WEIGHTNAME@*PriorWeight                     #Merge the two weights 
  +CALCCOLNAME=@BV:WEIGHTNAME@_wPV                          #Include the PV label in the column name 
  +CALCCOMM="Combined calibration weight (priorVol+shape)"  #Comment for the new column 
  ldaccalc                                                  #Compute the new column 
  #+BLIND=B
  #+LABELNAME=@BV:WEIGHTNAME@       #We want to inherit the shape weight 
  #assign_matching_label            #Perform the label inheritence 
  #+CALCCOND=@BV:WEIGHTNAME@*PriorWeight                     #Merge the two weights 
  #+CALCCOLNAME=@BV:WEIGHTNAME@_wPV                          #Include the PV label in the column name 
  #+CALCCOMM="Combined calibration weight (priorVol+shape)"  #Comment for the new column 
  #ldaccalc                                                  #Compute the new column 
  +BLIND=C
  +LABELNAME=@BV:WEIGHTNAME@       #We want to inherit the shape weight 
  assign_matching_label            #Perform the label inheritence 
  +CALCCOND=@BV:WEIGHTNAME@*PriorWeight                     #Merge the two weights 
  +CALCCOLNAME=@BV:WEIGHTNAME@_wPV                          #Include the PV label in the column name 
  +CALCCOMM="Combined calibration weight (priorVol+shape)"  #Comment for the new column 
  ldaccalc                                                  #Compute the new column 
  !specz_adapt                     #Save the result back to specz_adapt
  +DATAFEATURES=@BV:DATAFEAT_OLD@  #Restore the data features 
  +BLIND=@BV:BLIND_OLD@            #Restore the data features 
  -match_base                      #Delete the match_base catalogue 
#}}}

.sim_specz_inherit_weight: #Inherit the BV:LABELNAME weight from DB:main_allweight to DB:specz_adapt_tomo {{{
  #Phase 3b: inherit lensfit weight into simulated calibration data & merge with prior volume weight 
  +LABELNAME=@BV:WEIGHTNAME@                                #Label to inherit is the recalibrated weight 
  #Currently just use simulation shape weight 
  +DATAFEAT_OLD=@BV:DATAFEATURES@                           #Save the previous data features 
  +DATAFEATURES="MAG_AUTO FLUX_RADIUS BAgaper Z_B PSF_RAD"  #Define the matching features 
  @sims_all                  #Use the sim main catalogues **before removal of zero weight sources** as the base to get the lensfit weight
  +NREPL=@BV:NSPLITKEEP@     #-> replicate for the number of spatial splits 
  +LINKREPL=TRUE
  replicate_datahead         #-> replicate in block order (so keeping tomographic ordering: 1,2,3,...,1,2,3)
  !match_base                #Assign this combined catalogue to match_base 
  @sims_specz                #Inherit lensfit weight into the non-tomographic catalogues 
  assign_matching_label      #Perform the label inheritence 
  +CALCCOND=@BV:WEIGHTNAME@*PriorWeight                     #Merge the two weights 
  +CALCCOLNAME=@BV:WEIGHTNAME@_wPV                          #Include the PV label in the column name 
  +CALCCOMM="Combined calibration weight (priorVol+shape)"  #Comment for the new column 
  ldaccalc                                                  #Compute the new column 
  !sims_specz                #Save the result back to sims_specz
  tomography                 #Apply tomography to calibration catalogue
  !sims_specz_tomo           #Save specz adapt tomographic catalogue to data block 
  -match_base                #Delete the match_base catalogue 
#}}}

.sim_specz_noinherit_weight: #Inherit the BV:LABELNAME weight from DB:main_allweight to DB:specz_adapt_tomo {{{
  #Phase 3b: incorporate lensfit weight into simulated calibration data & merge with prior volume weight 
  #Currently just use simulation shape weight as measured 
  @sims_specz                #Inherit lensfit weight into the non-tomographic catalogues 
  +CALCCOND=@BV:WEIGHTNAME@*PriorWeight                     #Merge the two weights 
  +CALCCOLNAME=@BV:WEIGHTNAME@_wPV                          #Include the PV label in the column name 
  +CALCCOMM="Combined calibration weight (priorVol+shape)"  #Comment for the new column 
  ldaccalc                                                  #Compute the new column 
  !sims_specz                #Save the result back to sims_specz
  tomography                 #Apply tomography to calibration catalogue
  !sims_specz_tomo           #Save specz adapt tomographic catalogue to data block 
#}}}

.delete_chip: #{{{
  +FILTERCOND='((Xpos<14500)|(Xpos>18000)|(Ypos<5500)|(Ypos>11000))' #Remove chip
  ldacfilter                      #Filter the catalogue to this subset 
#}}}

.delete_inconsistent_exposures: #{{{
  !temp_storage             #Apply these functions to the current DATAHEAD
  +LABELNAME=maxSep
  #+INPUTS=/net/home/fohlen13/awright/KiDS/Legacy/SelectionTests/onsky_stats/all_delta_sep_statsmooth_maxSep_wcs.asc
  #+FILTERCOND="(maxSep<=0.15)&(maxSep!=-999)"   #Delta sep is in arcsec 
  +INPUTS=/net/home/fohlen13/awright/KiDS/Legacy/SelectionTests/onsky_stats/all_delta_radec_statsmooth_maxSep_smooth_wcs.asc
  #+FILTERCOND="(maxSep<=0.00004167)&(maxSep!=-999)"    #Delta RADec is in degrees 
  +FILTERCOND="(maxSep<=@BV:SELTHRESH@)&(maxSep!=-999)"    #Delta RADec is in degrees 
  add_head
  !maskfile
  !match_base    
  @temp_storage
  assign_matching_label_onsky
  ldacfilter          #Filter the catalogue to this subset 
                      #Final result is also in the DATAHEAD 
  -temp_storage
  -match_base
#}}}
#
.delete_inconsistent_exposures_flip: #{{{
  !temp_storage             #Apply these functions to the current DATAHEAD
  +LABELNAME=maxSep_flip
  +INPUTS=/net/home/fohlen13/awright/KiDS/Legacy/SelectionTests/onsky_stats/all_delta_radec_statsmooth_maxSep_smooth_wcs_RAND.asc
  +FILTERCOND="(@BV:LABELNAME@<=@BV:SELTHRESH@)&(@BV:LABELNAME@!=-999)"    #Delta RADec is in degrees 
  add_head
  !maskfile
  !match_base    
  @temp_storage
  assign_matching_label_onsky
  ldacfilter          #Filter the catalogue to this subset 
                      #Final result is also in the DATAHEAD 
  -temp_storage
  -match_base
#}}}
#
#.delete_unmatched_exposures: #{{{
#  +LABELNAME=maxSep
#  +INPUTS=/net/home/fohlen13/awright/KiDS/Legacy/SelectionTests/onsky_stats/all_maxSep_smooth_wcs.asc
#  add_head
#  !maskfile
#  @maskfile
#  !match_base    
#  %main_all_gold-main_all_gold_predem
#  @main_all_gold_predem
#  RESUME
#  assign_matching_label_onsky
#  !main_all_gold_dem
#  +FILTERCOND=(maxSep!=-999) 
#  ldacfilter          #Filter the catalogue to this subset 
#  !main_all_gold
##}}}
#
.delete_inconsistent_astrom: #{{{
  !temp_storage             #Apply these functions to the current DATAHEAD
  +LABELNAME=sep
  +INPUTS=/net/home/fohlen13/awright/KiDS/Legacy/SelectionTests/astrometric_offset/all_astrom_sep.asc
  add_head
  !maskfile
  !match_base    
  @temp_storage
  assign_matching_label_onsky
  +FILTERCOND="(sep<=0.6)&(sep!=-999)"
  ldacfilter          #Filter the catalogue to this subset 
                      #Final result is also in the DATAHEAD 
  -temp_storage
  -match_base
#}}}
#
#.delete_inconsistent_autocal: #{{{
#  +LABELNAME=dem_MASK
#  +INPUTS=/net/home/fohlen13/awright/KiDS/Legacy/SelectionTests/dem_masks/all_dem_mask.asc
#  add_head
#  !maskfile
#  @maskfile
#  !match_base    
#  %main_all_gold-main_all_gold_predem
#  @main_all_gold_predem
#  assign_matching_label_onsky
#  !main_all_gold_dem
#  +FILTERCOND=(dem_MASK==0) 
#  ldacfilter          #Filter the catalogue to this subset 
#  !main_all_gold
##}}}
.delete_inconsistent_autocal: #{{{
  !temp_storage             #Apply these functions to the current DATAHEAD
  +LABELNAME=dem_MASK
  +INPUTS=/net/home/fohlen13/awright/KiDS/Legacy/SelectionTests/dem_masks/all_dem_mask.asc
  add_head
  !maskfile
  !match_base    
  @temp_storage
  assign_matching_label_onsky
  +FILTERCOND=(dem_MASK==0) 
  ldacfilter          #Filter the catalogue to this subset 
                      #Final result is also in the DATAHEAD 
  -temp_storage
  -match_base
#}}}
.delete_unmatched_autocal: #{{{
  !temp_storage             #Apply these functions to the current DATAHEAD
  +LABELNAME=dem_MASK
  +INPUTS=/net/home/fohlen13/awright/KiDS/Legacy/SelectionTests/dem_masks/all_dem_mask.asc
  add_head
  !maskfile
  !match_base    
  @temp_storage
  assign_matching_label_onsky
  +FILTERCOND=(dem_MASK!=-999) 
  ldacfilter          #Filter the catalogue to this subset 
                      #Final result is also in the DATAHEAD 
  -temp_storage
  -match_base
#}}}
#
##.delete_unmatched_autocal: #{{{
#  +LABELNAME=dem_MASK
#  +INPUTS=/net/home/fohlen13/awright/KiDS/Legacy/SelectionTests/dem_masks/all_dem_mask.asc
#  add_head
#  !maskfile
#  @maskfile
#  !match_base    
#  %main_all_gold-main_all_gold_predem
#  @main_all_gold_predem
#  assign_matching_label_onsky
#  !main_all_gold_dem
#  +FILTERCOND=(dem_MASK!=-999) 
#  ldacfilter          #Filter the catalogue to this subset 
#  !main_all_gold
##}}}
#
##.delete_unmatched_psf: #{{{
#  +LABELNAME=dem_MASK
#  +INPUTS=/net/home/fohlen13/awright/KiDS/Legacy/SelectionTests/dem_psf_masks/all_dem_psf_mask.asc
#  add_head
#  !maskfile
#  %main_all_gold-main_all_gold_predem
#  @maskfile
#  !match_base    
#  @main_all_gold_predem
#  assign_matching_label_onsky
#  !main_all_gold_dem
#  +FILTERCOND=(dem_MASK!=-999) 
#  ldacfilter          #Filter the catalogue to this subset 
#  !main_all_gold
##}}}
#
##.delete_inconsistent_psf: #{{{
#  +LABELNAME=dem_MASK
#  +INPUTS=/net/home/fohlen13/awright/KiDS/Legacy/SelectionTests/dem_psf_masks/all_dem_psf_mask.asc
#  add_head
#  !maskfile
#  %main_all_gold-main_all_gold_predem
#  @maskfile
#  !match_base    
#  @main_all_gold_predem
#  assign_matching_label_onsky
#  !main_all_gold_dem
#  +FILTERCOND=(dem_MASK==0) 
#  ldacfilter          #Filter the catalogue to this subset 
#  !main_all_gold
##}}}
#
.delete_badchip_pointings: #Delete pointings selected by Konrad {{{
  +FILTERCOND="(((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((THELI_NAME!=\'KIDS_0p0_m30p2\')&(THELI_NAME!=\'KIDS_132p4_2p5\'))&(THELI_NAME!=\'KIDS_135p0_1p5\'))&(THELI_NAME!=\'KIDS_138p0_0p5\'))&(THELI_NAME!=\'KIDS_139p0_0p5\'))&(THELI_NAME!=\'KIDS_13p8_m30p2\'))&(THELI_NAME!=\'KIDS_14p8_m29p2\'))&(THELI_NAME!=\'KIDS_161p4_3p5\'))&(THELI_NAME!=\'KIDS_162p5_3p5\'))&(THELI_NAME!=\'KIDS_162p5_m2p5\'))&(THELI_NAME!=\'KIDS_163p0_m0p5\'))&(THELI_NAME!=\'KIDS_163p5_m2p5\'))&(THELI_NAME!=\'KIDS_165p5_m2p5\'))&(THELI_NAME!=\'KIDS_16p1_m30p2\'))&(THELI_NAME!=\'KIDS_16p5_m32p1\'))&(THELI_NAME!=\'KIDS_16p8_m34p1\'))&(THELI_NAME!=\'KIDS_171p0_0p5\'))&(THELI_NAME!=\'KIDS_172p5_2p5\'))&(THELI_NAME!=\'KIDS_173p5_3p5\'))&(THELI_NAME!=\'KIDS_178p0_1p5\'))&(THELI_NAME!=\'KIDS_179p5_3p5\'))&(THELI_NAME!=\'KIDS_180p0_m0p5\'))&(THELI_NAME!=\'KIDS_181p5_2p5\'))&(THELI_NAME!=\'KIDS_184p0_1p5\'))&(THELI_NAME!=\'KIDS_185p0_1p5\'))&(THELI_NAME!=\'KIDS_187p0_1p5\'))&(THELI_NAME!=\'KIDS_189p0_0p5\'))&(THELI_NAME!=\'KIDS_191p5_m2p5\'))&(THELI_NAME!=\'KIDS_192p5_3p5\'))&(THELI_NAME!=\'KIDS_193p5_3p5\'))&(THELI_NAME!=\'KIDS_194p0_m0p5\'))&(THELI_NAME!=\'KIDS_194p5_m2p5\'))&(THELI_NAME!=\'KIDS_195p5_m3p5\'))&(THELI_NAME!=\'KIDS_1p2_m33p1\'))&(THELI_NAME!=\'KIDS_200p6_2p5\'))&(THELI_NAME!=\'KIDS_202p0_1p5\'))&(THELI_NAME!=\'KIDS_213p6_3p5\'))&(THELI_NAME!=\'KIDS_218p0_0p5\'))&(THELI_NAME!=\'KIDS_218p0_m1p5\'))&(THELI_NAME!=\'KIDS_222p0_0p5\'))&(THELI_NAME!=\'KIDS_222p0_m0p5\'))&(THELI_NAME!=\'KIDS_222p0_m1p5\'))&(THELI_NAME!=\'KIDS_224p0_0p5\'))&(THELI_NAME!=\'KIDS_224p0_m0p5\'))&(THELI_NAME!=\'KIDS_224p6_m2p5\'))&(THELI_NAME!=\'KIDS_225p6_2p5\'))&(THELI_NAME!=\'KIDS_226p0_0p5\'))&(THELI_NAME!=\'KIDS_226p6_2p5\'))&(THELI_NAME!=\'KIDS_227p0_0p5\'))&(THELI_NAME!=\'KIDS_22p8_m29p2\'))&(THELI_NAME!=\'KIDS_230p0_0p5\'))&(THELI_NAME!=\'KIDS_230p0_m0p5\'))&(THELI_NAME!=\'KIDS_233p0_0p5\'))&(THELI_NAME!=\'KIDS_235p7_2p5\'))&(THELI_NAME!=\'KIDS_237p0_m1p5\'))&(THELI_NAME!=\'KIDS_24p2_m30p2\'))&(THELI_NAME!=\'KIDS_26p9_m27p2\'))&(THELI_NAME!=\'KIDS_27p1_m32p1\'))&(THELI_NAME!=\'KIDS_28p0_m31p2\'))&(THELI_NAME!=\'KIDS_28p2_m32p1\'))&(THELI_NAME!=\'KIDS_28p5_m33p1\'))&(THELI_NAME!=\'KIDS_28p8_m30p2\'))&(THELI_NAME!=\'KIDS_29p2_m35p1\'))&(THELI_NAME!=\'KIDS_2p3_m28p2\'))&(THELI_NAME!=\'KIDS_30p9_m33p1\'))&(THELI_NAME!=\'KIDS_329p7_m27p2\'))&(THELI_NAME!=\'KIDS_332p4_m34p1\'))&(THELI_NAME!=\'KIDS_335p2_m28p2\'))&(THELI_NAME!=\'KIDS_336p5_m32p1\'))&(THELI_NAME!=\'KIDS_337p0_m30p2\'))&(THELI_NAME!=\'KIDS_338p1_m35p1\'))&(THELI_NAME!=\'KIDS_338p8_m32p1\'))&(THELI_NAME!=\'KIDS_339p8_m27p2\'))&(THELI_NAME!=\'KIDS_340p4_m30p2\'))&(THELI_NAME!=\'KIDS_342p9_m29p2\'))&(THELI_NAME!=\'KIDS_343p5_m32p1\'))&(THELI_NAME!=\'KIDS_343p9_m30p2\'))&(THELI_NAME!=\'KIDS_344p1_m29p2\'))&(THELI_NAME!=\'KIDS_344p2_m35p1\'))&(THELI_NAME!=\'KIDS_344p4_m34p1\'))&(THELI_NAME!=\'KIDS_345p2_m29p2\'))&(THELI_NAME!=\'KIDS_347p6_m28p2\'))&(THELI_NAME!=\'KIDS_347p7_m27p2\'))&(THELI_NAME!=\'KIDS_348p7_m28p2\'))&(THELI_NAME!=\'KIDS_349p4_m32p1\'))&(THELI_NAME!=\'KIDS_352p9_m32p1\'))&(THELI_NAME!=\'KIDS_354p4_m27p2\'))&(THELI_NAME!=\'KIDS_357p7_m28p2\'))&(THELI_NAME!=\'KIDS_357p7_m30p2\'))&(THELI_NAME!=\'KIDS_358p8_m34p1\'))&(THELI_NAME!=\'KIDS_35p3_m29p2\'))&(THELI_NAME!=\'KIDS_35p7_m30p2\'))&(THELI_NAME!=\'KIDS_35p9_m27p2\'))&(THELI_NAME!=\'KIDS_36p1_m31p2\'))&(THELI_NAME!=\'KIDS_37p3_m31p2\'))&(THELI_NAME!=\'KIDS_39p1_m30p2\'))&(THELI_NAME!=\'KIDS_3p5_m31p2\'))&(THELI_NAME!=\'KIDS_40p3_m30p2\'))&(THELI_NAME!=\'KIDS_41p4_m35p1\'))&(THELI_NAME!=\'KIDS_42p8_m33p1\'))&(THELI_NAME!=\'KIDS_42p9_m28p2\'))&(THELI_NAME!=\'KIDS_47p8_m29p2\'))&(THELI_NAME!=\'KIDS_48p0_m34p1\'))&(THELI_NAME!=\'KIDS_48p6_m35p1\'))&(THELI_NAME!=\'KIDS_49p3_m27p2\'))&(THELI_NAME!=\'KIDS_50p0_m26p2\'))&(THELI_NAME!=\'KIDS_51p1_m35p1\'))&(THELI_NAME!=\'KIDS_5p7_m29p2\'))&(THELI_NAME!=\'KIDS_7p1_m33p1\'))"
  ldacfilter
#}}}

.rename_radec: #{{{
  +OLDKEY=RAJ2000
  +NEWKEY=ALPHA_J2000
  ldacrenkey
  +OLDKEY=DECJ2000
  +NEWKEY=DELTA_J2000
  ldacrenkey
#}}}
#}}}

#SKILLS Simulation {{{ 
.prepare_sims_main_skills: # Prepare simulated calibration catalogues {{{
  .setup_datasim_variables_skills     #Update variables for the data catalogues 
  .use_simulation_variables_skills    #Use Simulation variables 
  @sims_raw                           #Move onto the main catalogues
  .column_reduction_fits              #Do an initial column reduction, because LDAC conversion is slow...
  .ensure_ldac                        #Ensure the main catalogues are ldac compatible 
  !temp_storage
  .rename_skills_iband                #Rename the incorrect i1 labels 
  .column_reduction                   #Keep only columns that we need for CosmoPipe
  +WEIGHTNAME=@BV:WEIGHTNAME_SIM@     #The pre-recalibration weight name 
  run_weight_recal                    #Run the weight recalibration 
  +WEIGHTNAME_SIM=AlphaRecalC_weight  #Use the post-recalibration weight name 
  !sims_all                           #Save all sources catalogue to sims_all
  .skills_lensing_selection           #Perform the SKILLS lensing selection (same as done on data: Wright et al. 2024a)
  !sims_lensing                       #Output full simulated catalogue for calibration sample creation 
  -temp_storage
  @                                   #Clear the DATAHEAD 
#}}}

.skills_lensing_selection:  #Apply the lensing selections to the SKiLLS simulations  {{{
  +FILTERCOND=(flag_gaap+flag_binary+flag_asteroid+flag_LF_noWeiCut==0) 
  ldacfilter          #Filter the catalogue to this subset 
#}}}

.skills_N_selection: # {{{
    +FILTERCOND='((((((((((((((((((((((((((((((((((((((((((((((((((((((@BV:SIMLABEL@!=\"10.3_-29.2\")&(@BV:SIMLABEL@!=\"10.5_-31.2\"))&(@BV:SIMLABEL@!=\"10.6_-32.1\"))&(@BV:SIMLABEL@!=\"10.7_-33.1\"))&(@BV:SIMLABEL@!=\"11.4_-29.2\"))&(@BV:SIMLABEL@!=\"11.5_-30.2\"))&(@BV:SIMLABEL@!=\"11.7_-31.2\"))&(@BV:SIMLABEL@!=\"12.7_-30.2\"))&(@BV:SIMLABEL@!=\"12.8_-31.2\"))&(@BV:SIMLABEL@!=\"332.4_-30.2\"))&(@BV:SIMLABEL@!=\"332.9_-32.1\"))&(@BV:SIMLABEL@!=\"333.2_-31.2\"))&(@BV:SIMLABEL@!=\"333.5_-30.2\"))&(@BV:SIMLABEL@!=\"333.8_-29.2\"))&(@BV:SIMLABEL@!=\"333.9_-33.1\"))&(@BV:SIMLABEL@!=\"334.1_-32.1\"))&(@BV:SIMLABEL@!=\"334.4_-31.2\"))&(@BV:SIMLABEL@!=\"334.7_-30.2\"))&(@BV:SIMLABEL@!=\"334.9_-29.2\"))&(@BV:SIMLABEL@!=\"335.0_-33.1\"))&(@BV:SIMLABEL@!=\"335.3_-32.1\"))&(@BV:SIMLABEL@!=\"335.5_-31.2\"))&(@BV:SIMLABEL@!=\"336.1_-29.2\"))&(@BV:SIMLABEL@!=\"336.2_-33.1\"))&(@BV:SIMLABEL@!=\"336.7_-31.2\"))&(@BV:SIMLABEL@!=\"337.0_-30.2\"))&(@BV:SIMLABEL@!=\"337.6_-32.1\"))&(@BV:SIMLABEL@!=\"43.1_-31.2\"))&(@BV:SIMLABEL@!=\"43.3_-29.2\"))&(@BV:SIMLABEL@!=\"43.5_-32.1\"))&(@BV:SIMLABEL@!=\"43.7_-30.2\"))&(@BV:SIMLABEL@!=\"44.0_-33.1\"))&(@BV:SIMLABEL@!=\"44.3_-31.2\"))&(@BV:SIMLABEL@!=\"44.7_-32.1\"))&(@BV:SIMLABEL@!=\"44.9_-30.2\"))&(@BV:SIMLABEL@!=\"45.1_-33.1\"))&(@BV:SIMLABEL@!=\"45.4_-31.2\"))&(@BV:SIMLABEL@!=\"45.6_-29.2\"))&(@BV:SIMLABEL@!=\"45.9_-32.1\"))&(@BV:SIMLABEL@!=\"46.0_-30.2\"))&(@BV:SIMLABEL@!=\"46.3_-33.1\"))&(@BV:SIMLABEL@!=\"46.6_-31.2\"))&(@BV:SIMLABEL@!=\"46.7_-29.2\"))&(@BV:SIMLABEL@!=\"47.1_-32.1\"))&(@BV:SIMLABEL@!=\"47.2_-30.2\"))&(@BV:SIMLABEL@!=\"8.1_-30.2\"))&(@BV:SIMLABEL@!=\"8.2_-31.2\"))&(@BV:SIMLABEL@!=\"8.2_-32.1\"))&(@BV:SIMLABEL@!=\"8.3_-33.1\"))&(@BV:SIMLABEL@!=\"9.1_-29.2\"))&(@BV:SIMLABEL@!=\"9.2_-30.2\"))&(@BV:SIMLABEL@!=\"9.3_-31.2\"))&(@BV:SIMLABEL@!=\"9.4_-32.1\"))&(@BV:SIMLABEL@!=\"9.5_-33.1\"))'
    ldacfilter

#}}}

.skills_S_selection: #{{{
    +FILTERCOND=((((((((((((((((((((((((((((((((((((((((((((((((((((((@BV:SIMLABEL@=='10.3_-29.2')|(@BV:SIMLABEL@=='10.5_-31.2'))|(@BV:SIMLABEL@=='10.6_-32.1'))|(@BV:SIMLABEL@=='10.7_-33.1'))|(@BV:SIMLABEL@=='11.4_-29.2'))|(@BV:SIMLABEL@=='11.5_-30.2'))|(@BV:SIMLABEL@=='11.7_-31.2'))|(@BV:SIMLABEL@=='12.7_-30.2'))|(@BV:SIMLABEL@=='12.8_-31.2'))|(@BV:SIMLABEL@=='332.4_-30.2'))|(@BV:SIMLABEL@=='332.9_-32.1'))|(@BV:SIMLABEL@=='333.2_-31.2'))|(@BV:SIMLABEL@=='333.5_-30.2'))|(@BV:SIMLABEL@=='333.8_-29.2'))|(@BV:SIMLABEL@=='333.9_-33.1'))|(@BV:SIMLABEL@=='334.1_-32.1'))|(@BV:SIMLABEL@=='334.4_-31.2'))|(@BV:SIMLABEL@=='334.7_-30.2'))|(@BV:SIMLABEL@=='334.9_-29.2'))|(@BV:SIMLABEL@=='335.0_-33.1'))|(@BV:SIMLABEL@=='335.3_-32.1'))|(@BV:SIMLABEL@=='335.5_-31.2'))|(@BV:SIMLABEL@=='336.1_-29.2'))|(@BV:SIMLABEL@=='336.2_-33.1'))|(@BV:SIMLABEL@=='336.7_-31.2'))|(@BV:SIMLABEL@=='337.0_-30.2'))|(@BV:SIMLABEL@=='337.6_-32.1'))|(@BV:SIMLABEL@=='43.1_-31.2'))|(@BV:SIMLABEL@=='43.3_-29.2'))|(@BV:SIMLABEL@=='43.5_-32.1'))|(@BV:SIMLABEL@=='43.7_-30.2'))|(@BV:SIMLABEL@=='44.0_-33.1'))|(@BV:SIMLABEL@=='44.3_-31.2'))|(@BV:SIMLABEL@=='44.7_-32.1'))|(@BV:SIMLABEL@=='44.9_-30.2'))|(@BV:SIMLABEL@=='45.1_-33.1'))|(@BV:SIMLABEL@=='45.4_-31.2'))|(@BV:SIMLABEL@=='45.6_-29.2'))|(@BV:SIMLABEL@=='45.9_-32.1'))|(@BV:SIMLABEL@=='46.0_-30.2'))|(@BV:SIMLABEL@=='46.3_-33.1'))|(@BV:SIMLABEL@=='46.6_-31.2'))|(@BV:SIMLABEL@=='46.7_-29.2'))|(@BV:SIMLABEL@=='47.1_-32.1'))|(@BV:SIMLABEL@=='47.2_-30.2'))|(@BV:SIMLABEL@=='8.1_-30.2'))|(@BV:SIMLABEL@=='8.2_-31.2'))|(@BV:SIMLABEL@=='8.2_-32.1'))|(@BV:SIMLABEL@=='8.3_-33.1'))|(@BV:SIMLABEL@=='9.1_-29.2'))|(@BV:SIMLABEL@=='9.2_-30.2'))|(@BV:SIMLABEL@=='9.3_-31.2'))|(@BV:SIMLABEL@=='9.4_-32.1'))|(@BV:SIMLABEL@=='9.5_-33.1'))
    ldacfilter
#}}}

.rename_skills_iband: #Rename the SKILLS GAaP i-band column {{{
  +OLDKEY=MAG_GAAP_i 
  +NEWKEY=MAG_GAAP_i1 
  ldacrenkey
#}}}
#}}}

#MICE2 Simulations {{{
.prepare_sims_main_mice2: # Prepare simulated catalogues {{{ 
  .setup_datasim_variables_mice2   #Update variables for the data catalogues 
  .use_simulation_variables_mice2  #Use Simulation variables 
  @sims_raw                  #Move onto the main catalogues
  .ensure_ldac               #Ensure the main catalogues are ldac compatible 
  .rename_mice2              #Rename mice2 magnitude names to GAAP names 
  .column_reduction          #Keep only columns that we need for CosmoPipe
  +FILTERCOND=(ra_gal_mag>=32)&(ra_gal_mag<=58)&(dec_gal_mag>=2)&(dec_gal_mag<=70.02)
  ldacfilter 
  !sims_all                  #Save the ldac compatible tables to sims_all 
  .sim_all_inherit_weight_mice2 
  +FILTERCOND=(@BV:WEIGHTNAME_SIM@>0) #Filter the catalogue to remove weight=0 sources 
  ldacfilter                          #Filter the catalogue to this subset 
  !sims_lensing              #... and to sims_lensing, because that is the same for MICE2
  @                          #Clear the DATAHEAD 
#}}}

.sim_all_inherit_weight_mice2: #Inherit the BV:LABELNAME weight from DB:main_allweight to DB:specz_adapt_tomo {{{
  #Phase 3b: inherit lensfit weight into simulated calibration data & merge with prior volume weight 
  +LABELNAME=@BV:WEIGHTNAME@                                #Label to inherit is the recalibrated weight 
  #Currently just use simulation shape weight 
  +DATAFEAT_OLD=@BV:DATAFEATURES@                           #Save the previous data features 
  +DATAFEATURES="MAG_GAAP_u MAG_GAAP_g MAG_GAAP_r MAG_GAAP_i1 MAG_GAAP_i2 MAG_GAAP_Z MAG_GAAP_Y MAG_GAAP_J MAG_GAAP_H MAG_GAAP_Ks Z_B"  #Define the matching features 
  +TOMOBAK=@BV:TOMOLIMS@
  +TOMOLIMS="-0.0025 0.0975 0.1475 0.1975 0.2475 0.2975 0.3475 0.3975 0.4475 0.4975 0.5475 0.5975 0.6475 0.6975 0.7475 0.7975 0.8475 0.8975 0.9475 0.9975 1.0475 1.0975 1.1475 1.1975 1.2475 1.2975 1.3475 1.3975 2.4975"
  @main_allweight                  #Use the main catalogues **before removal of zero weight sources** as the base to get the lensfit weight
  +KEEPSTRINGS="unique tile_label run_id flag_ Level ^R$ MAG_GAAP_ MAG_AUTO ALPHA_ DELTA_ RAJ2000 DECJ2000 ^FLUX_RADIUS$ ^PSF_Q ^Agaper ^Bgaper ^RA_ ^DEC_ ^X_ ^Y_ e1 e2 weight scalelength SNR SNratio variance g1 g2 ^T_B$ ^Z_B$ redshift ^z_ zspec zbest ^SeqNr$ ^FIELD_POS$ Xpos Ypos ^W$ ^bulge_fraction ^BAgaper$ ^PSF_RAD$"  #(Partial-)Matching columns are kept, case-insensitive  
  ldackeepcols        #Remove non-matching columns 
  combine_patch                    #Combine patches into a single catalogue 
  tomography
  !match_base                      #Assign this combined catalogue to match_base 
  @sims_all                  #Inherit lensfit weight into the non-tomographic catalogues 
  #Create fine bins of photoz
  tomography                         #Construct the fine splits 
  +TOMOLIMS=@BV:TOMOBAK@
  assign_matching_label      #Perform the label inheritence 
  combine_cats                        #Combine the main catalogues into a single catalogue 
  !sims_all                  #Save the result back to sims_specz
  -match_base                #Delete the match_base catalogue 
#}}}

.rename_mice2: #Rename the magnitude columns in MICE2 {{{
  +OLDKEY=sdss_u_obs
  +NEWKEY=MAG_GAAP_u
  ldacrenkey
  +OLDKEY=sdss_g_obs
  +NEWKEY=MAG_GAAP_g
  ldacrenkey
  +OLDKEY=sdss_r_obs
  +NEWKEY=MAG_GAAP_r
  ldacrenkey
  +OLDKEY=sdss_i1_obs
  +NEWKEY=MAG_GAAP_i1
  ldacrenkey
  +OLDKEY=sdss_i2_obs
  +NEWKEY=MAG_GAAP_i2
  ldacrenkey
  +OLDKEY=sdss_z_obs
  +NEWKEY=MAG_GAAP_Z
  ldacrenkey
  +OLDKEY=des_asahi_full_y_obs
  +NEWKEY=MAG_GAAP_Y
  ldacrenkey
  +OLDKEY=vhs_j_obs
  +NEWKEY=MAG_GAAP_J
  ldacrenkey
  +OLDKEY=vhs_h_obs
  +NEWKEY=MAG_GAAP_H
  ldacrenkey
  +OLDKEY=vhs_ks_obs
  +NEWKEY=MAG_GAAP_Ks
  ldacrenkey
#}}}

.rename_mice2_mag: #Rename the magnitude columns in MICE2 {{{
  +OLDKEY=sdss_u_obs_mag
  +NEWKEY=MAG_GAAP_u
  ldacrenkey
  +OLDKEY=sdss_g_obs_mag
  +NEWKEY=MAG_GAAP_g
  ldacrenkey
  +OLDKEY=sdss_r_obs_mag
  +NEWKEY=MAG_GAAP_r
  ldacrenkey
  +OLDKEY=sdss_i_obs_mag
  +NEWKEY=MAG_GAAP_i1
  ldacrenkey
  +OLDKEY=sdss_z_obs_mag
  +NEWKEY=MAG_GAAP_Z
  ldacrenkey
  +OLDKEY=des_asahi_full_y_obs_mag
  +NEWKEY=MAG_GAAP_Y
  ldacrenkey
  +OLDKEY=vhs_j_obs_mag
  +NEWKEY=MAG_GAAP_J
  ldacrenkey
  +OLDKEY=vhs_h_obs_mag
  +NEWKEY=MAG_GAAP_H
  ldacrenkey
  +OLDKEY=vhs_ks_obs_mag
  +NEWKEY=MAG_GAAP_Ks
  ldacrenkey
#}}}
#}}}

#PAUS Specz compilation {{{
.specz_selection_paus: #Select sources with valid GAAPFlag {{{
  +FILTERCOND=z_Flag>=3
  ldacfilter                      #Filter the catalogues 
#}}}
#}}}
#}}}

#Matching Functions {{{ 
.match_sim_to_main: # Match the simulated catalogue to the wide-field sample {{{
  #Matching Stage 1a: Match sims to data using Z_B & colours, after lensing selections
  @sims_lensing                      #Use the lensing selected sample (!)
  !match_base                        #-> set as matching base 
  #Construct the features lists for matching between data & simulation  
  +ZSPECDATA=@BV:ZPHOTNAME@          #Match on photo-z 
  +ZSPECSIM=@BV:ZPHOTNAME@           #Match on photo-z 
  +WEIGHTNAME=@BV:WEIGHTNAME_SIM@    #Weight to add frequency weights to 
  @main_all                          #set the main -> set a matching target 
  +NREPL=@BV:NSIM@                   #-> replicate for the number of spatial splits 
  +LINKREPL=FALSE
  replicate_datahead                 #-> replicate in block order (so keeping tomographic ordering: 1,2,3,...,1,2,3)
  add_repr_weights                   #Run the matching 
  .ensure_ldac                       #Convert the matched catalogue to LDAC 
  #%match_base-stage1a_match_base    #Rename the match_base, to avoid confustion with stage 2 matching base 
  -match_base                        #Rename the match_base, to avoid confustion with stage 2 matching base 

  #Construct the sims main catalogues from the post-matched catalogue 
  !sims_main_rwgt                     #Save the lensing-selected catalogue to skills_main
  combine_cats                        #Combine the main catalogues into a single catalogue 
  !sims_main_comb                     #Save the combined catalogue to skills_main_comb
  +WEIGHTNAME=@BV:WEIGHTNAME_SIM@     #The pre-recalibration weight name 
  +FILTERCOND=(@BV:WEIGHTNAME_SIM@>0) #Filter the catalogue to remove weight=0 sources 
  ldacfilter                          #Filter the catalogue to this subset 
  !sims_main                          #Save the ldac compatible tables to skills_main_rwgt
  tomography                          #Tomographically bin the main catalogues 
  !sims_main_tomo                     #Save the tomographic main catalogues to skills_main_rwgt_tomo
  -sims_main_rwgt
  -sims_main_comb
  @                                   #Clear the DATAHEAD 
#}}}

.match_sim_to_main_nocomb: # Match the simulated catalogue to the wide-field sample {{{
  #Matching Stage 1a: Match sims to data using Z_B & colours, after lensing selections
  @sims_lensing                      #Use the lensing selected sample (!)
  !match_base                        #-> set as matching base 
  #Construct the features lists for matching between data & simulation  
  +ZSPECDATA=@BV:ZPHOTNAME@          #Match on photo-z 
  +ZSPECSIM=@BV:ZPHOTNAME@           #Match on photo-z 
  +WEIGHTNAME=@BV:WEIGHTNAME_SIM@    #Weight to add frequency weights to 
  @main_all                          #set the main -> set a matching target 
  +NREPL=@BV:NSIM@                   #-> replicate for the number of spatial splits 
  +LINKREPL=FALSE
  replicate_datahead                 #-> replicate in block order (so keeping tomographic ordering: 1,2,3,...,1,2,3)
  add_repr_weights                   #Run the matching 
  .ensure_ldac                       #Convert the matched catalogue to LDAC 
  #%match_base-stage1a_match_base    #Rename the match_base, to avoid confustion with stage 2 matching base 
  -match_base                        #Rename the match_base, to avoid confustion with stage 2 matching base 

  #Construct the sims main catalogues from the post-matched catalogue 
  !sims_main_rwgt                     #Save the lensing-selected catalogue to skills_main
  +WEIGHTNAME=@BV:WEIGHTNAME_SIM@     #The pre-recalibration weight name 
  +FILTERCOND=(@BV:WEIGHTNAME_SIM@>0) #Filter the catalogue to remove weight=0 sources 
  ldacfilter                          #Filter the catalogue to this subset 
  !sims_main                          #Save the ldac compatible tables to skills_main_rwgt
  tomography                          #Tomographically bin the main catalogues 
  !sims_main_tomo                     #Save the tomographic main catalogues to skills_main_rwgt_tomo
  -sims_main_rwgt
  @                                   #Clear the DATAHEAD 
#}}}

.match_sim_to_main_mice2: # Match the simulated catalogue to the wide-field sample {{{
  #Matching Stage 1a: Match sims to data using Z_B & colours, after lensing selections
  +TOMOBAK=@BV:TOMOLIMS@
  #Create fine bins of photoz
  +TOMOLIMS="-0.0025 0.0975 0.1475 0.1975 0.2475 0.2975 0.3475 0.3975 0.4475 0.4975 0.5475 0.5975 0.6475 0.6975 0.7475 0.7975 0.8475 0.8975 0.9475 0.9975 1.0475 1.0975 1.1475 1.1975 1.2475 1.2975 1.3475 1.3975 2.4975"
  @sims_lensing                      #Use the lensing selected sample (!)
  tomography                         #Construct the fine splits 
  !match_base                        #-> set as matching base 
  #Construct the features lists for matching between data & simulation  
  +ZSPECDATA=@BV:ZPHOTNAME@          #Match on photo-z 
  +ZSPECSIM=@BV:ZPHOTNAME@           #Match on photo-z 
  +WEIGHTNAME=@BV:WEIGHTNAME_SIM@    #Weight to add frequency weights to 
  @main_all                          #set the main -> set a matching target 
  tomography                         #Construct the fine splits 
  +TOMOLIMS=@BV:TOMOBAK@             #Replace the tomographic bin limits 
  +NREPL=@BV:NSIM@                   #-> replicate for the number of spatial splits 
  +LINKREPL=FALSE
  replicate_datahead                 #-> replicate in block order (so keeping tomographic ordering: 1,2,3,...,1,2,3)
  add_repr_weights                   #Run the matching 
  .ensure_ldac                       #Convert the matched catalogue to LDAC 
  combine_cats                       #Recombine the fine splits 
  %match_base-stage1a_match_base     #Rename the match_base, to avoid confustion with stage 2 matching base 

  #Construct the sims main catalogues from the post-matched catalogue 
  !sims_main_rwgt                     #Save the lensing-selected catalogue to skills_main
  combine_cats                        #Combine the main catalogues into a single catalogue 
  !sims_main_comb                     #Save the combined catalogue to skills_main_comb
  +WEIGHTNAME=@BV:WEIGHTNAME_SIM@     #The pre-recalibration weight name 
  +FILTERCOND=(@BV:WEIGHTNAME_SIM@>0) #Filter the catalogue to remove weight=0 sources 
  ldacfilter                          #Filter the catalogue to this subset 
  !sims_main                          #Save the ldac compatible tables to skills_main_rwgt
  tomography                          #Tomographically bin the main catalogues 
  !sims_main_tomo                     #Save the tomographic main catalogues to skills_main_rwgt_tomo
  @                                   #Clear the DATAHEAD 
#}}}

.match_sim_to_calib: # Match the simulated catalogue to the specz calibration sample {{{
  @sims_all                          #Use the non-lensing selected sample (!)
  !match_base                        #-> set as matching base 
  +ZSPECDATA=@BV:ZPHOTNAME@          #Match on Z_B
  +ZSPECSIM=@BV:ZPHOTNAME@           #Match on Z_B
  +WEIGHTNAME=                       #Calibration data have no weights 
  @specz_adapt                       #set the main -> set a matching target 
  +NREPL=@BV:NSIM@                   #-> replicate for the number of simulated catalogues 
  +LINKREPL=FALSE
  replicate_datahead                 #-> replicate in block order (so keeping tomographic ordering: 1,2,3,...,1,2,3)
  add_repr_weights                   #Run the matching 
  .ensure_ldac                       #Convert the matched catalogue to LDAC 
  #%match_base-stage1a_speczmatch_base #Rename the match_base, to avoid confustion with stage 2 matching base 
  -match_base                        #Delete the match_base

  #Construct the sims calib catalogues from the post-matched catalogue 
  !sims_calib_rwgt              
  spatial_split                   #-> perform spatial splits 
  tomography                      #-> tomography on spatial splits 
  !match_base                     #-> set as matching base 
  #Construct the features lists for matching between data & simulation  
  +ZSPECDATA=@BV:ZSPECDATAKEEP@   #Match on zspec
  +ZSPECSIM=@BV:ZSPECSIMKEEP@     #Match on zspec
  +WEIGHTNAME=repr_weight         #Use the representation weights 
  @specz_adapt_tomo               #set the tomographic calibration sample as matching target 
  +NREPL=@BV:NSIM@                #-> replicate for the number of shear realisations 
  +LINKREPL=FALSE                 #Catalogues are overwritten; replicate as files 
  replicate_datahead              #-> replicate in block order (so keeping tomographic ordering: 1,2,3,...,1,2,3)
  +NREPL=@BV:NSPLITKEEP@          #-> replicate for the number of spatial splits 
  replicate_datahead              #-> replicate in block order (so keeping tomographic ordering: 1,2,3,...,1,2,3)
  match_to_sims                   #Run the matching 
  .ensure_ldac                    #Convert the matched catalogue to LDAC
  combine_tomocats                #Combine the tomographic catalogues
  add_prior_weights               #Add the weights to correct for prior volume shift
  !sims_specz                     #Save the non-tomographic matched catalogue
  tomography                      #Perform tomographic binning 
  !sims_specz_tomo                #Save the output matched LDAC file
  #%match_base-stage2_match_base   #Rename the match_base, to avoid confustion with stage 1 matching base 
  -match_base                        #Delete the match_base
  -sims_calib_rwgt
  @                               #Clear the DATAHEAD 
#}}}

.match_sim_to_calib_mice2: # Match the simulated catalogue to the specz calibration sample {{{
  @sims_all                          #Use the non-lensing selected sample (!)
  +TOMOBAK=@BV:TOMOLIMS@
  #Create fine bins of photoz
  +TOMOLIMS="-0.0025 0.0975 0.1475 0.1975 0.2475 0.2975 0.3475 0.3975 0.4475 0.4975 0.5475 0.5975 0.6475 0.6975 0.7475 0.7975 0.8475 0.8975 0.9475 0.9975 1.0475 1.0975 1.1475 1.1975 1.2475 1.2975 1.3475 1.3975 2.4975"
  tomography
  !match_base                        #-> set as matching base 
  +ZSPECDATA=@BV:ZPHOTNAME@          #Match on Z_B
  +ZSPECSIM=@BV:ZPHOTNAME@           #Match on Z_B
  +WEIGHTNAME=                       #Calibration data have no weights 
  @specz_adapt                       #set the main -> set a matching target 
  tomography
  +TOMOLIMS=@BV:TOMOBAK@             #Replace the tomographic bin limits 
  +NREPL=@BV:NSIM@                   #-> replicate for the number of simulated catalogues 
  +LINKREPL=FALSE
  replicate_datahead                 #-> replicate in block order (so keeping tomographic ordering: 1,2,3,...,1,2,3)
  add_repr_weights                   #Run the matching 
  .ensure_ldac                       #Convert the matched catalogue to LDAC 
  combine_cats
  #%match_base-stage1a_speczmatch_base #Rename the match_base, to avoid confustion with stage 2 matching base 
  -match_base                        #Delete the match_base

  #Construct the sims calib catalogues from the post-matched catalogue 
  !sims_calib_rwgt              
  spatial_split                   #-> perform spatial splits 
  tomography                      #-> tomography on spatial splits 
  !match_base                     #-> set as matching base 
  #Construct the features lists for matching between data & simulation  
  +ZSPECDATA=@BV:ZSPECDATAKEEP@   #Match on zspec
  +ZSPECSIM=@BV:ZSPECSIMKEEP@     #Match on zspec
  +WEIGHTNAME=repr_weight         #Use the representation weights 
  @specz_adapt_tomo               #set the tomographic calibration sample as matching target 
  +NREPL=@BV:NSIM@                #-> replicate for the number of shear realisations 
  +LINKREPL=FALSE                 #Catalogues are overwritten; replicate as files 
  replicate_datahead              #-> replicate in block order (so keeping tomographic ordering: 1,2,3,...,1,2,3)
  +NREPL=@BV:NSPLITKEEP@          #-> replicate for the number of spatial splits 
  replicate_datahead              #-> replicate in block order (so keeping tomographic ordering: 1,2,3,...,1,2,3)
  match_to_sims                   #Run the matching 
  .ensure_ldac                    #Convert the matched catalogue to LDAC
  combine_tomocats                #Combine the tomographic catalogues
  add_prior_weights               #Add the weights to correct for prior volume shift
  !sims_specz                     #Save the non-tomographic matched catalogue
  tomography                      #Perform tomographic binning 
  !sims_specz_tomo                #Save the output matched LDAC file
  #%match_base-stage2_match_base   #Rename the match_base, to avoid confustion with stage 1 matching base 
  -match_base                        #Delete the match_base
  @                               #Clear the DATAHEAD 
#}}}

.trim_skills_to_mice2: #Truncate the skills simulations to the limits of MICE2 {{{
  +FILTERCOND='(redshift_input>=0.073)&(redshift_input<=1.42)"
  @sims_lensing
  ldacfilter
  !sims_lensing
  @sims_all
  ldacfilter
  !sims_all
#}}}

.remove_stars: #Truncate the skills simulations to the limits of MICE2 {{{
  +FILTERCOND='(redshift_input>=0)"
  @sims_lensing
  ldacfilter
  !sims_lensing
  @sims_all
  ldacfilter
  !sims_all
#}}}
#}}} 

#Nz Calibration {{{
.add_dz_calib: #Add the dz priors estimated previously {{{
  add_nzbias                      #Add preexisting Nz bias to the datablock 
  add_nzcov                       #Add preexisting Nz covariance matrix to the datablock 
  decorrelate_nzbias              #Compute the decorrelated Nz bias priors 
#}}}

.goldweight_dz_calib: #Compute the dz priors using simulations {{{
  +FEATURETYPES=ALLCOLOUR+MAG                 #Features to use for the SOM construction 
  +OPTIMISE=                                    #Optimise the number of HCs
  +SOMDIM="51 51" 
  +NITER=100 
  get_features                                  #Add the SOM feature list variable to the data block
  @sims_specz_tomo                              #Start with the calibration catalogues 
  +NREPL=@BV:NSOM_GOLDWEIGHT@                   #Compute the goldclass NSOM_GOLDWEIGHT times 
  +LINKREPL=FALSE                               #Catalogues are not overwritten: replicate as links 
  replicate_datahead                            #Replicate the datahead 
  construct_som                                 #Construct a SOM for each calibration catalogue  
  !sim_tomo_som                                 #Save the SOM(s) to sim_som
  @sims_specz_tomo                              #Assign the tomographic sim specz sample as the calibrators 
  .lensfit_magnitude_selection                  #Select spectra with appropriate MAG_AUTO 
  +NREPL=@BV:NSOM_GOLDWEIGHT@                   #There are NSOM_GOLDWEIGHT SOMs per catalogue 
  +LINKREPL=TRUE                                #Catalogues are not overwritten: replicate as links 
  replicate_datahead                            #Replicate the datahead 
  !som_weight_training                          # ^^
  @sims_main_tomo                               #Assign the tomographic shear sample as the targets
  +NREPL=@BV:NSIM@                              #There are NSIM*NSPLIT*NSOM_GOLDWEIGHT calibration catalogues 
  +LINKREPL=TRUE                                #Catalogues are not overwritten: replicate as links 
  replicate_datahead                            #Replicate the datahead 
  !intermediate_one
  +NREPL=@BV:NSPLITKEEP@                        #There are NSIM*NSPLITKEEP*NSOM_GOLDWEIGHT calibration catalogues
  +LINKREPL=TRUE                                #Catalogues are not overwritten: replicate as links 
  replicate_datahead                            #Replicate the datahead 
  !intermediate_two
  +NREPL=@BV:NSOM_GOLDWEIGHT@                   #There are NSIM*NSPLIT*NSOM_GOLDWEIGHT calibration catalogues
  +LINKREPL=TRUE                                #Catalogues are not overwritten: replicate as links 
  replicate_datahead                            #Replicate the datahead 
  !som_weight_reference                         # ^^
  @sim_tomo_som                                 #Use the SOMs that we calculated above 
  get_features                                  #Add the SOM feature list variable to the data block
  compute_nz_weights                            #Compute the SOM Nz weights 
  merge_goldweight                              #Re-merge the tomographic catalogues 
  construct_nz                                  #Construct the goldweighted Nz 
  compute_dz_priors                             #Compute the dz bias priors from the results 
  decorrelate_nzbias                            #Compute the decorrelated Nz bias priors 
  @nzbias_NS !nzbias @nzcov_NS !nzcov
  %som_weight_reference-sims_main_tomo_input    #Save the main sample inputs to sims_main_tomo_input
  %som_weight_training-sims_specz_tomo_input    #Save the calibration inputs to sims_specz_tomo_input
  %som_weight_refr_cats-sims_main_tomo_out      #Save the main sample outputs to sims_main_tomo_out 
  %som_weight_refr_gold-sims_main_tomo_gold     #Save the main sample gold sample to sims_main_tomo_gold 
  %som_weight_calib_cats-sims_specz_tomo_out    #Save the calibration outputs to sims_specz_tomo_out
  %som_weight_calib_gold-sims_specz_tomo_gold   #Save the calibration outputs to sims_specz_tomo_gold 
  %nz_NS-nz_sims                                #Save the Nz to nz_sims 
  @sims_main_tomo_gold                          #Load the resulting gold catalogues 
  combine_tomocats                              #Re-merge the tomographic catalogues 
  !sims_main_gold                               #Save the gold catalogue as main_all_gold 
  @                                             #Clear the DATAHEAD 
#}}}

.goldweight_dz_calib_nocomb: #Compute the dz priors using simulations {{{
  +FEATURETYPES=ALLCOLOUR+MAG                 #Features to use for the SOM construction 
  +OPTIMISE=                                    #Optimise the number of HCs
  +SOMDIM="51 51" 
  +NITER=100 
  get_features                                  #Add the SOM feature list variable to the data block
  @sims_specz_tomo                              #Start with the calibration catalogues 
  +NREPL=@BV:NSOM_GOLDWEIGHT@                   #Compute the goldclass NSOM_GOLDWEIGHT times 
  +LINKREPL=FALSE                               #Catalogues are not overwritten: replicate as links 
  replicate_datahead                            #Replicate the datahead 
  construct_som                                 #Construct a SOM for each calibration catalogue  
  !sim_tomo_som                                 #Save the SOM(s) to sim_som
  @sims_specz_tomo                              #Assign the tomographic sim specz sample as the calibrators 
  .lensfit_magnitude_selection                  #Select spectra with appropriate MAG_AUTO 
  +NREPL=@BV:NSOM_GOLDWEIGHT@                   #There are NSOM_GOLDWEIGHT SOMs per catalogue 
  +LINKREPL=TRUE                                #Catalogues are not overwritten: replicate as links 
  replicate_datahead                            #Replicate the datahead 
  !som_weight_training                          # ^^
  @sims_main_tomo                               #Assign the tomographic shear sample as the targets
  +NREPL=@BV:NSPLITKEEP@                        #There are NSIM*NSPLITKEEP*NSOM_GOLDWEIGHT calibration catalogues
  +LINKREPL=TRUE                                #Catalogues are not overwritten: replicate as links 
  replicate_datahead                            #Replicate the datahead 
  !intermediate_two
  +NREPL=@BV:NSOM_GOLDWEIGHT@                   #There are NSIM*NSPLIT*NSOM_GOLDWEIGHT calibration catalogues
  +LINKREPL=TRUE                                #Catalogues are not overwritten: replicate as links 
  replicate_datahead                            #Replicate the datahead 
  !som_weight_reference                         # ^^
  @sim_tomo_som                                 #Use the SOMs that we calculated above 
  get_features                                  #Add the SOM feature list variable to the data block
  compute_nz_weights                            #Compute the SOM Nz weights 
  merge_goldweight                              #Re-merge the tomographic catalogues 
  construct_nz                                  #Construct the goldweighted Nz 
  compute_dz_priors                             #Compute the dz bias priors from the results 
  @nzbias_NS !nzbias @nzcov_NS !nzcov
  decorrelate_nzbias                            #Compute the decorrelated Nz bias priors 
  %som_weight_reference-sims_main_tomo_input    #Save the main sample inputs to sims_main_tomo_input
  %som_weight_training-sims_specz_tomo_input    #Save the calibration inputs to sims_specz_tomo_input
  %som_weight_refr_cats-sims_main_tomo_out      #Save the main sample outputs to sims_main_tomo_out 
  %som_weight_refr_gold-sims_main_tomo_gold     #Save the main sample gold sample to sims_main_tomo_gold 
  %som_weight_calib_cats-sims_specz_tomo_out    #Save the calibration outputs to sims_specz_tomo_out
  %som_weight_calib_gold-sims_specz_tomo_gold   #Save the calibration outputs to sims_specz_tomo_gold 
  %nz_NS-nz_sims                                #Save the Nz to nz_sims 
  @sims_main_tomo_gold                          #Load the resulting gold catalogues 
  combine_tomocats                              #Re-merge the tomographic catalogues 
  !sims_main_gold                               #Save the gold catalogue as main_all_gold 
  -intermediate_two
  @                                             #Clear the DATAHEAD 
#}}}

.goldweight_dz_calib_nosom: #Compute the dz priors using simulations {{{
  @sims_specz_tomo                              #Assign the tomographic sim specz sample as the calibrators 
  .lensfit_magnitude_selection                  #Select spectra with appropriate MAG_AUTO 
  +NREPL=@BV:NSOM_GOLDWEIGHT@                   #There are NSOM_GOLDWEIGHT SOMs per catalogue 
  +LINKREPL=TRUE                                #Catalogues are not overwritten: replicate as links 
  replicate_datahead                            #Replicate the datahead 
  !som_weight_training                          # ^^
  @sims_main_tomo                               #Assign the tomographic shear sample as the targets
  +NREPL=@BV:NSIM@                              #There are NSIM*NSPLIT*NSOM_GOLDWEIGHT calibration catalogues 
  +LINKREPL=TRUE                                #Catalogues are not overwritten: replicate as links 
  replicate_datahead                            #Replicate the datahead 
  !intermediate_one
  +NREPL=@BV:NSPLITKEEP@                        #There are NSIM*NSPLITKEEP*NSOM_GOLDWEIGHT calibration catalogues
  +LINKREPL=TRUE                                #Catalogues are not overwritten: replicate as links 
  replicate_datahead                            #Replicate the datahead 
  !intermediate_two
  +NREPL=@BV:NSOM_GOLDWEIGHT@                   #There are NSIM*NSPLIT*NSOM_GOLDWEIGHT calibration catalogues
  +LINKREPL=TRUE                                #Catalogues are not overwritten: replicate as links 
  replicate_datahead                            #Replicate the datahead 
  !som_weight_reference                         # ^^
  @sim_tomo_som                                 #Use the SOMs that we calculated above 
  get_features                                  #Add the SOM feature list variable to the data block
  compute_nz_weights                            #Compute the SOM Nz weights 
  merge_goldweight                              #Re-merge the tomographic catalogues 
  construct_nz                                  #Construct the goldweighted Nz 
  compute_dz_priors                             #Compute the dz bias priors from the results 
  @nzbias_NS !nzbias @nzcov_NS !nzcov
  decorrelate_nzbias                            #Compute the decorrelated Nz bias priors 
  %som_weight_reference-sims_main_tomo_input    #Save the main sample inputs to sims_main_tomo_input
  %som_weight_training-sims_specz_tomo_input    #Save the calibration inputs to sims_specz_tomo_input
  %som_weight_refr_cats-sims_main_tomo_out      #Save the main sample outputs to sims_main_tomo_out 
  %som_weight_refr_gold-sims_main_tomo_gold     #Save the main sample gold sample to sims_main_tomo_gold 
  %som_weight_calib_cats-sims_specz_tomo_out    #Save the calibration outputs to sims_specz_tomo_out
  %som_weight_calib_gold-sims_specz_tomo_gold   #Save the calibration outputs to sims_specz_tomo_gold 
  %nz_NS-nz_sims                                #Save the Nz to nz_sims 
  @sims_main_tomo_gold                          #Load the resulting gold catalogues 
  combine_tomocats                              #Re-merge the tomographic catalogues 
  !sims_main_gold                               #Save the gold catalogue as main_all_gold 
  @                                             #Clear the DATAHEAD 
#}}}

.tomosom_dz_calib: #Compute the dz priors using simulations {{{
  @sims_specz_tomo                              #Start with the tomographic calibration catalogues 
  +FEATURETYPES=ALLCOLOUR+MAG                 #Features to use for the SOM construction 
  +OPTIMISE=--optimise                          #Optimise the number of HCs
  +SOMDIM="51 51" 
  get_features                                  #Add the SOM feature list variable to the data block
  construct_som                                 #Construct a SOM for each calibration catalogue  
  !sim_som_tomo                                 #Save the SOM(s) to sim_som
  @sims_specz_tomo                              #Assign the tomographic sim specz sample as the calibrators 
  !som_weight_training                          # ^^
  @sims_main_tomo                               #Assign the tomographic shear sample as the targets
  !som_weight_reference                         # ^^
  @sim_som_tomo                                 #Use the SOMs that we calculated above 
  .compute_nz_goldclass                         #Compute the nz 
  compute_dz_priors                             #Compute the dz bias priors from the results 
  @nzbias_NS !nzbias @nzcov_NS !nzcov
  decorrelate_nzbias                            #Compute the decorrelated Nz bias priors 
  %som_weight_reference-sims_main_tomo_input    #Save the main sample inputs to sims_main_tomo_input
  %som_weight_training-sims_specz_tomo_input    #Save the calibration inputs to sims_specz_tomo_input
  %som_weight_refr_cats-sims_main_tomo_out      #Save the main sample outputs to sims_main_tomo_out 
  %som_weight_refr_gold-sims_main_tomo_gold     #Save the main sample gold sample to sims_main_tomo_gold 
  %som_weight_calib_cats-sims_specz_tomo_gold   #Save the calibration outputs to sims_specz_tomo_gold 
  %nz_hc_optim-nz_hc_optim_sims                 #Save the Nz HC optimisation structures to nz_hc_optim_sims
  %nz_NS-nz_sims                                #Save the Nz to nz_sims 
  @sims_main_tomo_gold                          #Load the resulting gold catalogues 
  combine_tomocats                              #Re-merge the tomographic catalogues 
  !sims_main_gold                               #Save the gold catalogue as main_all_gold 
  @                                             #Clear the DATAHEAD 
#}}}

.photsom_dz_calib: #Compute the dz priors using simulations {{{
  @sims_main                                    #Start with the calibration catalogues 
  +FEATURETYPES=ALLCOLOUR+MAG                 #Features to use for the SOM construction 
  +OPTIMISE=--optimise                          #Optimise the number of HCs
  +SOMDIM="101 101" 
  +ADDITIONALFLAGS="-ct AlphaRecalC_weight --sparse.som 0.5"     #Don't use zero weight sources in the training, and use sparse training 
  get_features                                  #Add the SOM feature list variable to the data block
  construct_som                                 #Construct a SOM for each calibration catalogue  
  !sim_photsom                                  #Save the SOM(s) to sim_som
  @sims_specz_tomo                              #Assign the tomographic sim specz sample as the calibrators 
  !som_weight_training                          # ^^
  @sims_main_tomo                               #Assign the tomographic shear sample as the targets
  !som_weight_reference                         # ^^
  @sim_photsom                                  #Use the SOMs that we calculated above 
  replicate_ntomo                               #Replicate each SOM for the NTOMO tomographic bins 
  .compute_nz_goldclass                         #Compute the nz 
  compute_dz_priors                             #Compute the dz bias priors from the results 
  @nzbias_NS !nzbias @nzcov_NS !nzcov
  decorrelate_nzbias                            #Compute the decorrelated Nz bias priors 
  %som_weight_reference-sims_main_tomo_input    #Save the main sample inputs to sims_main_tomo_input
  %som_weight_training-sims_specz_tomo_input    #Save the calibration inputs to sims_specz_tomo_input
  %som_weight_refr_cats-sims_main_tomo_out      #Save the main sample outputs to sims_main_tomo_out 
  %som_weight_refr_gold-sims_main_tomo_gold     #Save the main sample gold sample to sims_main_tomo_gold 
  %som_weight_calib_cats-sims_specz_tomo_gold   #Save the calibration outputs to sims_specz_tomo_gold 
  %nz_hc_optim-nz_hc_optim_sims                 #Save the Nz HC optimisation structures to nz_hc_optim_sims
  %nz_NS-nz_sims                                   #Save the Nz to nz_sims 
  @sims_main_tomo_gold                          #Load the resulting gold catalogues 
  combine_tomocats                              #Re-merge the tomographic catalogues 
  !sims_main_gold                               #Save the gold catalogue as main_all_gold 
  @                                             #Clear the DATAHEAD 
#}}}

.tomophotsom_dz_calib: #Compute the dz priors using simulations {{{
  @sims_main_tomo                               #Start with the tomographic calibration catalogues 
  +FEATURETYPES=ALLCOLOUR+MAG                 #Features to use for the SOM construction 
  +OPTIMISE=--optimise                          #Optimise the number of HCs
  +SOMDIM="51 51" 
  +ADDITIONALFLAGS="--refr.truth -ct AlphaRecalC_weight --sparse.som 0.5"     #Don't use zero weight sources in the training, and use sparse training 
  get_features                                  #Add the SOM feature list variable to the data block
  construct_som                                 #Construct a SOM for each calibration catalogue  
  !sim_photsom_tomo                                 #Save the SOM(s) to sim_som
  @sims_specz_tomo                              #Assign the tomographic sim specz sample as the calibrators 
  !som_weight_training                          # ^^
  @sims_main_tomo                               #Assign the tomographic shear sample as the targets
  +NREPL=40                                     #-> replicate for the number of spatial splits x number of shear realisations 
  replicate 
  !som_weight_reference                         # ^^
  @sim_photsom_tomo                                 #Use the SOMs that we calculated above 
  get_features                                  #Add the SOM feature list variable to the data block
  .compute_nz_goldclass                         #Compute the nz 
  compute_dz_priors                             #Compute the dz bias priors from the results 
  @nzbias_NS !nzbias @nzcov_NS !nzcov
  decorrelate_nzbias                            #Compute the decorrelated Nz bias priors 
  %som_weight_reference-sims_main_tomo_input    #Save the main sample inputs to sims_main_tomo_input
  %som_weight_training-sims_specz_tomo_input    #Save the calibration inputs to sims_specz_tomo_input
  %som_weight_refr_cats-sims_main_tomo_out      #Save the main sample outputs to sims_main_tomo_out 
  %som_weight_refr_gold-sims_main_tomo_gold     #Save the main sample gold sample to sims_main_tomo_gold 
  %som_weight_calib_cats-sims_specz_tomo_gold   #Save the calibration outputs to sims_specz_tomo_gold 
  %nz_hc_optim-nz_hc_optim_sims                 #Save the Nz HC optimisation structures to nz_hc_optim_sims
  %nz_NS-nz_sims                                   #Save the Nz to nz_sims 
  @sims_main_tomo_gold                          #Load the resulting gold catalogues 
  combine_tomocats                              #Re-merge the tomographic catalogues 
  !sims_main_gold                               #Save the gold catalogue as main_all_gold 
  @                                             #Clear the DATAHEAD 
#}}}
#}}}

#Nz Computation {{{
.compute_nz_goldclass: #Compute an Nz given the current SOM & requested catalogues {{{
  compute_nz_weights     #Compute the SOM Nz weights 
  merge_goldclass        #Merge the goldclass information back (-> som_weight_refr_gold) 
  @som_weight_calib_cats #Copy the calib cats to the gold location (not made in merge_goldclass)
  !som_weight_calib_gold #Copy the calib cats to the gold location 
  construct_nz           #Make the Nz 
  plot_HC_nz             #Make some diagnostic figures 
#}}}

.compute_nz_goldweight: #Compute an Nz given the current SOM & requested catalogues {{{
  compute_nz_weights     #Compute the SOM Nz weights 
  merge_goldweight       #Merge the goldweight information back (-> som_weight_refr_gold, som_weight_calib_gold) 
  construct_nz           #Make the Nz 
#}}}

.goldclass_nz_calc: # Perform the fiducial Nz construction {{{
  @specz_adapt                                   #Use the specz calibration sample with adapted magnitudes 
  +FEATURETYPES=ALLCOLOUR+MAG                    #Features to use for the SOM construction 
  +OPTIMISE=--optimise                           #Optimise the number of HCs
  get_features                                   #Add the SOM feature list variable to the data block
  +NTHREADSSTORE=@BV:NTHREADS@      
  +NTHREADS=128                
  construct_som                                  #Construct the SOM 
  +NTHREADS=@BV:NTHREADSSTORE@
  !specz_som                                     #Save the SOM to specz_som 
  @specz_adapt_tomo                              #Assign the tomographic specz sample as the calibrators 
  !som_weight_training                           # ^^
  @main_all_tomo                                 #Assign the tomographic shear sample as the targets
  !som_weight_reference                          # ^^
  @specz_som                                     #Use the SOM trained on the calibration sample
  .compute_nz_goldclass                          #Compute Nz from the SOM (in DATAHEAD) & main+specz data (in reference/training blocks)
  %som_weight_reference-main_all_tomo_input      #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_training-specz_adapt_tomo_input    #Save the calibration outputs to specz_adapt_tomo_gold 
  %som_weight_refr_cats-main_all_tomo_out        #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_refr_gold-main_all_tomo_gold       #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_calib_cats-specz_adapt_tomo_gold   #Save the calibration outputs to specz_adapt_tomo_gold 
  %nz_hc_optim-nz_hc_optim_data                  #Save the Nz HC optimisation structures to nz_hc_optim_data 
  %nz_NS-nz_data                                    #Save the Nz to nz_data 
  @main_all_tomo_gold                            #Load the resulting gold catalogues 
  combine_tomocats                               #Re-merge the tomographic catalogues 
  !main_all_gold                                 #Save the gold catalogue as main_all_gold 
  @                                              #Clear the DATAHEAD 
#}}}

.goldclass_nz_calc_tomo: # Perform the fiducial Nz construction {{{
  @specz_adapt_tomo                              #Use the specz calibration sample with adapted magnitudes 
  +FEATURETYPES=ALLCOLOUR+MAG                    #Features to use for the SOM construction 
  +OPTIMISE=--optimise                           #Optimise the number of HCs
  get_features                                   #Add the SOM feature list variable to the data block
  +NTHREADSSTORE=@BV:NTHREADS@      
  +NTHREADS=128                
  construct_som                                  #Construct the SOM 
  +NTHREADS=@BV:NTHREADSSTORE@
  !specz_som                                     #Save the SOM to specz_som 
  @specz_adapt_tomo                              #Assign the tomographic specz sample as the calibrators 
  !som_weight_training                           # ^^
  @main_all_tomo                                 #Assign the tomographic shear sample as the targets
  !som_weight_reference                          # ^^
  @specz_som                                     #Use the SOM trained on the calibration sample
  .compute_nz_goldclass                          #Compute Nz from the SOM (in DATAHEAD) & main+specz data (in reference/training blocks)
  %som_weight_reference-main_all_tomo_input      #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_training-specz_adapt_tomo_input    #Save the calibration outputs to specz_adapt_tomo_gold 
  %som_weight_refr_cats-main_all_tomo_out        #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_refr_gold-main_all_tomo_gold       #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_calib_cats-specz_adapt_tomo_gold   #Save the calibration outputs to specz_adapt_tomo_gold 
  %nz_hc_optim-nz_hc_optim_data                  #Save the Nz HC optimisation structures to nz_hc_optim_data 
  %nz_NS-nz_data                                    #Save the Nz to nz_data 
  @main_all_tomo_gold                            #Load the resulting gold catalogues 
  combine_tomocats                               #Re-merge the tomographic catalogues 
  !main_all_gold                                 #Save the gold catalogue as main_all_gold 
  @                                              #Clear the DATAHEAD 
#}}}

.goldweight_nz_calc_notraining: #construct the Nz without retraining the SOMs {{{
  #@specz_adapt_tomo                              #Assign the tomographic specz sample as the calibrators 
  #.lensfit_magnitude_selection                  #Select spectra with appropriate MAG_AUTO 
  #+NREPL=@BV:NSOM_GOLDWEIGHT@                    #Compute the goldclass 10 times 
  #+LINKREPL=TRUE                                 #Catalogues are not overwritten: replicate as links 
  #replicate_datahead                             #Replicate the datahead 
  #!som_weight_training                           # ^^
  #@main_all_tomo                                 #Assign the tomographic shear sample as the targets
  #+NREPL=@BV:NSOM_GOLDWEIGHT@                    #Compute the goldclass 10 times 
  #+LINKREPL=TRUE                                 #Catalogues are not overwritten: replicate as links 
  #replicate_datahead                             #Replicate the datahead 
  #!som_weight_reference                          # ^^
  %main_all_tomo_input-som_weight_reference      #Save the main sample outputs to main_all_tomo_gold 
  %specz_adapt_tomo_input-som_weight_training    #Save the calibration outputs to specz_adapt_tomo_gold 
  @specz_tomo_som                                #Use the SOM trained on the calibration sample
  compute_nz_weights                             #Compute the SOM Nz weights 
  merge_goldweight                               #Re-merge the tomographic catalogues 
  construct_nz                                   #Construct the goldweighted Nz 
  %som_weight_reference-main_all_tomo_input      #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_training-specz_adapt_tomo_input    #Save the calibration outputs to specz_adapt_tomo_gold 
  %som_weight_refr_cats-main_all_tomo_out        #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_refr_gold-main_all_tomo_gold       #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_calib_cats-specz_adapt_tomo_out    #Save the calibration outputs to specz_adapt_tomo_gold 
  %som_weight_calib_gold-specz_adapt_tomo_gold   #Save the calibration outputs to specz_adapt_tomo_gold 
  #%nz_hc_optim-nz_hc_optim_data                  #Save the Nz HC optimisation structures to nz_hc_optim_data 
  %nz_NS-nz_data                                    #Save the Nz to nz_data 
  @main_all_tomo_gold                            #Load the resulting gold catalogues 
  combine_tomocats                               #Re-merge the tomographic catalogues 
  !main_all_gold                                 #Save the gold catalogue as main_all_gold 
  @                                              #Clear the DATAHEAD 

#}}}

.goldweight_nz_calc: # Perform the fiducial Nz construction {{{
  @specz_adapt_tomo                              #Use the specz calibration sample with adapted magnitudes 
  +FEATURETYPES=ALLCOLOUR+MAG                    #Features to use for the SOM construction 
  +SOMDIM="51 51"                                #Dimensions of the SOM 
  +NITER=100                                     #Number of training iterations  
  +OPTIMISE=                                     #Optimise the number of HCs
  get_features                                   #Add the SOM feature list variable to the data block
  +NREPL=@BV:NSOM_GOLDWEIGHT@                    #Compute the goldclass 10 times 
  +LINKREPL=FALSE                                #Catalogues are not overwritten: replicate as links 
  replicate_datahead                             #Replicate the datahead 
  construct_som                                  #Construct the SOMs 
  !specz_tomo_som                                #Save the SOM to specz_som 
  @specz_adapt_tomo                              #Assign the tomographic specz sample as the calibrators 
  .lensfit_magnitude_selection                  #Select spectra with appropriate MAG_AUTO 
  +NREPL=@BV:NSOM_GOLDWEIGHT@                    #Compute the goldclass 10 times 
  +LINKREPL=TRUE                                 #Catalogues are not overwritten: replicate as links 
  replicate_datahead                             #Replicate the datahead 
  !som_weight_training                           # ^^
  @main_all_tomo                                 #Assign the tomographic shear sample as the targets
  +NREPL=@BV:NSOM_GOLDWEIGHT@                    #Compute the goldclass 10 times 
  +LINKREPL=TRUE                                 #Catalogues are not overwritten: replicate as links 
  replicate_datahead                             #Replicate the datahead 
  !som_weight_reference                          # ^^
  @specz_tomo_som                                #Use the SOM trained on the calibration sample
  compute_nz_weights                             #Compute the SOM Nz weights 
  merge_goldweight                               #Re-merge the tomographic catalogues 
  construct_nz                                   #Construct the goldweighted Nz 
  %som_weight_reference-main_all_tomo_input      #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_training-specz_adapt_tomo_input    #Save the calibration outputs to specz_adapt_tomo_gold 
  %som_weight_refr_cats-main_all_tomo_out        #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_refr_gold-main_all_tomo_gold       #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_calib_cats-specz_adapt_tomo_out    #Save the calibration outputs to specz_adapt_tomo_gold 
  %som_weight_calib_gold-specz_adapt_tomo_gold   #Save the calibration outputs to specz_adapt_tomo_gold 
  #%nz_hc_optim-nz_hc_optim_data                  #Save the Nz HC optimisation structures to nz_hc_optim_data 
  %nz_NS-nz_data                                    #Save the Nz to nz_data 
  @main_all_tomo_gold                            #Load the resulting gold catalogues 
  combine_tomocats                               #Re-merge the tomographic catalogues 
  !main_all_gold                                 #Save the gold catalogue as main_all_gold 
  @                                              #Clear the DATAHEAD 
#}}}

.goldweight_nz_calc_nosom: # Perform the fiducial Nz construction {{{
  @specz_adapt_tomo                              #Assign the tomographic specz sample as the calibrators 
  .lensfit_magnitude_selection                  #Select spectra with appropriate MAG_AUTO 
  +NREPL=@BV:NSOM_GOLDWEIGHT@                    #Compute the goldclass 10 times 
  +LINKREPL=TRUE                                 #Catalogues are not overwritten: replicate as links 
  replicate_datahead                             #Replicate the datahead 
  !som_weight_training                           # ^^
  @main_all_tomo                                 #Assign the tomographic shear sample as the targets
  +NREPL=@BV:NSOM_GOLDWEIGHT@                    #Compute the goldclass 10 times 
  +LINKREPL=TRUE                                 #Catalogues are not overwritten: replicate as links 
  replicate_datahead                             #Replicate the datahead 
  !som_weight_reference                          # ^^
  @specz_tomo_som                                #Use the SOM trained on the calibration sample
  compute_nz_weights                             #Compute the SOM Nz weights 
  merge_goldweight                               #Re-merge the tomographic catalogues 
  construct_nz                                   #Construct the goldweighted Nz 
  %som_weight_reference-main_all_tomo_input      #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_training-specz_adapt_tomo_input    #Save the calibration outputs to specz_adapt_tomo_gold 
  %som_weight_refr_cats-main_all_tomo_out        #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_refr_gold-main_all_tomo_gold       #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_calib_cats-specz_adapt_tomo_out    #Save the calibration outputs to specz_adapt_tomo_gold 
  %som_weight_calib_gold-specz_adapt_tomo_gold   #Save the calibration outputs to specz_adapt_tomo_gold 
  #%nz_hc_optim-nz_hc_optim_data                  #Save the Nz HC optimisation structures to nz_hc_optim_data 
  %nz_NS-nz_data                                    #Save the Nz to nz_data 
  @main_all_tomo_gold                            #Load the resulting gold catalogues 
  combine_tomocats                               #Re-merge the tomographic catalogues 
  !main_all_gold                                 #Save the gold catalogue as main_all_gold 
  @                                              #Clear the DATAHEAD 
#}}}

.goldweight_nz_calc_hemi: # Perform the fiducial Nz construction {{{
  @specz_adapt_tomo                              #Use the specz calibration sample with adapted magnitudes 
  +FEATURETYPES=ALLCOLOUR+MAG                    #Features to use for the SOM construction 
  +SOMDIM="51 51"                                #Dimensions of the SOM 
  +NITER=100                                     #Number of training iterations  
  +OPTIMISE=                                     #Optimise the number of HCs
  get_features                                   #Add the SOM feature list variable to the data block
  +NREPL=@BV:NSOM_GOLDWEIGHT@                    #Compute the goldclass 10 times 
  +LINKREPL=FALSE                                #Catalogues are not overwritten: replicate as links 
  replicate_datahead                             #Replicate the datahead 
  construct_som                                  #Construct the SOMs 
  !specz_tomo_som                                #Save the SOM to specz_som 
  @specz_adapt_tomo                              #Assign the tomographic specz sample as the calibrators 
  .lensfit_magnitude_selection                   #Select spectra with appropriate MAG_AUTO 
  +NREPL=2                                       #Replicate for the 2 hemispheres 
  +LINKREPL=TRUE                                 #Catalogues are not overwritten: replicate as links 
  replicate_datahead                             #Replicate the datahead 
  +NREPL=@BV:NSOM_GOLDWEIGHT@                    #Compute the goldclass 10 times 
  +LINKREPL=TRUE                                 #Catalogues are not overwritten: replicate as links 
  replicate_datahead                             #Replicate the datahead 
  !som_weight_training                           # ^^
  @main_cats_tomo                                #Assign the tomographic shear sample as the targets
  +NREPL=@BV:NSOM_GOLDWEIGHT@                    #Compute the goldclass 10 times 
  +LINKREPL=TRUE                                 #Catalogues are not overwritten: replicate as links 
  replicate_datahead                             #Replicate the datahead 
  !som_weight_reference                          # ^^
  @specz_tomo_som                                #Use the SOM trained on the calibration sample
  compute_nz_weights                             #Compute the SOM Nz weights 
  merge_goldweight                               #Re-merge the tomographic catalogues 
  construct_nz                                   #Construct the goldweighted Nz 
  %som_weight_reference-main_cats_tomo_input     #Save the main sample outputs to main_cats_tomo_gold 
  %som_weight_training-specz_adapt_tomo_input    #Save the calibration outputs to specz_adapt_tomo_gold 
  %som_weight_refr_cats-main_cats_tomo_out       #Save the main sample outputs to main_cats_tomo_gold 
  %som_weight_refr_gold-main_cats_tomo_gold      #Save the main sample outputs to main_cats_tomo_gold 
  %som_weight_calib_cats-specz_adapt_tomo_out    #Save the calibration outputs to specz_adapt_tomo_gold 
  %som_weight_calib_gold-specz_adapt_tomo_gold   #Save the calibration outputs to specz_adapt_tomo_gold 
  #%nz_hc_optim-nz_hc_optim_data                 #Save the Nz HC optimisation structures to nz_hc_optim_data 
  %nz_NS-nz_data                                    #Save the Nz to nz_data 
  @main_cats_tomo_gold                           #Load the resulting gold catalogues 
  combine_tomocats                               #Re-merge the tomographic catalogues 
  !main_cats_gold                                #Save the hemisphere gold catalogues as main_cats_gold 
  combine_patch                                  #Combine the patches 
  !main_all_gold                                 #Save the gold catalogue as main_all_gold
  @                                              #Clear the DATAHEAD 
#}}}

.tomosom_nz_calc: # Perform the fiducial Nz construction {{{
  @specz_adapt_tomo                              #Use the specz calibration sample with adapted magnitudes 
  +FEATURETYPES=ALLCOLOUR+MAG                    #Features to use for the SOM construction 
  +MAGLIST="MAG_GAAP_u MAG_GAAP_g MAG_GAAP_r MAG_GAAP_i1 MAG_GAAP_i2 MAG_GAAP_Z MAG_GAAP_Y MAG_GAAP_J MAG_GAAP_H MAG_GAAP_Ks"
  +REFMAGNAME=MAG_AUTO                           #Name of the reference magnitude
  +OPTIMISE=--optimise                           #Optimise the number of HCs
  get_features                                   #Add the SOM feature list variable to the data block
  construct_som                                  #Construct the SOM 
  !specz_som_tomo                                #Save the SOM to specz_som 
  @specz_adapt_tomo                              #Assign the tomographic specz sample as the calibrators 
  !som_weight_training                           # ^^
  @main_all_tomo                                 #Assign the tomographic shear sample as the targets
  !som_weight_reference                          # ^^
  @specz_som_tomo                                #Use the SOM trained on the calibration sample
  .compute_nz_goldclass                          #Compute Nz from the SOM (in DATAHEAD) & main+specz data (in reference/training blocks)
  %som_weight_reference-main_all_tomo_input      #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_training-specz_adapt_tomo_input    #Save the calibration outputs to specz_adapt_tomo_gold 
  %som_weight_refr_cats-main_all_tomo_out        #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_refr_gold-main_all_tomo_gold       #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_calib_cats-specz_adapt_tomo_gold   #Save the calibration outputs to specz_adapt_tomo_gold 
  %nz_hc_optim-nz_hc_optim_data                  #Save the Nz HC optimisation structures to nz_hc_optim_data 
  %nz_NS-nz_data                                    #Save the Nz to nz_data 
  @main_all_tomo_gold                            #Load the resulting gold catalogues 
  combine_tomocats                               #Re-merge the tomographic catalogues 
  !main_all_gold                                 #Save the gold catalogue as main_all_gold 
  @                                              #Clear the DATAHEAD 
#}}}

.photsom_nz_calc: # Perform the photometric SOM Nz construction {{{
  @main_all                                      #Use the wide-field sample 
  +FEATURETYPES=ALLCOLOUR+MAG                    #Features to use for the SOM construction 
  +MAGLIST="MAG_GAAP_u MAG_GAAP_g MAG_GAAP_r MAG_GAAP_i1 MAG_GAAP_i2 MAG_GAAP_Z MAG_GAAP_Y MAG_GAAP_J MAG_GAAP_H MAG_GAAP_Ks"
  +REFMAGNAME=MAG_AUTO                           #Name of the reference magnitude
  +OPTIMISE=--optimise                           #Optimise the number of HCs
  get_features                                   #Add the SOM feature list variable to the data block
  construct_som                                  #Construct the SOM 
  !main_som                                      #Save the SOM to main_som 
  @specz_adapt_tomo                              #Assign the tomographic specz sample as the calibrators 
  !som_weight_training                           # ^^
  @main_all_tomo                                 #Assign the tomographic shear sample as the targets
  !som_weight_reference                          # ^^
  @main_som                                      #Use the SOM trained on the calibration sample
  .compute_nz_goldclass                          #Compute Nz from the SOM (in DATAHEAD) & main+specz data (in reference/training blocks)
  %som_weight_reference-main_all_tomo_input      #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_training-specz_adapt_tomo_input    #Save the calibration outputs to specz_adapt_tomo_gold 
  %som_weight_refr_cats-main_all_tomo_out        #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_refr_gold-main_all_tomo_gold       #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_calib_cats-specz_adapt_tomo_gold   #Save the calibration outputs to specz_adapt_tomo_gold 
  %nz_hc_optim-nz_hc_optim_data                  #Save the Nz HC optimisation structures to nz_hc_optim_data 
  %nz_NS-nz_data                                    #Save the Nz to nz_data 
  @main_all_tomo_gold                            #Load the resulting gold catalogues 
  combine_tomocats                               #Re-merge the tomographic catalogues 
  !main_all_gold                                 #Save the gold catalogue as main_all_gold 
  @                                              #Clear the DATAHEAD 
#}}}

.tomophotsom_nz_calc: # Perform the photometric SOM Nz construction {{{
  @main_all_tomo                                 #Use the wide-field sample 
  +FEATURETYPES=ALLCOLOUR+MAG                    #Features to use for the SOM construction 
  +MAGLIST="MAG_GAAP_u MAG_GAAP_g MAG_GAAP_r MAG_GAAP_i1 MAG_GAAP_i2 MAG_GAAP_Z MAG_GAAP_Y MAG_GAAP_J MAG_GAAP_H MAG_GAAP_Ks"
  +REFMAGNAME=MAG_AUTO                           #Name of the reference magnitude
  +OPTIMISE=--optimise                           #Optimise the number of HCs
  get_features                                   #Add the SOM feature list variable to the data block
  construct_som                                  #Construct the SOM 
  !main_som_tomo                                 #Save the SOM to main_som 
  @specz_adapt_tomo                              #Assign the tomographic specz sample as the calibrators 
  !som_weight_training                           # ^^
  @main_all_tomo                                 #Assign the tomographic shear sample as the targets
  !som_weight_reference                          # ^^
  @main_som_tomo                                 #Use the SOM trained on the calibration sample
  .compute_nz_goldclass                          #Compute Nz from the SOM (in DATAHEAD) & main+specz data (in reference/training blocks)
  %som_weight_reference-main_all_tomo_input      #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_training-specz_adapt_tomo_input    #Save the calibration outputs to specz_adapt_tomo_gold 
  %som_weight_refr_cats-main_all_tomo_out        #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_refr_gold-main_all_tomo_gold       #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_calib_cats-specz_adapt_tomo_gold   #Save the calibration outputs to specz_adapt_tomo_gold 
  %nz_hc_optim-nz_hc_optim_data                  #Save the Nz HC optimisation structures to nz_hc_optim_data 
  %nz_NS-nz_data                                    #Save the Nz to nz_data 
  @main_all_tomo_gold                            #Load the resulting gold catalogues 
  combine_tomocats                               #Re-merge the tomographic catalogues 
  !main_all_gold                                 #Save the gold catalogue as main_all_gold 
  @                                              #Clear the DATAHEAD 
#}}}

.readSOM_nz_calc_mad: # Perform the fiducial Nz construction {{{
  +FEATURETYPES=ALLCOLOUR+MAG                    #Features to use for the SOM construction 
  +OPTIMISE=--optimise                           #Optimise the number of HCs
  +SOMDIM="51 51" 
  +NITER=100 
  #get_features                                   #Add the SOM feature list variable to the data block
  +SOMFEATURES="MAG_GAAP_u-MAG_GAAP_g MAG_GAAP_u-MAG_GAAP_r MAG_GAAP_g-MAG_GAAP_r MAG_GAAP_u-MAG_GAAP_i MAG_GAAP_g-MAG_GAAP_i MAG_GAAP_r-MAG_GAAP_i MAG_GAAP_u-MAG_GAAP_Z MAG_GAAP_g-MAG_GAAP_Z MAG_GAAP_r-MAG_GAAP_Z MAG_GAAP_i-MAG_GAAP_Z MAG_GAAP_u-MAG_GAAP_Y MAG_GAAP_g-MAG_GAAP_Y MAG_GAAP_r-MAG_GAAP_Y MAG_GAAP_i-MAG_GAAP_Y MAG_GAAP_Z-MAG_GAAP_Y MAG_GAAP_u-MAG_GAAP_J MAG_GAAP_g-MAG_GAAP_J MAG_GAAP_r-MAG_GAAP_J MAG_GAAP_i-MAG_GAAP_J MAG_GAAP_Z-MAG_GAAP_J MAG_GAAP_Y-MAG_GAAP_J MAG_GAAP_u-MAG_GAAP_H MAG_GAAP_g-MAG_GAAP_H MAG_GAAP_r-MAG_GAAP_H MAG_GAAP_i-MAG_GAAP_H MAG_GAAP_Z-MAG_GAAP_H MAG_GAAP_Y-MAG_GAAP_H MAG_GAAP_J-MAG_GAAP_H MAG_GAAP_u-MAG_GAAP_Ks MAG_GAAP_g-MAG_GAAP_Ks MAG_GAAP_r-MAG_GAAP_Ks MAG_GAAP_i-MAG_GAAP_Ks MAG_GAAP_Z-MAG_GAAP_Ks MAG_GAAP_Y-MAG_GAAP_Ks MAG_GAAP_J-MAG_GAAP_Ks MAG_GAAP_H-MAG_GAAP_Ks MAG_AUTO"
  +WEIGHTNAME=AlphaRecalC_weight
  @specz_adapt_tomo                              #Assign the tomographic specz sample as the calibrators 
  !som_weight_training                           # ^^
  @main_all_tomo                                 #Assign the tomographic shear sample as the targets
  !som_weight_reference                          # ^^
  add_som                                        #Add a pre-existing SOM to the datablock 
  %som-specz_som                                 #Use the SOM trained on the calibration sample
  @specz_som
  .compute_nz_goldclass                          #Compute Nz from the SOM (in DATAHEAD) & main+specz data (in reference/training blocks)
  %som_weight_reference-main_all_tomo_input      #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_training-specz_adapt_tomo_input    #Save the calibration outputs to specz_adapt_tomo_gold 
  %som_weight_refr_cats-main_all_tomo_out        #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_refr_gold-main_all_tomo_gold       #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_calib_cats-specz_adapt_tomo_gold   #Save the calibration outputs to specz_adapt_tomo_gold 
  #%nz_hc_optim-nz_hc_optim_data                  #Save the Nz HC optimisation structures to nz_hc_optim_data 
  %nz_NS-nz_data                                 #Save the Nz to nz_data 
  @main_all_tomo_gold
  combine_tomocats 
  !main_all_gold
#}}}

.readSOM_nz_calc: # Perform the fiducial Nz construction {{{
  @specz_adapt_tomo     #Assign the tomographic specz sample as the calibrators 
  !som_weight_training  # ^^
  @main_all_tomo        #Assign the tomographic shear sample as the targets
  !som_weight_reference # ^^
  add_som               #Add a pre-existing SOM to the datablock 
  %som-specz_som        #Use the SOM trained on the calibration sample
  @specz_som
  .compute_nz_goldclass #Compute Nz from the SOM (in DATAHEAD) & main+specz data (in reference/training blocks)
  %som_weight_reference-main_all_tomo_input      #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_training-specz_adapt_tomo_input    #Save the calibration outputs to specz_adapt_tomo_gold 
  %som_weight_refr_cats-main_all_tomo_out        #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_refr_gold-main_all_tomo_gold       #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_calib_cats-specz_adapt_tomo_gold   #Save the calibration outputs to specz_adapt_tomo_gold 
  %nz_hc_optim-nz_hc_optim_data           #Save the Nz HC optimisation structures to nz_hc_optim_data 
  %nz_NS-nz_data           #Save the Nz to nz_data 
#}}}

.readSOM_nz_calc_hc_mad: # Perform the fiducial Nz construction {{{
  +FEATURETYPES=ALLCOLOUR+MAG                    #Features to use for the SOM construction 
  +OPTIMISE=
  +MINNHC=2000
  +SOMDIM="51 51" 
  +NITER=100 
  #get_features                                   #Add the SOM feature list variable to the data block
  +SOMFEATURES="MAG_GAAP_u-MAG_GAAP_g MAG_GAAP_u-MAG_GAAP_r MAG_GAAP_g-MAG_GAAP_r MAG_GAAP_u-MAG_GAAP_i MAG_GAAP_g-MAG_GAAP_i MAG_GAAP_r-MAG_GAAP_i MAG_GAAP_u-MAG_GAAP_Z MAG_GAAP_g-MAG_GAAP_Z MAG_GAAP_r-MAG_GAAP_Z MAG_GAAP_i-MAG_GAAP_Z MAG_GAAP_u-MAG_GAAP_Y MAG_GAAP_g-MAG_GAAP_Y MAG_GAAP_r-MAG_GAAP_Y MAG_GAAP_i-MAG_GAAP_Y MAG_GAAP_Z-MAG_GAAP_Y MAG_GAAP_u-MAG_GAAP_J MAG_GAAP_g-MAG_GAAP_J MAG_GAAP_r-MAG_GAAP_J MAG_GAAP_i-MAG_GAAP_J MAG_GAAP_Z-MAG_GAAP_J MAG_GAAP_Y-MAG_GAAP_J MAG_GAAP_u-MAG_GAAP_H MAG_GAAP_g-MAG_GAAP_H MAG_GAAP_r-MAG_GAAP_H MAG_GAAP_i-MAG_GAAP_H MAG_GAAP_Z-MAG_GAAP_H MAG_GAAP_Y-MAG_GAAP_H MAG_GAAP_J-MAG_GAAP_H MAG_GAAP_u-MAG_GAAP_Ks MAG_GAAP_g-MAG_GAAP_Ks MAG_GAAP_r-MAG_GAAP_Ks MAG_GAAP_i-MAG_GAAP_Ks MAG_GAAP_Z-MAG_GAAP_Ks MAG_GAAP_Y-MAG_GAAP_Ks MAG_GAAP_J-MAG_GAAP_Ks MAG_GAAP_H-MAG_GAAP_Ks MAG_AUTO"
  +WEIGHTNAME=AlphaRecalC_weight
  @specz_adapt_tomo                              #Assign the tomographic specz sample as the calibrators 
  !som_weight_training                           # ^^
  @main_all_tomo                                 #Assign the tomographic shear sample as the targets
  !som_weight_reference                          # ^^
  add_som                                        #Add a pre-existing SOM to the datablock 
  %som-specz_som                                 #Use the SOM trained on the calibration sample
  @specz_som
  .compute_nz_goldclass_hc                          #Compute Nz from the SOM (in DATAHEAD) & main+specz data (in reference/training blocks)
  %som_weight_reference-main_all_tomo_input      #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_training-specz_adapt_tomo_input    #Save the calibration outputs to specz_adapt_tomo_gold 
  %som_weight_refr_cats-main_all_tomo_out        #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_refr_gold-main_all_tomo_gold       #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_calib_cats-specz_adapt_tomo_gold   #Save the calibration outputs to specz_adapt_tomo_gold 
  #%nz_hc_optim-nz_hc_optim_data                  #Save the Nz HC optimisation structures to nz_hc_optim_data 
  %nz_NS-nz_data                                 #Save the Nz to nz_data 
  @main_all_tomo_gold
  combine_tomocats 
  !main_all_gold
#}}}
.readSOM_nz_calc_weight: # Perform the fiducial Nz construction {{{
  @specz_adapt_tomo     #Assign the tomographic specz sample as the calibrators 
  !som_weight_training  # ^^
  @main_all_tomo        #Assign the tomographic shear sample as the targets
  !som_weight_reference # ^^
  add_som               #Add a pre-existing SOM to the datablock 
  %som-specz_som        #Use the SOM trained on the calibration sample
  @specz_som
  .compute_nz_goldweight      #Compute Nz from the SOM (in DATAHEAD) & main+specz data (in reference/training blocks)
  %som_weight_reference-main_all_tomo_input      #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_training-specz_adapt_tomo_input    #Save the calibration outputs to specz_adapt_tomo_gold 
  %som_weight_refr_cats-main_all_tomo_out        #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_refr_gold-main_all_tomo_gold       #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_calib_cats-specz_adapt_tomo_gold   #Save the calibration outputs to specz_adapt_tomo_gold 
  %nz_hc_optim-nz_hc_optim_data           #Save the Nz HC optimisation structures to nz_hc_optim_data 
  %nz_NS-nz_data           #Save the Nz to nz_data 
  @main_all_tomo_gold
  combine_tomocats 
  !main_all_gold
#}}}
#}}}

#Shape calibration {{{
.fiducial_m_calib: #Compute the m priors using simulations {{{
  #Step 1: construct m-calibration surfaces from the simulated tomographic gold sample(s) 
  .simulation_side_mcalib 
  #Step 2: compute the data m values given the constructed m-surfaces  
  .data_side_mcalib 
#}}}

.simulation_side_mcalib: # construct m-calibration surfaces from the simulated tomographic gold sample(s) {{{
  +CONSTANT_SIMS=@DB:sims_main_tomo@ #Use the sims_main_tomo entries as the constant shear simulations
  @sims_main_gold                     #Use the gold simulated main catalogues 
  run_shape_recal_v2                  #Recalibrate shapes to remove PSF leakage
  +E1NAME=AlphaRecalD2_e1             #Use the recalibrated shapes
  +E2NAME=AlphaRecalD2_e2             #Use the recalibrated shapes
  !sims_main_gold_recal               #Save the recalibrated gold simulated main catalogues 
  tomography                          #Split the tomographic bins again 
  !sims_main_tomo_gold_recal          #Save the recalibrated gold tomographic simulated main catalogues 
  compute_m_surface                   #Compute an m_surface for each recalibrated tomographic catalogue 
  !m_surface                          #Save surface(s) to m_surface 
  +M1NAME=m1_raw                      #Use m1_raw (i.e. no higher order corrections)
  +M2NAME=m2_raw                      #Use m2_raw (i.e. no higher order corrections)
#}}}

.simulation_side_mcalib_nocomb: # construct m-calibration surfaces from the simulated tomographic gold sample(s) {{{
  +CONSTANT_SIMS=@DB:sims_main_tomo@ #Use the sims_main_tomo entries as the constant shear simulations
  @sims_main_gold                     #Use the gold simulated main catalogues 
  combine_cats
  run_shape_recal_v2                  #Recalibrate shapes to remove PSF leakage
  +E1NAME=AlphaRecalD2_e1             #Use the recalibrated shapes
  +E2NAME=AlphaRecalD2_e2             #Use the recalibrated shapes
  !sims_main_gold_recal               #Save the recalibrated gold simulated main catalogues 
  tomography                          #Split the tomographic bins again 
  !sims_main_tomo_gold_recal          #Save the recalibrated gold tomographic simulated main catalogues 
  compute_m_surface                   #Compute an m_surface for each recalibrated tomographic catalogue 
  !m_surface                          #Save surface(s) to m_surface 
  +M1NAME=m1_raw                      #Use m1_raw (i.e. no higher order corrections)
  +M2NAME=m2_raw                      #Use m2_raw (i.e. no higher order corrections)
#}}}

.simulation_side_mcalib_nocomb_bf: # construct m-calibration surfaces from the simulated tomographic gold sample(s) {{{
  +CONSTANT_SIMS=@DB:sims_main_tomo@ #Use the sims_main_tomo entries as the constant shear simulations
  @sims_main_gold                     #Use the gold simulated main catalogues 
  combine_cats
  +SPLITVAR=@BV:BULGEFRACNAME@
  +NSPLIT=10
  equalN_split
  run_shape_recal_v2                  #Recalibrate shapes to remove PSF leakage
  +E1NAME=AlphaRecalD2_e1             #Use the recalibrated shapes
  +E2NAME=AlphaRecalD2_e2             #Use the recalibrated shapes
  !sims_main_gold_recal               #Save the recalibrated gold simulated main catalogues 
  tomography                          #Split the tomographic bins again 
  !sims_main_tomo_gold_recal          #Save the recalibrated gold tomographic simulated main catalogues 
  compute_m_surface                   #Compute an m_surface for each recalibrated tomographic catalogue 
  !m_surface                          #Save surface(s) to m_surface 
  +M1NAME=m1_raw                      #Use m1_raw (i.e. no higher order corrections)
  +M2NAME=m2_raw                      #Use m2_raw (i.e. no higher order corrections)
#}}}

.simulation_side_mcalib_nocomb_conserv: # construct m-calibration surfaces from the simulated tomographic gold sample(s) {{{
  +CONSTANT_SIMS=@DB:sims_main_tomo@ #Use the sims_main_tomo entries as the constant shear simulations
  @sims_main_gold                     #Use the gold simulated main catalogues 
  combine_cats
  #Select sources we want/care about 
  add_epsf_variance 
  .select_epsf
  .select_epsf_variance
  !sims_main_gold_sel                 #Save the recalibrated gold simulated main catalogues 
  #Run shape recalibration 
  run_shape_recal_v2                  #Recalibrate shapes to remove PSF leakage
  +E1NAME=AlphaRecalD2_e1             #Use the recalibrated shapes
  +E2NAME=AlphaRecalD2_e2             #Use the recalibrated shapes
  correct_2D_cterm                    #Correct the 2D cterm 
  !sims_main_gold_recal               #Save the recalibrated gold simulated main catalogues 
  tomography                          #Split the tomographic bins again 
  !sims_main_tomo_gold_recal          #Save the recalibrated gold tomographic simulated main catalogues 
  compute_m_surface                   #Compute an m_surface for each recalibrated tomographic catalogue 
  !m_surface                          #Save surface(s) to m_surface 
  +M1NAME=m1_raw                      #Use m1_raw (i.e. no higher order corrections)
  +M2NAME=m2_raw                      #Use m2_raw (i.e. no higher order corrections)
#}}}

.simulation_side_mcalib_hemi: # construct m-calibration surfaces from the hemispherical simulated tomographic gold sample(s) {{{
  +CONSTANT_SIMS=@DB:sims_main_tomo@ #Use the sims_main_tomo entries as the constant shear simulations
  @sims_main_gold                     #Use the gold simulated main catalogues 
  run_shape_recal_v2                  #Recalibrate shapes to remove PSF leakage
  +E1NAME=AlphaRecalD2_e1             #Use the recalibrated shapes
  +E2NAME=AlphaRecalD2_e2             #Use the recalibrated shapes
  !sims_main_gold_recal               #Save the recalibrated gold simulated main catalogues 
  tomography                          #Split the tomographic bins again 
  !sims_main_tomo_gold_recal          #Save the recalibrated gold tomographic simulated main catalogues 
  compute_m_surface                   #Compute an m_surface for each recalibrated tomographic catalogue 
  !m_surface                          #Save surface(s) to m_surface 
  +M1NAME=m1_raw                      #Use m1_raw (i.e. no higher order corrections)
  +M2NAME=m2_raw                      #Use m2_raw (i.e. no higher order corrections)
#}}}

.dataonly_shape_recal: #Shape recalibration on the data-side only {{{
  @main_all_gold                              #Compute m for all sources in the main gold sample 
  run_shape_recal_v2                          #Recalibrate shapes to remove PSF leakage
  +E1NAME=AlphaRecalD2_e1                     #Use the recalibrated shapes
  +E2NAME=AlphaRecalD2_e2                     #Use the recalibrated shapes
  !main_all_gold_recal_@BV:BLIND@             #Save the recalibrated gold simulated main catalogues 
  tomography                                  #Split the tomographic bins again 
  !main_all_tomo_gold_recal_@BV:BLIND@        #Save the recalibrated gold tomographic simulated main catalogues 
#}}}

.dataonly_shape_recal_2dc: #Shape recalibration on the data-side only {{{
  @main_all_gold                              #Compute m for all sources in the main gold sample 
  run_shape_recal_v2                          #Recalibrate shapes to remove PSF leakage
  +E1NAME=AlphaRecalD2_e1                     #Use the recalibrated shapes
  +E2NAME=AlphaRecalD2_e2                     #Use the recalibrated shapes
  correct_2D_cterm                            #Correct the 2D cterm 
  !main_all_gold_recal_@BV:BLIND@             #Save the recalibrated gold simulated main catalogues 
  tomography                                  #Split the tomographic bins again 
  !main_all_tomo_gold_recal_@BV:BLIND@        #Save the recalibrated gold tomographic simulated main catalogues 
#}}}

.dataonly_shape_recal_2dc_start: #Shape recalibration on the data-side only {{{
  @main_all_gold                              #Compute m for all sources in the main gold sample 
  correct_2D_cterm                            #Correct the 2D cterm in raw shapes 
  !main_all_gold_2dc_@BV:BLIND@               #Save the 2D cterm corrected gold main catalogues 
  run_shape_recal_v2                          #Recalibrate shapes to remove PSF leakage
  +E1NAME=AlphaRecalD2_e1                     #Use the recalibrated shapes
  +E2NAME=AlphaRecalD2_e2                     #Use the recalibrated shapes
  !main_all_gold_recal_@BV:BLIND@             #Save the recalibrated gold simulated main catalogues 
  tomography                                  #Split the tomographic bins again 
  !main_all_tomo_gold_recal_@BV:BLIND@        #Save the recalibrated gold tomographic simulated main catalogues 
#}}}

.dataonly_shape_recal_2dc_both: #Shape recalibration on the data-side only {{{
  @main_all_gold                              #Compute m for all sources in the main gold sample 
  correct_2D_cterm                            #Correct the 2D cterm in raw shapes 
  !main_all_gold_2dc_@BV:BLIND@               #Save the 2D cterm corrected gold main catalogues 
  run_shape_recal_v2                          #Recalibrate shapes to remove PSF leakage
  +E1NAME=AlphaRecalD2_e1                     #Use the recalibrated shapes
  +E2NAME=AlphaRecalD2_e2                     #Use the recalibrated shapes
  correct_2D_cterm                            #Correct the 2D cterm in final shapes 
  !main_all_gold_recal_@BV:BLIND@             #Save the recalibrated gold simulated main catalogues 
  tomography                                  #Split the tomographic bins again 
  !main_all_tomo_gold_recal_@BV:BLIND@        #Save the recalibrated gold tomographic simulated main catalogues 
#}}}

.dataonly_shape_recal_flag: #Shape recalibration on the data-side only {{{
  @main_all_gold                              #Compute m for all sources in the main gold sample 
  run_shape_recal_flag                        #Recalibrate shapes to remove PSF leakage
  +E1NAME=AlphaRecalD2_e1                     #Use the recalibrated shapes
  +E2NAME=AlphaRecalD2_e2                     #Use the recalibrated shapes
  !main_all_gold_recal_@BV:BLIND@             #Save the recalibrated gold simulated main catalogues 
  tomography                                  #Split the tomographic bins again 
  !main_all_tomo_gold_recal_@BV:BLIND@        #Save the recalibrated gold tomographic simulated main catalogues 
#}}}

.dataonly_shape_recal_bf: #Shape recalibration on the data-side only {{{
  @main_all_gold                              #Compute m for all sources in the main gold sample 
  +SPLITVAR=@BV:BULGEFRACNAME@ 
  +NSPLIT=10
  equalN_split
  run_shape_recal_v2                          #Recalibrate shapes to remove PSF leakage
  combine_cats
  +E1NAME=AlphaRecalD2_e1                     #Use the recalibrated shapes
  +E2NAME=AlphaRecalD2_e2                     #Use the recalibrated shapes
  !main_all_gold_recal_@BV:BLIND@             #Save the recalibrated gold simulated main catalogues 
  tomography                                  #Split the tomographic bins again 
  !main_all_tomo_gold_recal_@BV:BLIND@        #Save the recalibrated gold tomographic simulated main catalogues 
#}}}

.iterate_covariance_onestat: #Run a single iteration of the covariance {{{
  .compute_covariance
  .prepare_chain
  .maximise_posterior_onestat

#}}}

.iterate_covariance_allstats: #Run a single iteration of the covariance {{{
  +ITERATION+=1
  .compute_covariance
  .prepare_all_chains
  .maximise_posterior_allstats

#}}}

.data_side_mcalib: # compute the data m values given the constructed m-surfaces  {{{
  .use_data_variables                         #Update variables for the data catalogues 
  @main_all_gold                              #Compute m for all sources in the main gold sample 
  run_shape_recal_v2                          #Recalibrate shapes to remove PSF leakage
  +E1NAME=AlphaRecalD2_e1                     #Use the recalibrated shapes
  +E2NAME=AlphaRecalD2_e2                     #Use the recalibrated shapes
  !main_all_gold_recal_@BV:BLIND@             #Save the recalibrated gold simulated main catalogues 
  tomography                                  #Split the tomographic bins again 
  !main_all_tomo_gold_recal_@BV:BLIND@        #Save the recalibrated gold tomographic simulated main catalogues 
  +NTHREADSBACK=@BV:NTHREADS@
  +NTHREADS=100
  compute_m_bias                              #Compute m-bias values & uncertainties  
  +NTHREADS=@BV:NTHREADSBACK@
  !main_all_tomo_gold_recal_mbias_@BV:BLIND@  #Save the individual mbias values to the datablock 
  make_m_covariance                           #Construct the m covariance matricies 
  #@mbias                                      #Save a copy of the mbiases for this blind 
  #!mbias_NS_@BV:BLIND@                        #
  #@mcov                                       #Save a copy of the mcovariances for this blind 
  #!mcov_NS_@BV:BLIND@                         #
#}}}

.data_side_mcalib_hemi: # compute the data m values given the constructed m-surfaces  {{{
  .use_data_variables                         #Update variables for the data catalogues 
  @main_cats_gold                             #Compute m for all sources in the main gold sample 
  run_shape_recal_v2                          #Recalibrate shapes to remove PSF leakage
  +E1NAME=AlphaRecalD2_e1                     #Use the recalibrated shapes
  +E2NAME=AlphaRecalD2_e2                     #Use the recalibrated shapes
  !main_gold_recal_@BV:BLIND@                 #Save the recalibrated gold simulated main catalogues 
  tomography                                  #Split the tomographic bins again 
  !main_tomo_gold_recal_@BV:BLIND@            #Save the recalibrated gold tomographic simulated main catalogues 
  compute_m_bias                              #Compute m-bias values & uncertainties  
  !main_tomo_gold_recal_mbias_@BV:BLIND@      #Save the individual mbias values to the datablock 
  make_m_covariance                           #Construct the m covariance matricies 
#}}}

.higher_m_calib: #Apply higher-order correction to m-calibration {{{
  add_higher_sims        #Add higher-order m-calibration catalogues 
  @m_surface             #Use the current m_surface
  higher_order_mcal      #Apply higher-order corrections to m_surface
  +M1NAME=m1_final       #Update variables to use corrected m1
  +M2NAME=m2_final       #Update variables to use corrected m2
  !m_surface             #Save the updated surface(s) to m_surface
#}}}

.add_m_calib: #Add the m calibraiton estimated previously {{{
  add_mbias                      #Add preexisting m calibration to the datablock 
  make_m_covariance              #Compute the m covariance 
#}}}

.sim_data_goldclass: #Compute the simulation goldclasses using data SOM {{{
  .add_dz_calib         #Add the dz priors 
  @specz_adapt_tomo     #Assign the tomographic specz sample as the calibrators 
  !som_weight_training  # ^^
  @sims_main_tomo                 #Assign the tomographic shear sample as the targets
  !som_weight_reference           # ^^
  @specz_som            #Use the SOM trained on the calibration sample
  .compute_nz_goldclass #Compute Nz from the SOM (in DATAHEAD) & main+specz data (in reference/training blocks)
  %nz_NS-nz_sim            #Use the data Nz from here on, when needed
  @nz_data              #Use the data Nz from here on, when needed
  !nz                   #Use the data Nz from here on, when needed
  %som_weight_reference-sims_main_tomo_input    #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_training-specz_sims_tomo_input    #Save the calibration outputs to specz_adapt_tomo_gold 
  %som_weight_refr_cats-sims_main_tomo_out      #Save the main sim sample outputs to sims_main_tomo_gold 
  %som_weight_refr_gold-sims_main_tomo_gold     #Save the main sim sample outputs to sims_main_tomo_gold 
  %som_weight_calib_cats-specz_sims_tomo_gold   #Save the sim calibration outputs to sims_specz_tomo_gold 
#}}}

.sim_data_goldweight: #Compute the simulation goldclasses using data SOM {{{
  .add_dz_calib         #Add the dz priors 
  @specz_adapt_tomo     #Assign the tomographic specz sample as the calibrators 
  !som_weight_training  # ^^
  @sims_main_tomo                 #Assign the tomographic shear sample as the targets
  !som_weight_reference           # ^^
  @specz_som            #Use the SOM trained on the calibration sample
  .compute_nz_goldweight #Compute Nz from the SOM (in DATAHEAD) & main+specz data (in reference/training blocks)
  %nz_NS-nz_sim            #Use the data Nz from here on, when needed
  @nz_data              #Use the data Nz from here on, when needed
  !nz                   #Use the data Nz from here on, when needed
  %som_weight_reference-sims_main_tomo_input    #Save the main sample outputs to main_all_tomo_gold 
  %som_weight_training-specz_sims_tomo_input    #Save the calibration outputs to specz_adapt_tomo_gold 
  %som_weight_refr_cats-sims_main_tomo_out      #Save the main sim sample outputs to sims_main_tomo_gold 
  %som_weight_refr_gold-sims_main_tomo_gold     #Save the main sim sample outputs to sims_main_tomo_gold 
  %som_weight_calib_cats-specz_sims_tomo_gold   #Save the sim calibration outputs to sims_specz_tomo_gold 
  @sims_main_tomo_gold
  combine_tomocats 
  !sims_main_gold
#}}}

.select_epsf: #{{{
  +THRESHOLD_UPPER=0.0421
  +THRESHOLD_LOWER=-0.0335
  +FILTERCOND="((PSF_e1_exp1>90)|((PSF_e1_exp1<@BV:THRESHOLD_UPPER@)&(PSF_e1_exp1>@BV:THRESHOLD_LOWER@)))&((PSF_e1_exp2>90)|((PSF_e1_exp2<@BV:THRESHOLD_UPPER@)&(PSF_e1_exp2>@BV:THRESHOLD_LOWER@)))&((PSF_e1_exp3>90)|((PSF_e1_exp3<@BV:THRESHOLD_UPPER@)&(PSF_e1_exp3>@BV:THRESHOLD_LOWER@)))&((PSF_e1_exp4>90)|((PSF_e1_exp4<@BV:THRESHOLD_UPPER@)&(PSF_e1_exp4>@BV:THRESHOLD_LOWER@)))&((PSF_e1_exp5>90)|((PSF_e1_exp5<@BV:THRESHOLD_UPPER@)&(PSF_e1_exp5>@BV:THRESHOLD_LOWER@)))"
  ldacfilter                      #Filter the catalogues 
  +THRESHOLD_UPPER=0.0331
  +THRESHOLD_LOWER=-0.0375
  +FILTERCOND="((PSF_e2_exp1>90)|((PSF_e2_exp1<@BV:THRESHOLD_UPPER@)&(PSF_e2_exp1>@BV:THRESHOLD_LOWER@)))&((PSF_e2_exp2>90)|((PSF_e2_exp2<@BV:THRESHOLD_UPPER@)&(PSF_e2_exp2>@BV:THRESHOLD_LOWER@)))&((PSF_e2_exp3>90)|((PSF_e2_exp3<@BV:THRESHOLD_UPPER@)&(PSF_e2_exp3>@BV:THRESHOLD_LOWER@)))&((PSF_e2_exp4>90)|((PSF_e2_exp4<@BV:THRESHOLD_UPPER@)&(PSF_e2_exp4>@BV:THRESHOLD_LOWER@)))&((PSF_e2_exp5>90)|((PSF_e2_exp5<@BV:THRESHOLD_UPPER@)&(PSF_e2_exp5>@BV:THRESHOLD_LOWER@)))"
  ldacfilter                      #Filter the catalogues 
#}}}

.select_platinum: #{{{
  +FILTERCOND="(SOMGoldWeight>=1)"
  ldacfilter                      #Filter the catalogues 
#}}}

.select_pyrite: #{{{
  +FILTERCOND="(SOMGoldWeight<1)"
  ldacfilter                      #Filter the catalogues 
#}}}

.select_epsf_variance: #{{{
  +THRESHOLD_UPPER=0.05
  +FILTERCOND="(PSF_e1_var<@BV:THRESHOLD_UPPER@)&(PSF_e2_var<@BV:THRESHOLD_UPPER@)"
  ldacfilter                      #Filter the catalogues 
#}}}
#}}}

#Utilities {{{
.ensure_ldac: # Ensure current DATAHEAD catalogues are LDAC compatible {{{
  convert_to_ldac     #Convert the input file to LDAC (if not already) 
  ldacrentab          #Rename the data extension to OBJECTS (if not already)
#}}}
 
.column_reduction: #Reduce columns contained in the catalogues {{{
  +KEEPSTRINGS="unique tile_label run_id THELI_NAME flag_ Level ^R$ MAG_GAAP_ MAG_AUTO ALPHA_ DELTA_ RAJ2000 DECJ2000 ^FLUX_RADIUS$ ^PSF_Q ^Agaper ^Bgaper ^RA_ ^DEC_ ^X_ ^Y_ e1 e2 weight scalelength SNR SNratio variance g1 g2 ^T_B$ ^Z_B$ redshift ^z_ zspec zbest ^SeqNr$ ^FIELD_POS$ Xpos Ypos ^W$ ^bulge_fraction"  #(Partial-)Matching columns are kept, case-insensitive  
  ldackeepcols        #Remove non-matching columns 
#}}}

.column_reduction_fits: #Reduce columns contained in the catalogues {{{
  +KEEPSTRINGS="unique tile_label THELI_NAME run_id flag_ Level ^R$ MAG_GAAP_ MAG_AUTO ALPHA_ DELTA_ RAJ2000 DECJ2000 ^FLUX_RADIUS$ ^PSF_Q ^Agaper ^Bgaper ^RA_ ^DEC_ ^X_ ^Y_ e1 e2 weight scalelength SNR SNratio variance g1 g2 ^T_B$ ^Z_B$ redshift ^z_ zbest zspec ^SeqNr$ ^FIELD_POS$ Xpos Ypos ^W$ ^bulge_fraction"  #(Partial-)Matching columns are kept, case-insensitive  
  fitskeepcols        #Remove non-matching columns 
#}}}

.gaapflag_selection_i1: #Select sources with valid GAAPFlag {{{
  +FILTERCOND=(FLAG_GAAP_u==0)&(FLAG_GAAP_g==0)&(FLAG_GAAP_r==0)&(FLAG_GAAP_i1==0)&(FLAG_GAAP_Z==0)&(FLAG_GAAP_Y==0)&(FLAG_GAAP_J==0)&(FLAG_GAAP_H==0)&(FLAG_GAAP_Ks==0)  #Set the filter condition 
  ldacfilter                      #Filter the catalogues 
#}}}

.gaapflag_selection: #Select sources with valid GAAPFlag {{{
  +FILTERCOND=(FLAG_GAAP_u==0)&(FLAG_GAAP_g==0)&(FLAG_GAAP_r==0)&(FLAG_GAAP_i1==0)&(FLAG_GAAP_i2==0)&(FLAG_GAAP_Z==0)&(FLAG_GAAP_Y==0)&(FLAG_GAAP_J==0)&(FLAG_GAAP_H==0)&(FLAG_GAAP_Ks==0)  #Set the filter condition 
  ldacfilter                      #Filter the catalogues 
#}}}

.gaapflag_selection_k1000: #Select sources with valid GAAPFlag {{{
  +FILTERCOND=(FLAG_GAAP_u==0)&(FLAG_GAAP_g==0)&(FLAG_GAAP_r==0)&(FLAG_GAAP_i==0)&(FLAG_GAAP_Z==0)&(FLAG_GAAP_Y==0)&(FLAG_GAAP_J==0)&(FLAG_GAAP_H==0)&(FLAG_GAAP_Ks==0)  #Set the filter condition 
  ldacfilter                      #Filter the catalogues 
#}}}

.gaapflag_selection_kv450: #Select sources with valid GAAPFlag {{{
  +FILTERCOND=(GAAP_Flag_u==0)&(GAAP_Flag_g==0)&(GAAP_Flag_r==0)&(GAAP_Flag_i==0)&(GAAP_Flag_Z==0)&(GAAP_Flag_Y==0)&(GAAP_Flag_J==0)&(GAAP_Flag_H==0)&(GAAP_Flag_Ks==0)  #Set the filter condition 
  ldacfilter                      #Filter the catalogues 
#}}}

.mask_selection: #Select sources with valid MASK {{{
  +FILTERCOND=(MASK<=1)
  ldacfilter                      #Filter the catalogues 
#}}}

.use_single_bin: #Convert to the One-Bin setup {{{
  %nz_NS-nz_tomobin                                  #Move nz to temporary folder 
  .dataonly_shape_recal_2dc_start                    #Run the shape recalibration 
  @main_all_tomo_gold_recal_@BV:BLIND@               #Reset to the recalibrated, combined-patch tomographic gold catalogue
  extract_patch                                      #Extract the individual patches again (used for treecorr)
  correct_cterm                                      #Correct c-terms for individual patches & bins 
  !main_tomo_gold_recal_cc_@BV:BLIND@_tomobin        #Save results to data block

  +TOMOLIMS='0.10 2.00'                              # set up the single bin tomographic limits 
  +MBIASVALUES=0.02                                  #neff_sigmae requireis an mbias. Just put something in there for now and let future Benjamin worry about this.
  +MBIASERRORS=0.007
  +MBIASCORR=0.99
  add_mbias
  add_nz
  @nz
  !nz_data
  make_m_covariance

  @main_tomo_gold_recal_cc_@BV:BLIND@_tomobin       #Set up one bin file 
  combine_patch                                     #All patches together 
  combine_cats                                      #No tomography 
  tomography                                        #Add tomographic labels to file for book-keeping  
  !main_all_tomo_gold_recal_cc_@BV:BLIND@           #Save 
  neff_sigmae                                       #Compute the sigma_e and n_eff for the combined-patch samples
  extract_patch                                     #Extract the individual patches again (used for treecorr)
  !main_tomo_gold_recal_cc_@BV:BLIND@               #Save individual patch tomographic gold cats to block 
#}}}

.cleanup: #{{{
  #Remove lots of block items: keeps only the initial (main_all_tomo_input) and final (main_all_tomo_gold_recal_cc_A) products 
  -jackknife_cov
  -main_all
  -main_all_gold
  -main_all_gold_recal_A
  -main_all_gold_recal_cc_A
  -main_all_tomo
  -main_all_tomo_gold
  -main_all_tomo_gold_recal_A
  -main_all_tomo_out
  -main_allweight
  -main_cats
  -main_cats_tomo
  -main_raw
  -main_tomo_gold_recal_A
  -main_tomo_gold_recal_cc_A
  -tc_input
#}}}
#}}}

#Other {{{
.recalculate_datavector_funcs: #Compute the final statistics from the combined xipms {{{
  @xipm_comb_@BV:BLIND@                      #Save the combined xipms to the datablock
  calculate_cosebis                          #Compute cosebis from the xipm 
  calculate_bandpowers                       #Compute bandpowers from the xipm
  rebin_xipm                                 #Compute binned xipm from the xipm
  @cosebis !cosebis_@BV:BLIND@               #Save the cosebis for this blind for later 
  @bandpowers !bandpowers_@BV:BLIND@               #Save the cosebis for this blind for later 
  @xipm_binned !xipm_binned_@BV:BLIND@               #Save the cosebis for this blind for later 
  @xipm_comb_@BV:BLIND@
#}}}

.calculate_datavector_funcs: #Calculate the data vector correlation functions and summaries {{{
  @main_tomo_gold_recal_cc_@BV:BLIND@        #Run treecorr on individual patches 
  prepare_treecorr                           #Convert each DATAHEAD catalogue to treecorr's expected format 
  !tc_input                                  #Save treecorr inputs to datablock (not used, just for posterity) 
  calc_xi_w_treecorr                         #Calculate xipm with treecor for all files in the DATAHEAD (-> xipm)
  @xipm                                      #Set the treecorr xipm to the DATAHEAD 
  !xipm_@BV:BLIND@                           #Save the xipm to the datablock, tagged with the current blind
  combine_xi_patches                         #Combine the xipm values across the patches 
  !xipm_comb_@BV:BLIND@                      #Save the combined xipms to the datablock
  calculate_cosebis                          #Compute cosebis from the xipm 
  calculate_bandpowers                       #Compute bandpowers from the xipm
  rebin_xipm                                 #Compute binned xipm from the xipm
  @cosebis !cosebis_@BV:BLIND@               #Save the cosebis for this blind for later 
  @bandpowers !bandpowers_@BV:BLIND@               #Save the cosebis for this blind for later 
  @xipm_binned !xipm_binned_@BV:BLIND@               #Save the cosebis for this blind for later 
  @xipm_comb_@BV:BLIND@
#}}}

.calculate_datavector: #Run xipm & compute cosebis  {{{
  @main_all_tomo_gold_recal_@BV:BLIND@       #Reset to the recalibrated, combined-patch tomographic gold catalogue
  extract_patch                              #Extract the individual patches again (used for treecorr)
  !main_tomo_gold_recal_@BV:BLIND@           #Save individual patch tomographic gold cats to block 
  correct_cterm                              #Correct c-terms for individual patches & bins 
  !main_tomo_gold_recal_cc_@BV:BLIND@        #Save results to data block
  combine_patch                              #Combine the c-corrected patches together by patch
  !main_all_tomo_gold_recal_cc_@BV:BLIND@    #Start with the combined-patch tomographic gold catalogue 
  neff_sigmae                                #Compute the sigma_e and n_eff for the combined-patch samples
  combine_tomocats                           #Combine the tomographic catalogues 
  !main_all_gold_recal_cc_@BV:BLIND@         #Save the combined tomographic and patch catalogue to the block 
  .calculate_datavector_funcs
#}}}

.calculate_datavector_pointing: #Run xipm & compute cosebis  {{{
  #@main_all_tomo_gold_recal_@BV:BLIND@       #Reset to the recalibrated, combined-patch tomographic gold catalogue
  #extract_patch                              #Extract the individual patches again (used for treecorr)
  #!main_tomo_gold_recal_@BV:BLIND@           #Save individual patch tomographic gold cats to block 
  #correct_cterm                              #Correct c-terms for individual patches & bins 
  #!main_tomo_gold_recal_cc_@BV:BLIND@        #Save results to data block
  @main_all_tomo_gold_recal_cc_@BV:BLIND@
  +SPLITVAR=THELI_NAME
  column_split
  !main_point_tomo_gold_recal_cc_@BV:BLIND@    #Start with the combined-patch tomographic gold catalogue 
  prepare_treecorr                           #Convert each DATAHEAD catalogue to treecorr's expected format 
  calc_xi_w_treecorr_multi                   #Calculate xipm with treecor for all files in the DATAHEAD (-> xipm)
  @xipm                                      #Set the treecorr xipm to the DATAHEAD 
  !xipm_comb_@BV:BLIND@                           #Save the xipm to the datablock, tagged with the current blind
  calculate_cosebis                          #Compute cosebis from the xipm 
  calculate_bandpowers                       #Compute bandpowers from the xipm
  rebin_xipm                                 #Compute binned xipm from the xipm
#}}}

.calculate_datavector_jk: #Run xipm & compute cosebis  {{{
  +NSPLITBAK=@BV:NSPLIT@                     #Save the number of splits variable 
  +NSPLIT=@BV:NSPLIT_JACKKNIFE@              #Use the number of jackknife splits 
  @main_all_gold_recal_@BV:BLIND@            #Reset to the recalibrated, combined-patch gold catalogue
  prepare_treecorr                           #Convert this file into treecorr format 
  calc_spatial_bins_treecorr                 #Compute spatial patches for jackknife 
  +NSPLIT=@BV:NSPLITBAK@                     #Reset the NSPLIT variable 
  @main_all_tomo_gold_recal_@BV:BLIND@       #Reset to the recalibrated, combined-patch tomographic gold catalogue
  extract_patch                              #Extract the individual patches again (used for treecorr)
  !main_tomo_gold_recal_@BV:BLIND@           #Save individual patch tomographic gold cats to block 
  correct_cterm                              #Correct c-terms for individual patches & bins 
  !main_tomo_gold_recal_cc_@BV:BLIND@        #Save results to data block
  combine_patch                              #Combine the c-corrected patches together by patch
  !main_all_tomo_gold_recal_cc_@BV:BLIND@    #Start with the combined-patch tomographic gold catalogue 
  neff_sigmae                                #Compute the sigma_e and n_eff for the combined-patch samples
  combine_tomocats                           #Combine the tomographic catalogues 
  !main_all_gold_recal_cc_@BV:BLIND@         #Save the combined tomographic and patch catalogue to the block 
  @main_tomo_gold_recal_cc_@BV:BLIND@        #Run treecorr on individual patches 
  prepare_treecorr                           #Convert each DATAHEAD catalogue to treecorr's expected format 
  !tc_input                                  #Save treecorr inputs to datablock (not used, just for posterity) 
  calc_xi_w_treecorr                         #Calculate xipm with treecor for all files in the DATAHEAD (-> xipm)
  @jackknife_cov                             #Load the jackknife covariances into the datahead 
  combine_covariances                        #Combine the tomographic patchwise covariances together into single full covs
  !jackknife_fullcov                         #Save full covariances to the datablock 
  map_xicov_to_cosebi                        #Convert the xipm jackknife covariances to cosebis
  !covariance_cosebis_jackknife              #Save cosebis jackknife covariances to the datablock 
  @xipm                                      #Set the treecorr xipm to the DATAHEAD 
  !xipm_@BV:BLIND@                           #Save the xipm to the datablock, tagged with the current blind
  combine_xi_patches                         #Combine the xipm values across the patches 
  !xipm_comb_@BV:BLIND@                      #Save the combined xipms to the datablock
  calculate_cosebis                          #Compute cosebis from the xipm 
  calculate_bandpowers                       #Compute bandpowers from the xipm
  rebin_xipm                                 #Compute binned xipm from the xipm
#}}}

.calculate_datavector_galc: #Run xipm & compute cosebis  {{{
  @main_all_tomo_gold_recal_@BV:BLIND@       #Reset to the recalibrated, combined-patch tomographic gold catalogue
  extract_patch                              #Extract the individual patches again (used for treecorr)
  !main_tomo_gold_recal_@BV:BLIND@           #Save individual patch tomographic gold cats to block 
  correct_galactic_cterm                     #Correct c-terms for individual patches & bins 
  !main_tomo_gold_recal_cc_@BV:BLIND@        #Save results to data block
  combine_patch                              #Combine the c-corrected patches together by patch
  !main_all_tomo_gold_recal_cc_@BV:BLIND@    #Start with the combined-patch tomographic gold catalogue 
  neff_sigmae                                #Compute the sigma_e and n_eff for the combined-patch samples
  combine_tomocats                           #Combine the tomographic catalogues 
  !main_all_gold_recal_cc_@BV:BLIND@         #Save the combined tomographic and patch catalogue to the block 
  @main_tomo_gold_recal_cc_@BV:BLIND@        #Run treecorr on individual patches 
  prepare_treecorr                           #Convert each DATAHEAD catalogue to treecorr's expected format 
  !tc_input                                  #Save treecorr inputs to datablock (not used, just for posterity) 
  calc_xi_w_treecorr                         #Calculate xipm with treecor for all files in the DATAHEAD (-> xipm)
  @xipm                                      #Set the treecorr xipm to the DATAHEAD 
  !xipm_@BV:BLIND@                           #Save the xipm to the datablock, tagged with the current blind
  combine_xi_patches                         #Combine the xipm values across the patches 
  !xipm_comb_@BV:BLIND@                      #Save the combined xipms to the datablock
  calculate_cosebis                          #Compute cosebis from the xipm 
  calculate_bandpowers                       #Compute bandpowers from the xipm
  rebin_xipm                                 #Compute binned xipm from the xipm
#}}}

.calculate_datavector_hemi_galc: #Run xipm & compute cosebis  {{{
  @main_tomo_gold_recal_@BV:BLIND@           #Reset to the recalibrated, combined-patch tomographic gold catalogue
  correct_galactic_cterm                     #Correct c-terms for individual patches & bins with possible galactic latitude trend 
  !main_tomo_gold_recal_cc_@BV:BLIND@        #Save results to data block
  neff_sigmae                                #Compute the sigma_e and n_eff for the combined-patch samples
  combine_tomocats                           #Combine the tomographic catalogues 
  !main_gold_recal_cc_@BV:BLIND@         #Save the combined tomographic and patch catalogue to the block 
  @main_tomo_gold_recal_cc_@BV:BLIND@        #Run treecorr on individual patches 
  prepare_treecorr                           #Convert each DATAHEAD catalogue to treecorr's expected format 
  !tc_input                                  #Save treecorr inputs to datablock (not used, just for posterity) 
  calc_xi_w_treecorr                         #Calculate xipm with treecor for all files in the DATAHEAD (-> xipm)
  @xipm                                      #Set the treecorr xipm to the DATAHEAD 
  !xipm_@BV:BLIND@                           #Save the xipm to the datablock, tagged with the current blind
  calculate_cosebis                          #Compute cosebis from the xipm 
  calculate_bandpowers                       #Compute bandpowers from the xipm
  rebin_xipm                                 #Compute binned xipm from the xipm
#}}}

.calculate_datavector_hemi: #Run xipm & compute cosebis  {{{
  @main_tomo_gold_recal_@BV:BLIND@           #Reset to the recalibrated, combined-patch tomographic gold catalogue
  correct_cterm                              #Correct c-terms for individual patches & bins 
  !main_tomo_gold_recal_cc_@BV:BLIND@        #Save results to data block
  neff_sigmae                                #Compute the sigma_e and n_eff for the combined-patch samples
  combine_tomocats                           #Combine the tomographic catalogues 
  !main_gold_recal_cc_@BV:BLIND@         #Save the combined tomographic and patch catalogue to the block 
  @main_tomo_gold_recal_cc_@BV:BLIND@        #Run treecorr on individual patches 
  prepare_treecorr                           #Convert each DATAHEAD catalogue to treecorr's expected format 
  !tc_input                                  #Save treecorr inputs to datablock (not used, just for posterity) 
  calc_xi_w_treecorr                         #Calculate xipm with treecor for all files in the DATAHEAD (-> xipm)
  @xipm                                      #Set the treecorr xipm to the DATAHEAD 
  !xipm_@BV:BLIND@                           #Save the xipm to the datablock, tagged with the current blind
  calculate_cosebis                          #Compute cosebis from the xipm 
  calculate_bandpowers                       #Compute bandpowers from the xipm
  rebin_xipm                                 #Compute binned xipm from the xipm
#}}}

.xistatistics: #Compute the xi statistics for this blind {{{
  @main_tomo_gold_recal_cc_@BV:BLIND@  #Run treecorr on individual patches 
  prepare_treecorr                     #Convert each DATAHEAD catalogue to treecorr's expected format 
  !tc_input                            #Save treecorr inputs to datablock (not used, just for posterity) 
  calc_xigpsf_w_treecorr               #Calculate xigpsf with treecor for all files in the DATAHEAD (-> xigpsf)
  calc_xipsf_w_treecorr                #Calculate xipsf with treecor for all files in the DATAHEAD (-> xipsf)
  @xigpsf
  rebin_xigpsf                         #Rebin the xigpsf to coarse bins 
  combine_xi_patches                   #Combine the xipm values across the patches 
  rebin_xigpsf                         #rebin the patch-combined xipsfs 
  @xipsf                               #move xipsf to the datahead 
  rebin_xipsf                          #Rebin the xipsf to coarse bins
  combine_xi_patches                   #Combine the xipm values across the patches 
  rebin_xipsf                          #rebin the patch-combined xipsfs 

  +STATISTIC=xipsf
  make_data_vector_allstats
  +STATISTIC=xigpsf
  make_data_vector_allstats
  +STATISTIC=xipm
  make_data_vector_allstats
  @xipm_vec_NScomb
  !xipm_vec
  @xipsf_vec_NScomb
  !xipsf_vec
  @xigpsf_vec_NScomb
  !xigpsf_vec
  plot_xisys
#}}}

.compute_all_statistics: #Compute the 2pt statistics from correlation functions {{{
  @xipm_comb                      #Save the combined xipms to the datablock
  calculate_cosebis               #Compute cosebis from the xipm 
  calculate_bandpowers            #Compute bandpowers from the xipm
  rebin_xipm                      #Compute binned xipm from the xipm
#}}}

.fiducial_combination: #Use the fiducial data combination {{{
  @xipm_comb_@BV:BLIND@    #Use the combined xipm data vector
  +COSMOSIS_BACK=@BV:COSMOSIS_PATCHLIST@  #Store the desired cosmosis patchlist
  +COSMOSIS_PATCHLIST=ALL                 #Run prepare for all available patches 
  prepare_cosmosis                        #Construct input files needed by COSMOSIS
  +COSMOSIS_PATCHLIST=@BV:COSMOSIS_BACK@  #Run prepare for all available patches 
  @cosmosis_neff_NS_@BV:BLIND@            #Use the combined Neff as fiducial 
  !cosmosis_neff                          #Use the combined Neff as fiducial 
  @cosmosis_sigmae_NS_@BV:BLIND@          #Use the combined sigma_e as fiducial 
  !cosmosis_sigmae                        #Use the combined sigma_e as fiducial 
  @nz_NS_@BV:BLIND@ !nz_NS                #Use the data Nz from here on, when needed
  make_cosmosis_nz                        #Construct the cosmosis nz file 
  @mbias_NS_@BV:BLIND@                    #Use the combined m bias for this blind  
  !mbias                                  #Use the combined m bias for this blind   
  @nz_NS_@BV:BLIND@                       #Use the combined nz as fiducial 
  !nz !nz_NS                              #Use the combined nz as fiducial  
  @cosmosis_nz_NS                         #Use the combined Nz as fiducial 
  !cosmosis_nz                            #Use the combined Nz as fiducial 
  @cosmosis_mcov_NS_@BV:BLIND@            #Use the combined m covariance as fiducial 
  !cosmosis_mcov                          #Use the combined m covariance as fiducial 
  @cosmosis_xipm_NScomb_@BV:BLIND@        #Use the combined xipm as fiducial 
  !cosmosis_xipm                          #Use the combined xipm as fiducial
  +NPAIRBASE=XI_@BV:SURVEY@_NScomb        #Use the combined XIpm counts as fiducial
  @cosmosis_mbias_NS_@BV:BLIND@           #Use the combined m bias as fiducial 
  !cosmosis_mbias                         #Use the combined m bias as fiducial  
  @cosmosis_msigma_NS_@BV:BLIND@          #Use the combined m sigmas
  !cosmosis_msigma                        #Use the combined m sigmas
  +SURVEYAREA=@BV:SURVEYAREA_NS@          #Use the combined area for the survey area 
  +SURVEYAREADEG=@BV:SURVEYAREADEG_NS@    #Use the combined area for the survey area 
  +SURVEYMASKFILE=@BV:SURVEYMASKFILE_NS@  #Use the combined mask file for the survey mask 
#}}}

.fiducial_combination_noprep: #Use the fiducial data combination {{{
  @cosmosis_neff_NS_@BV:BLIND@            #Use the combined Neff as fiducial 
  !cosmosis_neff                          #Use the combined Neff as fiducial 
  @cosmosis_sigmae_NS_@BV:BLIND@          #Use the combined sigma_e as fiducial 
  !cosmosis_sigmae                        #Use the combined sigma_e as fiducial 
  @nz_NS_@BV:BLIND@ !nz_NS                #Use the data Nz from here on, when needed
  make_cosmosis_nz                        #Construct the cosmosis nz file 
  @mbias_NS_@BV:BLIND@                    #Use the combined m bias for this blind  
  !mbias                                  #Use the combined m bias for this blind   
  @nz_NS_@BV:BLIND@                       #Use the combined nz as fiducial 
  !nz !nz_NS                              #Use the combined nz as fiducial  
  @cosmosis_nz_NS                         #Use the combined Nz as fiducial 
  !cosmosis_nz                            #Use the combined Nz as fiducial 
  @cosmosis_mcov_NS_@BV:BLIND@            #Use the combined m covariance as fiducial 
  !cosmosis_mcov                          #Use the combined m covariance as fiducial 
  @cosmosis_xipm_NScomb_@BV:BLIND@        #Use the combined xipm as fiducial 
  !cosmosis_xipm                          #Use the combined xipm as fiducial
  +NPAIRBASE=XI_@BV:SURVEY@_NScomb        #Use the combined XIpm counts as fiducial
  @cosmosis_mbias_NS_@BV:BLIND@           #Use the combined m bias as fiducial 
  !cosmosis_mbias                         #Use the combined m bias as fiducial  
  @cosmosis_msigma_NS_@BV:BLIND@          #Use the combined m sigmas
  !cosmosis_msigma                        #Use the combined m sigmas
  +SURVEYAREA=@BV:SURVEYAREA_NS@          #Use the combined area for the survey area 
  +SURVEYAREADEG=@BV:SURVEYAREADEG_NS@    #Use the combined area for the survey area 
  +SURVEYMASKFILE=@BV:SURVEYMASKFILE_NS@  #Use the combined mask file for the survey mask 
#}}}

.hemi_lite_combination: #Use the lite combination for north/south split {{{
  @xipm_@BV:BLIND@                                      #Use the split xipm data vector
  +COSMOSIS_BACK=@BV:COSMOSIS_PATCHLIST@                #Store the desired cosmosis patchlist
  +COSMOSIS_PATCHLIST=ALL                               #Run prepare for all available patches 
  prepare_cosmosis                                      #Construct input files needed by COSMOSIS
  +COSMOSIS_PATCHLIST=@BV:COSMOSIS_BACK@                #Run prepare for all available patches 
  @cosmosis_neff_@BV:HEMISPHERE@_@BV:BLIND@             #Use the combined Neff 
  !cosmosis_neff                                        #Use the combined Neff 
  @cosmosis_sigmae_@BV:HEMISPHERE@_@BV:BLIND@           #Use the combined sigma_e 
  !cosmosis_sigmae                                      #Use the combined sigma_e 
  @nz_data                                              #Use the data Nz from here on, when needed
  !nz_@BV:HEMISPHERE@                                   #Use the data Nz from here on, when needed
  make_cosmosis_nz                                      #Construct the cosmosis nz file 
  @mbias_@BV:HEMISPHERE@_@BV:BLIND@                     #Use the hemisphere m bias for this blind  
  !mbias                                                #Use the combined m bias for this blind   
  @nz_@BV:HEMISPHERE@                                   #Use the combined nz 
  !nz                                                   #Use the combined m bias 
  @cosmosis_nz_@BV:HEMISPHERE@                          #Use the combined Nz 
  !cosmosis_nz                                          #Use the combined Nz 
  @cosmosis_msigma_@BV:HEMISPHERE@_@BV:BLIND@           #Use the combined m sigmas
  !cosmosis_msigma                                      #Use the combined m sigmas
  @cosmosis_mcov_@BV:HEMISPHERE@_@BV:BLIND@             #Use the combined m covariance 
  !cosmosis_mcov                                        #Use the combined m covariance 
  @cosmosis_xipm_@BV:HEMISPHERE@_@BV:BLIND@             #Use the North xipm  
  !cosmosis_xipm                                        #Use the combined m covariance 
  @cosmosis_mbias_@BV:HEMISPHERE@_@BV:BLIND@            #Use the combined m bias 
  !cosmosis_mbias                                       #Use the combined m bias 
  +SURVEYAREA=@BV:SURVEYAREA_@BV:HEMISPHERE@@           #Use the combined area for the survey area 
  +SURVEYAREADEG=@BV:SURVEYAREADEG_@BV:HEMISPHERE@@     #Use the combined area for the survey area 
  +SURVEYMASKFILE=@BV:SURVEYMASKFILE_@BV:HEMISPHERE@@   #Use the combined mask file for the survey mask 
  +NPAIRBASE=XI_KiDS_Legacy_@BV:HEMISPHERE@             #Use this hemisphere for the pair counts 
#}}}

.hemi_extralite_combination: #Use the extralite combination for north/south split {{{
  @xipm_@BV:BLIND@                                      #Use the split xipm data vector
  +COSMOSIS_BACK=@BV:COSMOSIS_PATCHLIST@                #Store the desired cosmosis patchlist
  +COSMOSIS_PATCHLIST=ALL                               #Run prepare for all available patches 
  prepare_cosmosis                                      #Construct input files needed by COSMOSIS
  +COSMOSIS_PATCHLIST=@BV:COSMOSIS_BACK@                #Run prepare for all available patches 
  @cosmosis_neff_@BV:HEMISPHERE@_@BV:BLIND@             #Use the combined Neff 
  !cosmosis_neff                                        #Use the combined Neff 
  @cosmosis_sigmae_@BV:HEMISPHERE@_@BV:BLIND@           #Use the combined sigma_e 
  !cosmosis_sigmae                                      #Use the combined sigma_e 
  @nz_data                                              #Use the data Nz from here on, when needed
  !nz_@BV:HEMISPHERE@                                   #Use the data Nz from here on, when needed
  make_cosmosis_nz                                      #Construct the cosmosis nz file 
  @mbias_NS_@BV:BLIND@                                  #Use the combined m bias for this blind  
  !mbias                                                #Use the combined m bias for this blind   
  @nz_@BV:HEMISPHERE@                                   #Use the combined nz 
  !nz                                                   #Use the combined m bias 
  @cosmosis_nz_NS                                       #Use the combined Nz 
  !cosmosis_nz                                          #Use the combined Nz 
  @cosmosis_mcov_NS_@BV:BLIND@                          #Use the combined m covariance 
  !cosmosis_mcov                                        #Use the combined m covariance 
  @cosmosis_xipm_@BV:HEMISPHERE@_@BV:BLIND@             #Use the North xipm  
  !cosmosis_xipm                                        #Use the combined m covariance 
  @cosmosis_mbias_NS_@BV:BLIND@                         #Use the combined m bias 
  !cosmosis_mbias                                       #Use the combined m bias 
  +SURVEYAREA=@BV:SURVEYAREA_@BV:HEMISPHERE@@           #Use the combined area for the survey area 
  +SURVEYAREADEG=@BV:SURVEYAREADEG_@BV:HEMISPHERE@@     #Use the combined area for the survey area 
  +SURVEYMASKFILE=@BV:SURVEYMASKFILE_@BV:HEMISPHERE@@   #Use the combined mask file for the survey mask 
  +NPAIRBASE=XI_KiDS_Legacy_@BV:HEMISPHERE@             #Use this hemisphere for the pair counts 
#}}}

.compute_all_covariances: #Compute all statistic covariances {{{ 
  +STATISTIC=cosebis      #Compute the cosebis covariance 
  .compute_covariance     #Construct the ini and run the covariance
  +STATISTIC=bandpowers   #Compute the bandpowers covariance
  .compute_covariance     #Construct the ini and run the covariance
  +STATISTIC=xipm         #Compute the xipm covariance 
  .compute_covariance     #Construct the ini and run the covariance
#}}}

.compute_covariance: #Compute @BV:STATISTIC@ covariance {{{ 
  covariance_constructor  #Construct the one-covariance input file 
  run_covariance          #Run the one-covariance 
  @covariance_@BV:STATISTIC@
  !covariance_@BV:STATISTIC@_@BV:BLIND@_@BV:BOLTZMAN@
#}}}

.run_allIA_allchain_allstats: #Run the set of all chains+stats+IAmodels {{{

  +IAMODEL='linear'
  .run_oneIA_allchain_allstats 

  +IAMODEL='linear_z'
  +AIASTORE=@BV:PRIOR_AIA@
  +PRIOR_AIA=1.0
  .run_oneIA_allchain_allstats 
  +PRIOR_AIA=@BV:AIASTORE@

  +IAMODEL='massdep'
  +AIASTORE=@BV:PRIOR_AIA@
  +PRIOR_AIA="gaussian 5.74 0.32"
  decorrelate_massdep_params          #Construct the decorrelated mass-dependent parameters 
  .run_oneIA_allchain_allstats 
  +PRIOR_AIA=@BV:AIASTORE@

  +IAMODEL='tatt'
  .run_oneIA_allchain_allstats 

#}}}

.run_oneIA_allchain_allstats: #Run the set of all chains+stats for one IAmodel {{{

  +CHAINSUFFIX='_@BV:IAMODEL@'
  .run_allchain_allstats 

#}}}

.run_allchain_allstats: #Run the set of fiducial chains {{{                    

  +STORED_SAMPLER=@BV:SAMPLER@              #Store the desired sampler name 
  +SAMPLER=test                             #Run the test sampler for all statistics 
  .run_chain_allstats                       #

  +SAMPLER=grid                             #Run the grid sampler for all statistics 
  .run_chain_allstats                       #

  +SAMPLER=@BV:STORED_SAMPLER@              #Run the desired sampler for all statistics 
  .run_chain_allstats                       #

  +LIST_INPUT_SAMPLER=@BV:STORED_SAMPLER@   #Run the list sampler for all statistics 
  +SAMPLER=list                             #
  .run_chain_allstats                       #
  +SAMPLER=@BV:STORED_SAMPLER@              #Reset to the desired sampler 

  +SAMPLER=maxlike                          #
  .run_chain_allstats                       #
  +SAMPLER=@BV:STORED_SAMPLER@              #Reset to the desired sampler 

#}}}

.run_allchain_onestat: #Run the set of fiducial chains for one statistic {{{                    

  +STORED_SAMPLER=@BV:SAMPLER@              #Store the desired sampler name 
  +SAMPLER=test                             #Run the test sampler for all statistics 
  .run_chain_onestat                        #

  +SAMPLER=grid                             #Run the grid sampler for all statistics 
  .run_chain_onestat                        #

  +SAMPLER=@BV:STORED_SAMPLER@              #Run the desired sampler for all statistics 
  .run_chain_onestat                        #

  +LIST_INPUT_SAMPLER=@BV:STORED_SAMPLER@   #Run the list sampler for all statistics 
  +SAMPLER=list                             #
  .run_chain_onestat                        #
  +SAMPLER=@BV:STORED_SAMPLER@              #Reset to the desired sampler 

  +SAMPLER=maxlike                          #
  .run_chain_onestat                        #
  +SAMPLER=@BV:STORED_SAMPLER@              #Reset to the desired sampler 

#}}}

.run_chain_allstats: #Run the set of fiducial chains {{{                    

  +STATISTIC=cosebis
  .run_chain_onestat

  +STATISTIC=bandpowers
  .run_chain_onestat

  +STATISTIC=xipm
  .run_chain_onestat

#}}}

.maximise_posterior_allstats: #Run the set of fiducial chains {{{                    

  +STATISTIC=cosebis
  .maximise_posterior_onestat

  +STATISTIC=bandpowers
  .maximise_posterior_onestat

  +STATISTIC=xipm
  .maximise_posterior_onestat

#}}}

.maximise_posterior_onestat: #Run a chain for a single statistic {{{
  @mcmc_inp_@BV:STATISTIC@_@BV:BLIND@ 
  !mcmc_inp_@BV:STATISTIC@
  @cosmosis_xipm_NScomb_@BV:BLIND@ 
  !cosmosis_xipm                         
  decorrelate_massdep_params  #Construct massdep priors 
  prepare_values_priors       #Construct the values and priors files 
  cosmosis_constructor        #Construct the cosmosis .ini files 
  maximise_posterior          #maximise the posterior
  plot_Om_S8                  #Plot the Omegam_S8 plane for the requested sampler and statistic 
  plot_TPD                    #Plot the Theory Predictive Distributions for the requested statistic 
#}}}

.run_chain_onestat: #Run a chain for a single statistic {{{
  @mcmc_inp_@BV:STATISTIC@_@BV:BLIND@ 
  !mcmc_inp_@BV:STATISTIC@
  @cosmosis_xipm_NScomb_@BV:BLIND@ 
  !cosmosis_xipm                         
  decorrelate_massdep_params  #Construct massdep priors 
  prepare_values_priors       #Construct the values and priors files 
  cosmosis_constructor        #Construct the cosmosis .ini files 
  run_chain                   #Run the chain with cosmosis 
  plot_Om_S8                  #Plot the Omegam_S8 plane for the requested sampler and statistic 
  plot_TPD                    #Plot the Theory Predictive Distributions for the requested statistic 
#}}}

.run_allfigs_allstats: #Run the set of fiducial figures {{{                    

  +STORED_SAMPLER=@BV:SAMPLER@              #Store the desired sampler name 
  +SAMPLER=test                             #Run the test sampler for all statistics 
  .run_figs_allstats                       #

  +SAMPLER=grid                             #Run the grid sampler for all statistics 
  .run_figs_allstats                       #

  +SAMPLER=@BV:STORED_SAMPLER@              #Run the desired sampler for all statistics 
  .run_figs_allstats                       #

  +LIST_INPUT_SAMPLER=@BV:STORED_SAMPLER@   #Run the list sampler for all statistics 
  +SAMPLER=list                             #
  .run_figs_allstats                       #
  +SAMPLER=@BV:STORED_SAMPLER@              #Reset to the desired sampler 

#}}}

.run_figs_allstats: #Run the set of fiducial chains {{{                    

  +STATISTIC=cosebis
  plot_Om_S8                  #Plot the Omegam_S8 plane for the requested sampler and statistic 
  plot_TPD                    #Plot the Theory Predicitve distributions for the requested statisticOmegam_S8 plane for the requested sampler and statistic 

  +STATISTIC=bandpowers
  plot_Om_S8                  #Plot the Omegam_S8 plane for the requested sampler and statistic 
  plot_TPD                    #Plot the Theory Predicitve distributions for the requested statistic

  +STATISTIC=xipm
  plot_Om_S8                  #Plot the Omegam_S8 plane for the requested sampler and statistic 
  plot_TPD                    #Plot the Theory Predicitve distributions for the requested statistic 

#}}}

.nosim_datacovchain_onestat: #NoSims loop for allstats data vector, covariance, and chains {{{
  #Construct data vector & Covariance 
  .add_m_calib                 #Add the m calibration
  .use_data_variables          #Use data variables for this part 
  .dataonly_shape_recal        #Run the shape recalibration 
  .calculate_datavector        #Compute the data vector using treecorr
  .fiducial_combination        #Use the fiducial combination of data products 
  +STATISTIC=cosebis
  .compute_covariance     #Construct the ini and run the covariance
  #Run the chains
  .prepare_cosebis_chain
  .run_allchain_onestat          #Run the chains
#}}}

.nosim_datacovchain: #NoSims loop for allstats data vector, covariance, and chains {{{
  #Construct data vector & Covariance 
  .add_m_calib                 #Add the m calibration
  .use_data_variables          #Use data variables for this part 
  .dataonly_shape_recal        #Run the shape recalibration 
  .calculate_datavector        #Compute the data vector using treecorr
  .fiducial_combination        #Use the fiducial combination of data products 
  .compute_all_covariances     #Compute the covariance using OneCov
  #Run the chains
  .prepare_all_chains          #Prepare the data products for running cosmosis
  .run_allchain_allstats          #Run the chains
#}}}

.datacovchain: #NoSims loop for allstats data vector, covariance, and chains {{{
  #Construct data vector & Covariance 
  @nz_NS_@BV:BLIND@ !nz_data !nz_NS 
  .use_data_variables          #Use data variables for this part 
  +E1NAME=AlphaRecalD2_e1                     #Use the recalibrated shapes
  +E2NAME=AlphaRecalD2_e2                     #Use the recalibrated shapes
  .calculate_datavector_funcs  #Compute the data vector using treecorr
  @main_tomo_gold_recal_cc_@BV:BLIND@    #Start with the combined-patch tomographic gold catalogue 
  combine_patch
  neff_sigmae                                #Compute the sigma_e and n_eff for the combined-patch samples
  .fiducial_combination        #Use the fiducial combination of data products 
  .compute_all_covariances     #Compute the covariance using OneCov
  #Run the chains
  .prepare_all_chains          #Prepare the data products for running cosmosis
  .run_allchain_allstats          #Run the chains
#}}}

.cosebis_datacovchain: #NoSims loop for allstats data vector, covariance, and chains {{{
  #Construct data vector & Covariance 
  @nz_NS_@BV:BLIND@ !nz_data !nz_NS 
  .use_data_variables          #Use data variables for this part 
  +E1NAME=AlphaRecalD2_e1                     #Use the recalibrated shapes
  +E2NAME=AlphaRecalD2_e2                     #Use the recalibrated shapes
  .calculate_datavector_funcs  #Compute the data vector using treecorr
  @main_tomo_gold_recal_cc_@BV:BLIND@    #Start with the combined-patch tomographic gold catalogue 
  combine_patch
  neff_sigmae                                #Compute the sigma_e and n_eff for the combined-patch samples
  .fiducial_combination        #Use the fiducial combination of data products 
  +STATISTIC=cosebis      #Compute the cosebis covariance 
  .compute_covariance     #Construct the ini and run the covariance
  .prepare_cosebis_chain
  .run_chain_onestat
#}}}

.cosebis_datachain: #NoSims loop for allstats data vector, covariance, and chains {{{
  #Construct data vector & Covariance 
  @nz_NS_@BV:BLIND@ !nz_data !nz_NS 
  .use_data_variables          #Use data variables for this part 
  +E1NAME=AlphaRecalD2_e1                     #Use the recalibrated shapes
  +E2NAME=AlphaRecalD2_e2                     #Use the recalibrated shapes
  .calculate_datavector_funcs  #Compute the data vector using treecorr
  @main_tomo_gold_recal_cc_@BV:BLIND@    #Start with the combined-patch tomographic gold catalogue 
  combine_patch
  neff_sigmae                                #Compute the sigma_e and n_eff for the combined-patch samples
  .fiducial_combination        #Use the fiducial combination of data products 
  +STATISTIC=cosebis      #Compute the cosebis covariance 
  .compute_covariance     #Construct the ini and run the covariance
  .prepare_cosebis_chain
  .run_chain_onestat
#}}}

.covchain: #NoSims loop for allstats data vector, covariance, and chains {{{
  #Construct data vector & Covariance 
  @cosebis_@BV:BLIND@               #Save the cosebis for this blind for later 
  !cosebis 
  @bandpowers_@BV:BLIND@               #Save the cosebis for this blind for later 
  !bandpowers 
  @xipm_binned_@BV:BLIND@  
  !xipm_binned              #Save the cosebis for this blind for later 
  .use_data_variables          #Use data variables for this part 
  @main_tomo_gold_recal_cc_@BV:BLIND@    #Start with the combined-patch tomographic gold catalogue 
  combine_patch
  neff_sigmae                                #Compute the sigma_e and n_eff for the combined-patch samples
  .fiducial_combination        #Use the fiducial combination of data products 
  .compute_all_covariances     #Compute the covariance using OneCov
  #Run the chains
  .prepare_all_chains          #Prepare the data products for running cosmosis
  .run_allchain_allstats          #Run the chains
#}}}

.chain: #NoSims loop for allstats and chains {{{
  #Construct data vector & Covariance 
  @cosebis_@BV:BLIND@               #Save the cosebis for this blind for later 
  !cosebis 
  @bandpowers_@BV:BLIND@               #Save the cosebis for this blind for later 
  !bandpowers 
  @xipm_binned_@BV:BLIND@  
  !xipm_binned              #Save the cosebis for this blind for later 
  .use_data_variables          #Use data variables for this part 
  .fiducial_combination_noprep #Use the fiducial combination of data products 
  #Run the chains
  .prepare_all_chains          #Prepare the data products for running cosmosis
  .run_allchain_allstats          #Run the chains
#}}}

.do_TPD_plot: #{{{
  +STATISTIC=cosebis
  @cosebis_@BV:BLIND@               #Save the cosebis for this blind for later 
  !cosebis 
  make_data_vector_allstats        #Construct the combined data vector 
  @cosebis_vec_NScomb              #Use the combined NS data vector as fiducial 
  !cosebis_vec                     #Use the combined NS data vector as fiducial
  plot_TPD
  +STATISTIC=bandpowers
  @bandpowers_@BV:BLIND@               #Save the bandpowers for this blind for later 
  !bandpowers 
  make_data_vector_allstats        #Construct the combined data vector 
  @bandpowers_vec_NScomb              #Use the combined NS data vector as fiducial 
  !bandpowers_vec                     #Use the combined NS data vector as fiducial
  plot_TPD
  +STATISTIC=xipm
  @xipm_binned_@BV:BLIND@               #Save the xipm for this blind for later 
  !xipm_binned 
  make_data_vector_allstats        #Construct the combined data vector 
  @xipm_vec_NScomb              #Use the combined NS data vector as fiducial 
  !xipm_vec                     #Use the combined NS data vector as fiducial
  plot_TPD
#}}}

.nosim_datacovchain_cosebis_paus: #NoSims loop for allstats data vector, covariance, and chains {{{
  #Construct data vector & Covariance 
  .add_dz_calib
  .add_m_calib                 #Add the m calibration
  .use_data_variables_paus          #Use data variables for this part 
  .dataonly_shape_recal        #Run the shape recalibration 
  .calculate_datavector        #Compute the data vector using treecorr
  .fiducial_combination        #Use the fiducial combination of data products 
  +STATISTIC=cosebis      #Compute the cosebis covariance 
  .compute_covariance     #Construct the ini and run the covariance
  .prepare_cosebis_chain
  .run_chain_onestat
#}}}

.nosim_datacov_paus: #NoSims loop for allstats data vector, covariance, and chains {{{
  #Construct data vector & Covariance 
  .use_data_variables_paus          #Use data variables for this part 
  .dataonly_shape_recal        #Run the shape recalibration 
  .calculate_datavector        #Compute the data vector using treecorr
  .fiducial_combination        #Use the fiducial combination of data products 
  +STATISTIC=cosebis      #Compute the cosebis covariance 
  .compute_covariance     #Construct the ini and run the covariance
  .prepare_cosebis_chain
#}}}

.nz_mcal_datacovchain: #loop for allstats data-side mcal, data vector, covariance, and chains {{{
  .use_data_variables          #Use data variables for this part 
  .goldweight_nz_calc          #Compute Nz and Gold classes using fiducial setup 
  @nz_data                     #Use the data Nz from here on, when needed
  !nz_NS_@BV:BLIND@ !nz_NS     #Use the data Nz from here on, when needed
  .data_side_mcalib            #Run the m-calibration for this blind 
  make_m_covariance
  .calculate_datavector        #Compute the data vector using treecorr
  .fiducial_combination        #Use the fiducial combination of data products 
  .compute_all_covariances     #Compute the covariance using OneCov
  .prepare_all_chains          #Prepare the data products for running cosmosis
  .run_allchain_allstats       #Run the chains
#}}}

.nz_datacovchain: #loop for allstats data vector, covariance, and chains {{{
  .use_data_variables          #Use data variables for this part 
  .goldweight_nz_calc          #Compute Nz and Gold classes using fiducial setup 
  @nz_data                     #Use the data Nz from here on, when needed
  !nz_NS_@BV:BLIND@ !nz_NS     #Use the data Nz from here on, when needed
  @main_all_gold                              #Compute m for all sources in the main gold sample 
  run_shape_recal_v2                          #Recalibrate shapes to remove PSF leakage
  +E1NAME=AlphaRecalD2_e1                     #Use the recalibrated shapes
  +E2NAME=AlphaRecalD2_e2                     #Use the recalibrated shapes
  !main_all_gold_recal_@BV:BLIND@             #Save the recalibrated gold simulated main catalogues 
  tomography                                  #Split the tomographic bins again 
  !main_all_tomo_gold_recal_@BV:BLIND@        #Save the recalibrated gold tomographic simulated main catalogues 

  make_m_covariance
  .calculate_datavector        #Compute the data vector using treecorr
  .fiducial_combination        #Use the fiducial combination of data products 
  .compute_all_covariances     #Compute the covariance using OneCov
  .prepare_all_chains          #Prepare the data products for running cosmosis
  .run_allchain_allstats       #Run the chains
#}}}

.mcal_datacovchain: #loop for allstats data-side mcal, data vector, covariance, and chains {{{
  .data_side_mcalib            #Run the m-calibration for this blind 
  make_m_covariance
  .calculate_datavector        #Compute the data vector using treecorr
  .fiducial_combination        #Use the fiducial combination of data products 
  .compute_all_covariances     #Compute the covariance using OneCov
  .prepare_all_chains          #Prepare the data products for running cosmosis
  .run_allchain_allstats       #Run the chains
#}}}

.mcal_datacovchainIA: #loop for allstats data-side mcal, data vector, covariance, and chains for all IA models {{{
  .data_side_mcalib            #Run the m-calibration for this blind 
  .calculate_datavector        #Compute the data vector using treecorr
  .fiducial_combination        #Use the fiducial combination of data products 
  .compute_all_covariances     #Compute the covariance using OneCov
  .prepare_all_chains          #Prepare the data products for running cosmosis
  .run_allIA_allchain_allstats #Run the chains
#}}}

.prepare_cosebis_chain: #{{{
  +STATISTIC=cosebis
  make_data_vector_allstats        #Construct the combined data vector 
  @cosebis_vec_NScomb              #Use the combined NS data vector as fiducial 
  !cosebis_vec                     #Use the combined NS data vector as fiducial
  save_and_check_mcmc_inp_allstats #Construct the cosmosis input fits file 
  @mcmc_inp_cosebis !mcmc_inp_cosebis_@BV:BLIND@
  Bmodes_pvalue
#}}}

.prepare_cosebis_chain_hemi: #{{{
  +STATISTIC=cosebis
  make_data_vector_allstats        #Construct the combined data vector 
  @cosebis_vec_@BV:HEMISPHERE@     #Use the combined NS data vector as fiducial 
  !cosebis_vec                     #Use the combined NS data vector as fiducial
  save_and_check_mcmc_inp_allstats #Construct the cosmosis input fits file 
  Bmodes_pvalue
#}}}

.prepare_bandpowers_chain: #{{{
  +STATISTIC=bandpowers
  make_data_vector_allstats        #Construct the combined data vector 
  @bandpowers_vec_NScomb
  !bandpowers_vec
  save_and_check_mcmc_inp_allstats #Construct the cosmosis input fits file
  @mcmc_inp_bandpowers !mcmc_inp_bandpowers_@BV:BLIND@
  Bmodes_pvalue
#}}}

.prepare_bandpowers_chain_hemi: #{{{
  +STATISTIC=bandpowers
  make_data_vector_allstats        #Construct the combined data vector 
  @bandpowers_vec_@BV:HEMISPHERE@
  !bandpowers_vec
  save_and_check_mcmc_inp_allstats #Construct the cosmosis input fits file
  Bmodes_pvalue
#}}}

.prepare_xipm_chain: #{{{
  +STATISTIC=xipm
  make_data_vector_allstats        #Construct the combined data vector
  @xipm_vec_NScomb
  !xipm_vec
  save_and_check_mcmc_inp_allstats #Construct the cosmosis input fits file
  @mcmc_inp_xipm !mcmc_inp_xipm_@BV:BLIND@
#}}}

.prepare_xipm_chain_hemi: #{{{
  +STATISTIC=xipm
  make_data_vector_allstats        #Construct the combined data vector
  @xipm_vec_@BV:HEMISPHERE@
  !xipm_vec
  save_and_check_mcmc_inp_allstats #Construct the cosmosis input fits file
#}}}

.prepare_chain: #{{{
  make_data_vector_allstats        #Construct the combined data vector
  @@BV:STATISTIC@_vec_NScomb
  !@BV:STATISTIC@_vec
  save_and_check_mcmc_inp_allstats #Construct the cosmosis input fits file
  @mcmc_inp_@BV:STATISTIC@ ! @mcmc_inp_@BV:STATISTIC@_@BV:BLIND@
#}}}

.prepare_all_chains: #{{{
  .prepare_cosebis_chain
  .prepare_bandpowers_chain
  .prepare_xipm_chain
#}}}

.prepare_all_chains_hemi: #{{{
  .prepare_cosebis_chain_hemi
  .prepare_bandpowers_chain_hemi
  .prepare_xipm_chain_hemi
#}}}

.run_chain_set: #Run the set of fiducial chains {{{
  +STATISTIC=cosebis          #Use COSEBIs
  +NMAXCOSEBIS=6              #Use 6 COSEBIs modes, starting from 1
  +NMINCOSEBIS=1              #Use 5 COSEBIs modes, starting from 1

  +BOLTZMAN=CAMB_HM2020       #Use CAMB with HMCODE2020 for the power spectrum 
  +COSMOSIS_PIPELINE="sample_S8 sigma8toAs correlated_dz_priors one_parameter_hmcode load_nz_fits camb extrapolate_power source_photoz_bias linear_alignment projection cosebis scale_cuts likelihood"

  +SAMPLER=multinest          #Use the multinest sampler 
  prepare_values_priors       #Construct the values and priors files 
  cosmosis_constructor        #Construct the cosmosis .ini files 
  run_chain
  +SAMPLER=nautilus           #Use the multinest sampler 
  prepare_values_priors       #Construct the values and priors files 
  cosmosis_constructor        #Construct the cosmosis .ini files 
  run_chain

  +BOLTZMAN=COSMOPOWER_HM2020 #Use COSMOPOWER with HMCODE2020 for the power spectrum 
  +COSMOSIS_PIPELINE="sample_S8 sigma8toAs correlated_dz_priors one_parameter_hmcode load_nz_fits cosmopower distances extrapolate_power source_photoz_bias linear_alignment projection cosebis scale_cuts likelihood"

  +SAMPLER=multinest          #Use the multinest sampler 
  prepare_values_priors       #Construct the values and priors files 
  cosmosis_constructor        #Construct the cosmosis .ini files 
  run_chain
  +SAMPLER=nautilus           #Use the multinest sampler 
  prepare_values_priors       #Construct the values and priors files 
  cosmosis_constructor        #Construct the cosmosis .ini files 
  run_chain

#}}}

.postprocess_chain: #{{{
  +DVLENGTH=105
  +LIST_INPUT_SAMPLER=@BV:SAMPLER@
  +SAMPLER=list
  prepare_values_priors 
  cosmosis_constructor
  run_chain
  plot_TPD                #Plot theory predictive distributions 
  +SAMPLER=@BV:LIST_INPUT_SAMPLER@
  plot_Om_S8
#}}}

.postprocess_all_chains: #{{{
  +STATISTIC=cosebis
  .postprocess_chain
  +STATISTIC=bandpowers
  .postprocess_chain
  +STATISTIC=xipm
  .postprocess_chain
#}}}

.plotall_datavector: #Plot all the data vectors {{{
  +STATISTIC=cosebis
  plot_data_vector

  +STATISTIC=bandpowers
  plot_data_vector

  +STATISTIC=xipm
  plot_data_vector

#}}}

.compute_nz_goldclass_hc: #Compute an Nz given the current SOM & requested catalogues {{{
  compute_nz_weights        #Compute the SOM Nz weights 
  merge_goldclass        #Merge the goldclass information back (-> som_weight_refr_gold) 
  @som_weight_calib_cats #Copy the calib cats to the gold location (not made in merge_goldclass)
  !som_weight_calib_gold #Copy the calib cats to the gold location 
  construct_nz           #Make the Nz 
#}}}

#}}}

